<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
  <front>
    <article-meta>
      <title-group>
        <article-title>A Tutorial on Tailored Simulation-Based Sample Size
Planning for Experimental Designs with Generalized Linear Mixed
Models</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" equal-contrib="yes">
          <contrib-id contrib-id-type="orcid">0000-0002-2388-553X</contrib-id>
          <name>
            <surname>Pargent</surname>
            <given-names>Florian</given-names>
          </name>
          <string-name>Florian Pargent</string-name>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">formal
analysis</role>
          <role vocab="https://credit.niso.org" vocab-term="methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">methodology</role>
          <role vocab="https://credit.niso.org" vocab-term="visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">visualization</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu">a</xref>
          <xref ref-type="deceased" rid="equal-1">‡</xref>
        </contrib>
        <contrib contrib-type="author" equal-contrib="yes" corresp="yes">
          <contrib-id contrib-id-type="orcid">0000-0001-6728-2063</contrib-id>
          <name>
            <surname>Koch</surname>
            <given-names>Timo K.</given-names>
          </name>
          <string-name>Timo K. Koch</string-name>
          <email>timo.koch@unisg.ch</email>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">formal
analysis</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu">a</xref>
          <xref ref-type="aff" rid="aff-2">b</xref>
          <xref ref-type="corresp" rid="cor-2">*</xref>
          <xref ref-type="deceased" rid="equal-2">‡</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Kleine</surname>
            <given-names>Anne-Kathrin</given-names>
          </name>
          <string-name>Anne-Kathrin Kleine</string-name>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">formal
analysis</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Lermer</surname>
            <given-names>Eva</given-names>
          </name>
          <string-name>Eva Lermer</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">conceptualization</role>
          <role>funding aquisition</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu">a</xref>
          <xref ref-type="aff" rid="aff-3">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Gaube</surname>
            <given-names>Susanne</given-names>
          </name>
          <string-name>Susanne Gaube</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">supervision</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu">a</xref>
          <xref ref-type="aff" rid="aff-4">d</xref>
        </contrib>
      </contrib-group>
      <aff id="lmu">
        <institution content-type="dept">Department of Psychology</institution>
        <institution-wrap>
          <institution>LMU Munich</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-2">
        <institution content-type="dept">Institute of Behavioral Science &amp;
Technology</institution>
        <institution-wrap>
          <institution>University of St. Gallen</institution>
        </institution-wrap>
        <addr-line>Torstrasse 25</addr-line>
        <city>St. Gallen</city>
        <country>Switzerland</country>
        <postal-code>9000</postal-code>
      </aff>
      <aff id="aff-3">
        <institution content-type="dept">Department of Business
Psychology</institution>
        <institution-wrap>
          <institution>Technical University of Applied Sciences
Augsburg</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-4">
        <institution content-type="dept">Global Business School for
Health</institution>
        <institution-wrap>
          <institution>University College London</institution>
        </institution-wrap>
      </aff>
      <author-notes>
        <corresp id="cor-2">timo.koch@unisg.ch</corresp>
        <fn id="equal-1" fn-type="equal" symbol="‡">
          <p>Florian
Pargent</p>
        </fn>
        <fn id="equal-2" fn-type="equal" symbol="‡">
          <p>Timo K.
Koch</p>
        </fn>
      </author-notes>
      <history/>
      <abstract>
When planning experimental research, determining an appropriate sample
size and using suitable statistical models are crucial for robust and
informative results. The recent replication crisis underlines the need
for more rigorous statistical methodology and adequately powered
designs. Generalized linear mixed models (GLMMs) offer a flexible
statistical framework to analyze experimental data with complex (e.g.,
dependent and hierarchical) data structures. However, available methods
and software for a priori sample size planning for GLMMs are often
limited to specific designs. Tailored data simulation approaches are a
more flexible alternative. Based on a practical case study, the current
tutorial equips researchers with a step-by-step guide and corresponding
code for conducting tailored a priori sample size planning with GLMMs.
We not only focus on power analysis but also explain how to use the
precision of parameter estimates to determine appropriate sample sizes.
We conclude with an outlook on the increasing importance of
simulation-based sample size planning.
</abstract>
      <kwd-group kwd-group-type="author">
        <kwd>tutorial</kwd>
        <kwd>sample size planning</kwd>
        <kwd>generalized linear mixed model</kwd>
        <kwd>power analysis</kwd>
        <kwd>precision</kwd>
        <kwd>data simulation</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="introduction">
      <title>Introduction</title>
      <p>When planning experimental research, it is essential to determine
  an appropriate sample size and to use appropriate statistical models
  to analyze the data to ensure that the results obtained are both
  robust and informative
  (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
  2022a</xref>). The recent replication crisis has illustrated many
  challenges surrounding the reproducibility and reliability of study
  findings
  (<xref alt="Yarkoni, 2022" rid="ref-yarkoniGeneralizabilityCrisis2022" ref-type="bibr">Yarkoni,
  2022</xref>). As a result, there is a growing need for more rigorous
  statistical methodology and the adoption of adequately powered
  experimental designs. Multiple easy-to-use software solutions exist
  for simple statistical models and experimental designs. However, many
  researchers lack the skills and tools to conduct “a priori” (i.e.,
  before data collection) sample size planning for more complex research
  designs such as flexible generalized linear mixed models (GLMM)
  framework. In the present work, we provide a tutorial on how to
  determine adequate sample sizes by performing tailored
  simulation-based sample size planning for GLMMs. After introducing
  some theoretical background on sample size planning, we review
  existing software solutions in R and discuss under which circumstances
  tailored data simulations are necessary. Then we describe general
  steps and decisions involved in tailored data simulation. To
  illustrate the details of these steps, we finish with a hypothetical
  case study from the field of human-AI (artificial intelligence)
  interaction research.</p>
      <p>To benefit most of this tutorial paper, we recommend readers to
  familiarise themselves with basic statistical concepts like hypothesis
  tests (HTs) and their statistical power as well as confidence
  intervals (CIs) and their precision
  (<xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021" ref-type="bibr">Kumle
  et al., 2021</xref>;
  <xref alt="Lakens, 2022b" rid="ref-lakensImprovingYourStatistical2022" ref-type="bibr">Lakens,
  2022b</xref>;
  <xref alt="Riesthuis, 2024" rid="ref-riesthuisSimulationBasedPowerAnalyses2024" ref-type="bibr">Riesthuis,
  2024</xref>). Some knowledge of causal inference is useful but not
  necessary
  (<xref alt="Deffner et al., 2022" rid="ref-deffnerCausalFrameworkCrossCultural2022" ref-type="bibr">Deffner
  et al., 2022</xref>;
  <xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021" ref-type="bibr">Lundberg
  et al., 2021</xref>). In addition, readers should have a rough
  understanding of R
  (<xref alt="Wickham et al., 2023" rid="ref-wickhamDataScienceImport2023" ref-type="bibr">Wickham
  et al., 2023</xref>) and how to simulate data. For data simulation, we
  use functions from the tidyverse
  (<xref alt="Wickham et al., 2019" rid="ref-wickhamWelcomeTidyverse2019" ref-type="bibr">Wickham
  et al., 2019</xref>) and the faux package
  (<xref alt="DeBruine, 2023" rid="ref-R-faux" ref-type="bibr">DeBruine,
  2023</xref>). Finally, readers should be familiar with regression
  modeling in general and GLMMs in particular. In this tutorial, we
  simulate data by manually specifying the model equation of a GLMM that
  represents our assumed data generating process
  (<xref alt="DeBruine &amp; Barr, 2021" rid="ref-debruineUnderstandingMixedEffectsModels2021" ref-type="bibr">DeBruine
  &amp; Barr, 2021</xref>). It is not necessary to understand the
  technical details of how GLMMs are estimated. However it is crucial to
  understand the structure of a basic GLMM (e.g., logistic regression
  with random intercepts) and how the model assumes that the values in
  the dependent variable are determined by the predictor variables and
  the random effects.</p>
    </sec>
    <sec id="theoretical-background">
      <title>Theoretical background</title>
      <sec id="planning-for-statistical-power-or-precision">
        <title>Planning for statistical power or precision</title>
        <p>Conducting research with insufficiently large sample sizes can
    have many negative consequences. First, experiments may yield
    inconclusive or misleading results, hindering the accumulation of
    knowledge. Second, studies that are doomed to never finding a
    postulated effect waste resources by consuming time, effort, and
    funding without delivering meaningful results. For these reasons,
    many journals and funding bodies now require that a justification of
    sample size is included in study protocols and grant proposals,
    recognizing its significance in ensuring robust and meaningful
    findings. Although scientists often do not justify sample size or
    use general heuristics from the literature, resource constraints
    often play an important role
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
    2022a</xref>). But ideally, a suitable sample size should be
    determined a priori (i.e., before the study is conducted) based on
    some meaningful computation to ensure that the study will be able to
    fulfill its purpose.</p>
        <p>The majority of empirical studies in psychology and other social
    sciences apply hypothesis testing. As a consequence, the dominant
    approach for determining an adequate sample size is based on power
    analysis (i.e., planning for power)
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
    2022a</xref>;
    <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008" ref-type="bibr">Maxwell
    et al., 2008</xref>). Statistical power is defined as the
    probability that a HT has a significant p-value when analyzing
    repeated samples from a population with a true effect of some
    pre-specified size
    (<xref alt="Cohen, 1992" rid="ref-cohenPowerPrimer1992" ref-type="bibr">Cohen,
    1992</xref>). Less formally, power is described as the probability
    that a HT correctly rejects the null hypothesis when the alternative
    hypothesis is true. If the sample size (i.e., the number of
    participants and/or stimuli) used for data collection is
    insufficient to detect the effects or relationships being
    investigated with high probability, the study is considered
    “underpowered”. When planning for power, a target is set for the
    statistical power of a HT of interest. Assuming some effect size of
    interest and a desired significance level, a minimum sample size can
    be determined that, on average, would guarantee reaching this
    target. Although it is recommended to justify the desired
    significance level and power
    (<xref alt="Lakens, Adolfi, et al., 2018" rid="ref-lakensJustifyYourAlpha2018" ref-type="bibr">Lakens,
    Adolfi, et al., 2018</xref>), most empirical studies adopt the
    heuristic of <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives><tex-math><![CDATA[1 - \beta = 0.80]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.80</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>In contrast to power analysis, sample size planning can also be
    based on the precision of parameter estimates (i.e., planning for
    precision or planning for accuracy)
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
    2022a</xref>;
    <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008" ref-type="bibr">Maxwell
    et al., 2008</xref>). Not all research questions are best answered
    using hypothesis testing. It has been argued that basic research
    rarely requires making discrete decisions on whether some effect has
    been “discovered” and should thus shift from a hypothesis testing
    towards an estimation framework
    (<xref alt="Cumming, 2014" rid="ref-cummingNewStatisticsWhy2014" ref-type="bibr">Cumming,
    2014</xref>;
    <xref alt="Kruschke &amp; Liddell, 2018" rid="ref-kruschkeBayesianNewStatistics2018" ref-type="bibr">Kruschke
    &amp; Liddell, 2018</xref>;
    <xref alt="McElreath, 2020" rid="ref-mcelreathStatisticalRethinkingBayesian2020" ref-type="bibr">McElreath,
    2020</xref>). Although this view is not without critique
    (<xref alt="Uygun Tunç et al., 2023" rid="ref-uyguntuncEpistemicPragmaticFunction2023" ref-type="bibr">Uygun
    Tunç et al., 2023</xref>), at least for exploratory or pilot studies
    where little previous research has been conducted, more scientists
    seem to agree that simply estimating the effects of interest and
    making the estimation uncertainty transparent by reporting CIs is
    more useful. Assuming that no HTs are conducted for a planned study,
    power analysis is not relevant for sample size planning.
    Nonetheless, the sample size still has a crucial effect on how
    informative the planned study will be, because an effect of interest
    is estimated more precisely with bigger samples. In the precision
    framework, the target quantity commonly used for sample size
    planning is the expected width of a CI
    (<xref alt="Kelley &amp; Rausch, 2006" rid="ref-kelleySampleSizePlanning2006" ref-type="bibr">Kelley
    &amp; Rausch, 2006</xref>;
    <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
    2022a</xref>;
    <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008" ref-type="bibr">Maxwell
    et al., 2008</xref>). The values inside a CI are often interpreted
    as plausible values for the quantity of interest it is supposed to
    estimate. More formally, a CI with confidence level 0.95 provides
    the smallest interval with the property that upon repeated sampling,
    95% of individual CIs would include the true quantity of interest.
    Thus, a narrow CI is more informative about the size of the true
    effect than a wide interval. Apart from the desired confidence
    level, the width of a CI depends strongly on the sample size.
    Because bigger samples carry more information, they lead to smaller
    CIs. When planning for precision, a target can be set for the
    expected width of a CI of interest. Assuming some effect size of
    interest and a desired confidence level, a minimum sample size can
    be determined that, on average, would guarantee reaching this
    target. Because planning for precision is still rare, there are no
    common heuristics on how to choose the desired width of the CI
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
    2022a</xref>).</p>
      </sec>
      <sec id="generalized-linear-mixed-models-glmms">
        <title>Generalized linear mixed models (GLMMs)</title>
        <p>As study designs become more complex, psychological researchers
    require more sophisticated statistical models to capture the nuanced
    relationships and grouping structures introduced by them
    (<xref alt="Yarkoni, 2022" rid="ref-yarkoniGeneralizabilityCrisis2022" ref-type="bibr">Yarkoni,
    2022</xref>). GLMMs (also called multilevel models) are gaining
    increasing popularity because they offer great flexibility
    (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021" ref-type="bibr">Fahrmeir
    et al., 2021</xref>). GLMMs are an extension of LMMs (Linear Mixed
    Models), which are, in turn, extensions of linear regression models
    that account for correlated data, including hierarchical structures
    (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021" ref-type="bibr">Fahrmeir
    et al., 2021</xref>). In this context, correlated data means that
    the value in the outcome variable for one observation may be related
    to the value of another observation in a systematic way that is not
    already accounted for by the usual (fixed) predictor variables
    (e.g., age of participants). This correlation can arise for various
    reasons: For instance, responses to some stimuli from some
    participants might be more similar because the same person was
    measured twice (repeated measurements), participants come from the
    same neighborhood (clustering), or participants responded to the
    same stimulus (stimulus effects). Thus, modeling such correlations
    is important whenever the data has a clear structure, while the
    grouping variables can be hierarchically nested (e.g., grouping
    variables students and schools: each student belongs to exactly one
    school) or cross-classified (e.g., grouping variables students and
    math exercises: each student is presented with several math
    exercises). LMMs are used when the outcome variable is continuous
    and follows a normal distribution. They allow for the modeling of
    fixed effects, which capture the relationships between the usual
    predictors and the outcome, as well as random effects, which account
    for the different types of correlation structure and grouping
    effects. Random effects are typically assumed to follow a normal
    distribution with a mean of zero and a variance that quantifies the
    heterogeneity across groups. GLMMs extend the LMM framework to
    accommodate non-normally distributed continuous and categorical
    outcome variables. GLMMs involve a link function that connects the
    linear combination of predictor variables to the expected value of
    the outcome variable. The link function allows for modeling the
    relationship between predictors and the outcome in a non-linear way
    that is appropriate for the specific distribution family of the
    outcome variable. For example, think of an experiment with different
    design factors (e.g., picture positions, headline aesthetics)
    impacting the likelihood of users clicking on an online
    advertisement. The participants’ behavior is measured repeatedly
    over several sessions. The click patterns of participants in one
    session are likely to be correlated with their previous sessions and
    the outcome variable is binary (click/no click) for each session,
    which follows a binomial distribution.</p>
      </sec>
    </sec>
    <sec id="simulation-based-sample-size-planning-with-glmms">
      <title>Simulation-based sample size planning with GLMMs</title>
      <p>To our knowledge, existing approaches for sample size planning for
  GLMMs have exclusively focused on planning for power. Power analysis
  methods for multilevel models can be categorized into formula-based
  methods and simulation-based methods
  (<xref alt="Murayama et al., 2022" rid="ref-murayamaSummarystatisticsbasedPowerAnalysis2022" ref-type="bibr">Murayama
  et al., 2022</xref>). Formula-based methods rely on formulas to
  calculate power directly while simulation-based methods rely on
  repeatedly simulating data with a known true effect size and
  estimating power empirically (i.e., what percentage of simulated
  datasets produces a significant p-value). Available formula-based
  software packages for multilevel models often do not include GLMMs or
  are limited to very simple designs
  (<xref alt="Murayama et al., 2022" rid="ref-murayamaSummarystatisticsbasedPowerAnalysis2022" ref-type="bibr">Murayama
  et al., 2022</xref>;
  <xref alt="Westfall et al., 2014" rid="ref-westfallStatisticalPowerOptimal2014" ref-type="bibr">Westfall
  et al., 2014</xref>), making it necessary to build data simulations
  tailored specifically to the study design. A number of tutorials have
  been published describing how to perform such simulation-based power
  analysis for multilevel models
  (<xref alt="Arend &amp; Schäfer, 2019" rid="ref-arendStatisticalPowerTwolevel2019" ref-type="bibr">Arend
  &amp; Schäfer, 2019</xref>;
  <xref alt="Brysbaert &amp; Stevens, 2018" rid="ref-brysbaertPowerAnalysisEffect2018" ref-type="bibr">Brysbaert
  &amp; Stevens, 2018</xref>;
  <xref alt="DeBruine &amp; Barr, 2021" rid="ref-debruineUnderstandingMixedEffectsModels2021" ref-type="bibr">DeBruine
  &amp; Barr, 2021</xref>;
  <xref alt="Green &amp; MacLeod, 2016" rid="ref-greenSIMRPackagePower2016a" ref-type="bibr">Green
  &amp; MacLeod, 2016</xref>;
  <xref alt="Kain et al., 2015" rid="ref-kainPracticalGuidePower2015" ref-type="bibr">Kain
  et al., 2015</xref>;
  <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021" ref-type="bibr">Kumle
  et al., 2021</xref>;
  <xref alt="Lafit et al., 2021" rid="ref-lafitSelectionNumberParticipants2021" ref-type="bibr">Lafit
  et al., 2021</xref>;
  <xref alt="Zimmer et al., 2022" rid="ref-zimmerSampleSizePlanning2022" ref-type="bibr">Zimmer
  et al., 2022</xref>). However, many of these tutorials focus on linear
  mixed models (LMMs) and the common study designs (but see
  <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021" ref-type="bibr">Kumle
  et al., 2021</xref>, for a tutorial that also covers more advanced
  settings). This narrow focus provides limited guidance for researchers
  faced with more complex study designs, especially when little prior
  knowledge about plausible effect sizes is available (see the
  discussion in
  <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021" ref-type="bibr">Kumle
  et al., 2021</xref>). Simulation-based power analysis with GLMMs
  requires making a range of assumptions: The (conditional) distribution
  assumption specifies the distributional family for the outcome
  variable. Assumptions about the random effects include the assumption
  of normality (i.e., that the random effects follow a normal
  distribution) and the covariance structure among the random effects
  (i.e., if and how they are correlated). Making these decisions
  requires understanding the underlying assumptions of the model and
  ensuring they align with the characteristics of the data being
  analyzed. Existing tutorials often rely on heuristics for specifying
  variance components (e.g., the standard deviation of random
  intercepts) or assume that results from meta-analyses or data from
  pilot studies are available to determine plausible values for all
  model parameters. However, in practice, knowledge about those
  parameters from prior studies is often limited, which makes specifying
  assumptions a practical challenge (see the discussion in
  (<xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008" ref-type="bibr">Maxwell
  et al., 2008</xref>) and
  (<xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021" ref-type="bibr">Kumle
  et al., 2021</xref>)).</p>
      <p>INSERT TABLE 1 HERE!</p>
      <p>In Table 1, we give a short review of existing R packages that can
  be used for power analysis for GLMMs.</p>
    </sec>
    <sec id="when-to-use-tailored-data-simulation">
      <title>When to use tailored data simulation?</title>
      <p>Performing tailored simulation-based sample size planning is more
  complicated and time-consuming than using the existing software tools
  outlined in TABLE 1. The most important circumstances under which
  tailored simulation-based sample size planning is necessary are 1)
  complex study designs, 2) complex statistical hypotheses, 3) planning
  for precision, 4) no available prior studies or pilot data.</p>
      <p>Requirements of real-world studies are often more complex than the
  simplified designs assumed by many user-friendly software packages for
  sample size planning. One frequent issue in applied data analysis is
  missing data, and there can be various reasons for this
  (<xref alt="Little &amp; Rubin, 2014" rid="ref-littleStatisticalAnalysisMissing2014" ref-type="bibr">Little
  &amp; Rubin, 2014</xref>). For example, data can be missing completely
  at random (e.g., because an electronic measurement device randomly
  failed for some technical reasons). Alternatively, subjects might
  systematically drop out or produce missing data, but this dropout can
  be explained by some attributes also measured in the dataset (e.g.,
  older subjects have a higher probability to refuse answering a
  question on income). In a more complicated scenario, missing data in
  some variable is caused by the measured attribute itself (e.g.,
  wealthy people are more likely to refuse reporting their income).
  Moreover, many experimental designs contain conditions in which values
  of the predictor variables are missing by design. This can make data
  analysis more complicated because predictors have to be coded in
  specific ways that prevent the estimated GLMM from becoming
  unidentified. Whether missing data has an effect on the sample size
  planning depends on our theoretical assumptions on how the missingness
  is caused. However, it is often challenging to decide whether missing
  data can be safely ignored in the data analysis and sample size
  planning process based on a merely theoretical approach
  (<xref alt="Gomila &amp; Clark, 2022" rid="ref-gomilaMissingDataExperiments2022" ref-type="bibr">Gomila
  &amp; Clark, 2022</xref>). Tailored simulation-based approaches offer
  the possibility to include the assumed process of how data become
  missing in the data simulation, thereby determining the required
  sample based on simulated datasets that contain missing values (for an
  example, see
  <xref alt="Lane &amp; Hennes, 2018" rid="ref-lanePowerStrugglesEstimating2018" ref-type="bibr">Lane
  &amp; Hennes, 2018</xref>). As a byproduct, the simulated datasets can
  also be used to test whether the intended data analysis provides the
  expected (unbiased) results, despite the missing data. Although GLMMs
  can handle a large variety of outcome variables, researchers are
  becoming increasingly aware that many datasets might profit from even
  more sophisticated models. Common examples are zero-inflated outcomes,
  censoring, and nonlinear predictor effects that can be modeled with
  the R packages glmmTMB
  (<xref alt="Brooks et al., 2017" rid="ref-brooksGlmmTMBBalancesSpeed2017" ref-type="bibr">Brooks
  et al., 2017</xref>) or brms
  (<xref alt="Bürkner, 2018" rid="ref-burknerAdvancedBayesianMultilevel2018" ref-type="bibr">Bürkner,
  2018</xref>). Tailored simulation-based approaches do not share the
  same limitation than the existing software solutions for power
  analysis that focus exclusively on GLMMs. As long as there is a
  software package available to estimate the model of interest, it is
  always possible to perform tailored simulation-based sample size
  planning.</p>
      <p>The most common hypotheses tested in psychological research are of
  the type <inline-formula><alternatives><tex-math><![CDATA[H_0: \beta = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
  where <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
  is a slope or intercept of a regression model. However, many research
  questions in psychology actually require testing more complex
  statistical hypotheses. In the new era of preregistration and
  registered reports
  (<xref alt="Chambers &amp; Tzavella, 2022" rid="ref-chambersPresentFutureRegistered2022" ref-type="bibr">Chambers
  &amp; Tzavella, 2022</xref>), most research questions should be tested
  with directed hypotheses because good theories at least postulate
  whether some psychological effect of interest is positive or negative.
  Even better theories should be able to specify the smallest effect
  sizes of interest (SESOI) that must be exceeded if the effect has any
  practical relevance
  (<xref alt="Lakens, Scheel, et al., 2018" rid="ref-lakensEquivalenceTestingPsychological2018" ref-type="bibr">Lakens,
  Scheel, et al., 2018</xref>). In combination, this might require a
  test such as <inline-formula><alternatives><tex-math><![CDATA[H_0: \beta \leq 0.1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mi>β</mml:mi><mml:mo>≤</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  More elaborate research questions often require testing hypotheses
  that consist of a combination of model parameters, for example testing
  simple slopes
  (<xref alt="Preacher et al., 2006" rid="ref-preacherComputationalToolsProbing2006" ref-type="bibr">Preacher
  et al., 2006</xref>) with a hypothesis such as
  <inline-formula><alternatives><tex-math><![CDATA[H_0: \beta_0 + \beta_1 \leq 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  If the research question consists only of a single hypothesis of this
  sort, it might be possible to reduce the hypothesis to a single
  regression coefficient by clever coding and/or centering of predictor
  variables. However, interesting research questions often consist of
  combined hypotheses that consist of more than one separate statistical
  hypothesis (for a tutorial on contrast analysis in GLMMs, see
  <xref alt="Schad et al., 2020" rid="ref-schadHowCapitalizePriori2020" ref-type="bibr">Schad
  et al., 2020</xref>). For example, a combined null hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  might consist of two single null hypotheses
  <inline-formula><alternatives><tex-math><![CDATA[H_{01}: \beta_1 \leq 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives><tex-math><![CDATA[H_{02}: \beta_0 + \beta_1 \leq 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  For some research questions, the combined null hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  would be rejected if both <inline-formula><alternatives><tex-math><![CDATA[H_{01}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  <italic>AND</italic> <inline-formula><alternatives><tex-math><![CDATA[H_{02}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  are rejected. For other research questions, the combined null
  hypothesis <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  would be rejected if <inline-formula><alternatives><tex-math><![CDATA[H_{01}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  <italic>OR</italic> <inline-formula><alternatives><tex-math><![CDATA[H_{02}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  <italic>OR</italic> both are rejected. If the global hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  is combined with <italic>OR</italic>, the p-values of the single
  hypotheses must be corrected for multiple testing to avoid
  <inline-formula><alternatives><tex-math><![CDATA[\alpha]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>α</mml:mi></mml:math></alternatives></inline-formula>-inflation
  for the global hypothesis
  (<xref alt="Dmitrienko &amp; D’Agostino, 2013" rid="ref-dmitrienkoTraditionalMultiplicityAdjustment2013" ref-type="bibr">Dmitrienko
  &amp; D’Agostino, 2013</xref>). However, if the global hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  is combined with <italic>AND</italic>, a correction for multiple
  testing is not necessary but rather a mistake that unnecessarily
  reduces the power of the global HT. None of the software packages for
  sample size planning in table X can handle combined hypotheses as
  discussed here and only some can handle directed hypotheses. In
  contrast, our case study will demonstrate how we can test directed
  combined hypotheses with tailored simulation-based sample size
  planning.</p>
      <p>Although planning for precision
  (<xref alt="Cumming, 2014" rid="ref-cummingNewStatisticsWhy2014" ref-type="bibr">Cumming,
  2014</xref>;
  <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
  2022a</xref>;
  <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008" ref-type="bibr">Maxwell
  et al., 2008</xref>) has been increasingly discussed as a useful
  strategy for empirical research, all available software packages for
  sample size planning with GLMMs are based on power analysis.
  Therefore, researchers that want to want to apply an estimation
  strategy in their studies, without testing any statistical hypotheses,
  currently cannot use the software packages outlined in TABLE 1.
  However, tailored simulation-based sample size planning can easily
  handle the planning for precision approach
  (<xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008" ref-type="bibr">Maxwell
  et al., 2008</xref>). The only change in procedure is that instead of
  computing HTs for each simulated dataset and estimating statistical
  power across repetitions, CIs are computed for each simulated dataset,
  and the expected width is estimated.</p>
      <p>All frameworks for sample size planning require the user to make
  assumptions about the expected effect size. Assuming the true effect
  is of this size (or greater), one can compute the (minimum) power of a
  HT or the (maximum) expected width of a CI. Existing software packages
  for sample size planning for GLMMs usually require to provide the
  assumed effect in the unit of some standardized measure of effect
  size. When the researcher has access to similar studies or pilot data,
  providing such standardized effect sizes is feasible. However, note
  that choosing effect sizes based on small pilot studies is generally
  not recommended, as those estimates can be heavily biased
  (<xref alt="Albers &amp; Lakens, 2018" rid="ref-albersWhenPowerAnalyses2018a" ref-type="bibr">Albers
  &amp; Lakens, 2018</xref>;
  <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
  2022a</xref>). Providing an informed standardized effect size can be
  an almost impossible challenge when no prior studies of pilot data are
  available. This problem is further exacerbated by the fact that GLMMs
  are so flexible that general heuristics of what should be considered a
  small effect do not exist or are difficult to defend. In our
  experience, using domain knowledge to construct a tailored data
  simulation is the only solution to determine plausible effect sizes in
  the absence of prior evidence. It would be possible to use these
  tailored simulations to extract plausible values for standardized
  effect sizes that could then be inserted in existing software packages
  for sample size planning. However, we would argue that when tailored
  data simulations necessary to determine effect sizes anyway,
  performing the whole sample size planning in a customized way is
  preferred over using the existing software packages.</p>
    </sec>
    <sec id="general-steps-in-tailored-simulation-based-sample-size-planning">
      <title>General steps in tailored simulation-based sample size
  planning</title>
      <p>Although the details differ depending on the specific study
  characteristics, each tailored simulation-based sample size planning
  requires a series of steps and decisions. We will introduce each step
  in a theoretical section, followed by the practical application based
  on a hypothetical case study. All code in this manuscript and
  simulation results are available in the project’s repository on the
  Open Science Framework
  (<ext-link ext-link-type="uri" xlink:href="https://osf.io/dhwf4/">https://osf.io/dhwf4/</ext-link>).</p>
      <sec id="step-1-define-the-estimand">
        <title>Step 1: Define the estimand</title>
        <sec id="theory">
          <title>THEORY</title>
          <p>The first step in every research process should be a clear
      definition of the theoretical <italic>estimand</italic>
      (<xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021" ref-type="bibr">Lundberg
      et al., 2021</xref>), i.e. the theoretical quantity which is
      necessary to answer a specific research question. The estimand
      consists of a quantity, that can be described for each unit under
      investigation and a clear definition of the target population, for
      which the quantity is of interest. For example, an estimand might
      be the probability that a clinical psychologists makes the correct
      diagnosis for a psychiatric patient with major depression,
      averaged across all clinical psychologists and depressed patients
      in psychiatric institutions in Germany.</p>
          <p>The estimand should always be defined outside of any
      statistical model, because there are usually a range of
      statistical methods that can be used to estimate the same
      estimand, depending on the study design (e.g., a randomized
      experiment) that will produce the observed data in the planned
      study. For many common research questions in psychology, the
      estimand can be expressed as a statistical quantity that can be
      estimated with a regression model, for example a single
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      coefficient. However, this is not possible for all estimands,
      which is why the literature discusses many estimation strategies
      beyond regression
      (<xref alt="Deffner et al., 2022" rid="ref-deffnerCausalFrameworkCrossCultural2022" ref-type="bibr">Deffner
      et al., 2022</xref>;
      <xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021" ref-type="bibr">Lundberg
      et al., 2021</xref>).</p>
        </sec>
        <sec id="practice">
          <title>PRACTICE</title>
          <p>In the present hypothetical case study, we consider the
      effectiveness of feedback provided by an artificial intelligence
      (AI) embedded in a diagnostic decision support system. The context
      is a clinical setting, where expert radiologists and students
      under training must detect bleeding based on head scans from
      computer tomography (CT). In the investigated AI-enabled
      diagnostic decision support system, an AI model can provide
      initial diagnostic advice, which can be used as guidance by the
      humans who are required to make the final diagnostic decision. The
      research goal is to validate the effectiveness of the AI-enabled
      advice. We consider the AI-enabled advice as effective, if the
      following pattern holds, which we will first describe
      verbally:</p>
          <p>
            <italic>We expect that for BOTH expert radiologists and medical
      students, correct AI-advice leads to a higher probability of
      accurately diagnosing a CT scan compared to no AI-advice
      presented, AND, we expect that for BOTH experts and non-experts,
      incorrect advice leads to a lower probability of accurately
      diagnosing a CT scan compared to no advice presented.</italic>
          </p>
          <p>It becomes clear that our estimand consists of four comparisons
      between experimental conditions
      (<xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021" ref-type="bibr">Lundberg
      et al., 2021</xref>). However, the verbal description is still
      somewhat vague, which is why we try to give a more precise
      expression for each comparison:</p>
          <p>
            <disp-formula>
              <alternatives>
                <tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{correct advice, average expert, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{no advice, average expert, average scan})
      \end{aligned}
      ]]></tex-math>
                <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                  <mml:mtable>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mtext mathvariant="normal">correct advice, average expert, average scan</mml:mtext>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mspace width="1.0em"/>
                        <mml:mo>−</mml:mo>
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mtext mathvariant="normal">no advice, average expert, average scan</mml:mtext>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:math>
              </alternatives>
            </disp-formula>
          </p>
          <p>
            <disp-formula>
              <alternatives>
                <tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{no advice, average expert, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{wrong advice, average expert, average scan})
      \end{aligned}
      ]]></tex-math>
                <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                  <mml:mtable>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mtext mathvariant="normal">no advice, average expert, average scan</mml:mtext>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mspace width="1.0em"/>
                        <mml:mo>−</mml:mo>
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mtext mathvariant="normal">wrong advice, average expert, average scan</mml:mtext>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:math>
              </alternatives>
            </disp-formula>
            <disp-formula>
              <alternatives>
                <tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{correct advice, average student, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{no advice, average student, average scan})
      \end{aligned}
      ]]></tex-math>
                <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                  <mml:mtable>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mtext mathvariant="normal">correct advice, average student, average scan</mml:mtext>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mspace width="1.0em"/>
                        <mml:mo>−</mml:mo>
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mtext mathvariant="normal">no advice, average student, average scan</mml:mtext>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:math>
              </alternatives>
            </disp-formula>
          </p>
          <p><disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{no advice, average student, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{wrong advice, average student, average scan})
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtext mathvariant="normal">correct diagnosis</mml:mtext><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mtext mathvariant="normal">no advice, average student, average scan</mml:mtext><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mspace width="1.0em"/><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtext mathvariant="normal">correct diagnosis</mml:mtext><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mtext mathvariant="normal">wrong advice, average student, average scan</mml:mtext><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      For example, the first expression is concerned with the difference
      between the probability that a correct diagnosis is made if
      correct AI-advice is presented and the probability that a correct
      diagnosis is made if no AI-advice is presented. This contrast is
      quantified for a hypothetical <italic>typical</italic> expert and
      a <italic>typical</italic> scan, where <italic>typical</italic> is
      usually defined as an average score on all attributes of the
      expert or scan.<xref ref-type="fn" rid="fn1">1</xref>. To complete
      our definition of the estimand, we have to define our target
      population that consists of persons, stimuli, and AI-advice: With
      respect to persons, we are only interested in expert radiologists
      and medical students at German universities. With respect to
      stimuli, we are only interested in the head CT scans made from
      subjects that do or do not suffer from intracerebral hemorrhage.
      Lastly, we are only interested in AI-advice given by a specific
      AI-enabled diagnostic decision support system.</p>
          <p>Although the estimand is initially defined outside of any
      statistical model, it is only useful if we find a way to estimate
      it based on observed data. For our exemplary research question, it
      is possible to construct an experimental study, where all
      participants are confronted with the same set of head CT scans,
      but the kind of AI-advice given for each scan is randomly assigned
      within participants. This random intervention allows us to produce
      an empirical estimate of our estimand, although, in reality, each
      person receives only one kind of AI-advice (correct advice, wrong
      advice, no advice) for each scan. We will see later how each of
      the probability expressions in our estimand can be modeled with
      the same GLMM. Estimating this GLMM based on the data observed in
      our planned study will produce an estimate for each probability,
      and these estimates can then be combined to compute an estimate
      for each of the four probability contrasts. For pedagogical
      reasons, we will skip the concrete definition of our estimate
      until we have discussed how to simulate data based on a concrete
      GLMM in the next section.</p>
        </sec>
      </sec>
      <sec id="step-2-simulate-the-data-generating-process">
        <title>Step 2: Simulate the data generating process</title>
        <sec id="theory-1">
          <title>THEORY</title>
          <p>When the estimand has been defined, the next step in the
      research process is to write code that simulates the (assumed)
      data generating process of the planned study. This requires
      specifying a generative process for all predictor variables used
      in the final data analysis. While such assumptions can be quite
      challenging for observational studies or continuous predictor
      variables, this is less of a problem for experimental studies with
      only categorical predictor variables. When all predictor variables
      have been simulated, one can use the structure of a suitable GLMM
      to simulate the dependent variable. To simulate the GLMM, one
      requires plausible values for all model parameters. We will
      discuss strategies on how these values can be obtained later.
      Because we have full control over the data generating process in a
      tailored simulation, it is possible to model specific aspects of
      the planned study, like data missing by design or assuming that
      some subjects might drop out. The quality of the results of the
      sample size planning crucially depends on the plausibility of the
      simulated data generating process. However, we would argue that
      even a strongly simplified data generating process (e.g. only a
      small number of interaction effects; only random intercepts and no
      random slopes; assuming that data is missing completely at random)
      can yield informative results.</p>
        </sec>
        <sec id="practice-1">
          <title>PRACTICE</title>
          <p>In our case study, we simulate data for an experiment where the
      diagnostic performance of users of an AI-enabled diagnostic
      decision support system will be evaluated. Radiologists (task
      experts) and students/interns (non experts) review a series of
      head computer tomography (CT) scans to assess the presence of a
      bleeding. An AI model provides initial diagnostic advice to assist
      their decision-making. In the control condition, no AI advice is
      presented. When AI advice is given, this advice can be either
      correct or incorrect. The type of advice (no advice, wrong advice,
      correct advice) is randomized within subjects across brain scans.
      After reviewing a CT scan, participants deliver a medical
      diagnosis (bleeding or no bleeding), which may be either accurate
      or inaccurate. This experimental design introduces some missing
      values by design since the advice is neither correct nor incorrect
      when no advice is present, which must be taken into account when
      simulating and analyzing the data. In this example, recruiting
      task experts (i.e., radiologists) is more challenging due to their
      limited availability, while non-experts (i.e., students/interns)
      are more readily accessible. The goal of simulation-based sample
      size planning is to determine how many task experts and
      non-experts must be recruited to achieve sufficient statistical
      power or precision in the planned experiment.</p>
          <sec id="our-specific-glmm">
            <title>Our specific GLMM</title>
            <p>In a GLMM, the expected value of the dependent variable
        <inline-formula><alternatives><tex-math><![CDATA[Y]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
        conditioned on the vector of predictor variables
        <inline-formula><alternatives><tex-math><![CDATA[\mathbf{X}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐗</mml:mi></mml:math></alternatives></inline-formula>
        and random effects <inline-formula><alternatives><tex-math><![CDATA[\mathbf{U}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐔</mml:mi></mml:math></alternatives></inline-formula>,
        transformed by a link function <inline-formula><alternatives><tex-math><![CDATA[g()]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
        is modeled as a linear combination
        <inline-formula><alternatives><tex-math><![CDATA[\eta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>η</mml:mi></mml:math></alternatives></inline-formula>
        of the predictor variables <inline-formula><alternatives><tex-math><![CDATA[\mathbf{X}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐗</mml:mi></mml:math></alternatives></inline-formula>,
        the random effects <inline-formula><alternatives><tex-math><![CDATA[\mathbf{U}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐔</mml:mi></mml:math></alternatives></inline-formula>
        and the model parameters <inline-formula><alternatives><tex-math><![CDATA[\mathbf{\beta}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝛃</mml:mi></mml:math></alternatives></inline-formula>
        (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021" ref-type="bibr">Fahrmeir
        et al., 2021</xref>): <disp-formula><alternatives><tex-math><![CDATA[
        g(E(Y|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u})) = \eta
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>𝐗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐱</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐮</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>η</mml:mi></mml:mrow></mml:math></alternatives></disp-formula>
        Equivalently, the conditional expected value is modeled as the
        linear combination <inline-formula><alternatives><tex-math><![CDATA[\eta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>η</mml:mi></mml:math></alternatives></inline-formula>,
        transformed by the inverse link function
        <inline-formula><alternatives><tex-math><![CDATA[g^{-1}()]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>:
        <disp-formula><alternatives><tex-math><![CDATA[
        E(Y|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u}) = g^{-1}(\eta)
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>𝐗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐱</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐮</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
        If the dependent variable (i.e., diagnostic decision)
        <inline-formula><alternatives><tex-math><![CDATA[Y]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
        is a binary variable with values <inline-formula><alternatives><tex-math><![CDATA[0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0</mml:mn></mml:math></alternatives></inline-formula>
        (i.e., inaccurate), or <inline-formula><alternatives><tex-math><![CDATA[1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>1</mml:mn></mml:math></alternatives></inline-formula>
        (i.e., accurate), the conditional expected value is equivalent
        to the probability: <disp-formula><alternatives><tex-math><![CDATA[
        P_{si} := P(Y = 1|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u})
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>:=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>𝐗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐱</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐮</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
        In our case study, <inline-formula><alternatives><tex-math><![CDATA[P_{si}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>
        is the conditional probability that subject
        <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
        gives the correct response to item (i.e., CT scan)
        <inline-formula><alternatives><tex-math><![CDATA[i]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula>.</p>
            <p>In such a setting, we model this probability as
        <disp-formula><alternatives><tex-math><![CDATA[
        P_{si} = \text{inverse\_logit}(\eta_{si})
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
        with the inverse-logit link <inline-formula><alternatives><tex-math><![CDATA[g^{-1}(\eta_{si}) = inverse\_logit(\eta_{si}) = \frac{exp(\eta_{si})}{1 + exp(\eta_{si})}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>
        or equivalently <disp-formula><alternatives><tex-math><![CDATA[
        \text{logit}(P_{si}) = \eta_{si}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:mtext mathvariant="normal">logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></disp-formula>
        with the logit link <inline-formula><alternatives><tex-math><![CDATA[g(P_{si}) = \text{logit}(P_{si}) = \text{ln} (\frac{P_{si}}{1 - P_{si}})]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">ln</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mfrac><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
            <p>In our case study, the probability of making an accurate
        diagnostic decision is assumed to depend on the predictors:</p>
            <list list-type="bullet">
              <list-item>
                <p><inline-formula><alternatives><tex-math><![CDATA[advice\_present_{si}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
            whether subject <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
            was presented with AI advice (1) or not (0) when asked to
            assess item <inline-formula><alternatives><tex-math><![CDATA[i]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula></p>
              </list-item>
              <list-item>
                <p><inline-formula><alternatives><tex-math><![CDATA[advice\_correct_{si}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
            whether this advice was correct (1) or not (0)</p>
              </list-item>
              <list-item>
                <p><inline-formula><alternatives><tex-math><![CDATA[expert_s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
            whether subject <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
            was a task expert (1) or not (0)</p>
              </list-item>
            </list>
            <p>and the random effects:</p>
            <list list-type="bullet">
              <list-item>
                <p><inline-formula><alternatives><tex-math><![CDATA[u_{0s}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>:
            the deviation of subject <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
            from the average ability to solve an item (i.e., CT scan)
            with average difficulty; assumed to be distributed as
            <inline-formula><alternatives><tex-math><![CDATA[u_{0s} \sim N(0, \sigma_S^2)]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
              </list-item>
              <list-item>
                <p><inline-formula><alternatives><tex-math><![CDATA[u_{0i}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>:
            the deviation of item (i.e., CT scan)
            <inline-formula><alternatives><tex-math><![CDATA[i]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula>
            from the average difficulty to be solved by a person with
            average ability; assumed to be distributed as
            <inline-formula><alternatives><tex-math><![CDATA[u_{0i} \sim N(0, \sigma_I^2)]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
              </list-item>
            </list>
            <p>In total, we assume the model <disp-formula><alternatives><tex-math><![CDATA[
        \begin{aligned}
        \text{logit}[P_{si}] =\ (&\beta_0 + u_{0s} + u_{0i}) + \\
        &\beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s + \\
        &\beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}
        \end{aligned}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mtext mathvariant="normal">logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.222em"/><mml:mo stretchy="false" form="prefix">(</mml:mo></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
        or equivalently <disp-formula><alternatives><tex-math><![CDATA[
        \begin{aligned}
        P_{si} = \text{inverse\_logit}[&(\beta_0 + u_{0s} + u_{0i}) + \\
        &\beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s + \\
        &\beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}]
        \end{aligned}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mo stretchy="false" form="prefix">[</mml:mo></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
        with model parameters <inline-formula><alternatives><tex-math><![CDATA[\beta_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_e]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_a]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_c]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_{ea}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_{ec}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>.</p>
            <p>In the GLMM literature, this would be called a binomial GLMM
        with two random intercepts (for subjects and items), two level-1
        predictors (<inline-formula><alternatives><tex-math><![CDATA[advice\_present]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[advice\_correct]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>),
        one level-2 predictor (<inline-formula><alternatives><tex-math><![CDATA[expert]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>)
        and two cross-level interactions (<inline-formula><alternatives><tex-math><![CDATA[expert \cdot advice\_present]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[expert \cdot advice\_correct]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>).
        To limit complexity, we do not consider random slopes,
        additional predictors or higher-level interactions.</p>
          </sec>
          <sec id="simulation-function-in-r">
            <title>Simulation function in R</title>
            <p>The following R function simulates a full dataset structured
        according to the design of our case study.</p>
            <code language="r script">simulate &lt;- function(n_subjects = 100, n_items = 50,
  b_0 = 0.847, b_e = 1.350, b_a = -1.253, b_c = 2.603,
  b_ea = 0.790, b_ec = -1.393,
  sd_u0s = 0.5, sd_u0i = 0.5, ...){
  require(dplyr)
  require(faux)
  # simulate design
  dat &lt;- add_random(subject = n_subjects, item = n_items) |&gt;
    add_between("subject", expert = c(1, 0), .prob = c(0.25, 0.75)) |&gt;
    mutate(advice_present = rbinom(n(), 1, prob = 2/3)) |&gt;
    mutate(advice_correct = if_else(advice_present == 1L, 
                                    rbinom(n(), 1L, prob = 0.8), 0L)) |&gt;
    # add random effects
    add_ranef("subject", u0s = sd_u0s) |&gt;
    add_ranef("item", u0i = sd_u0i) |&gt;
    # compute dependent variable
    mutate(linpred = b_0 + u0i + u0s +
        b_e * expert + b_a * advice_present + b_c * advice_correct +
        b_ea * expert * advice_present + b_ec * expert * advice_correct) |&gt;
    mutate(y_prob = plogis(linpred)) |&gt;
    mutate(y_bin = rbinom(n = n(), size = 1, prob = y_prob))
  dat
}</code>
            <p>In the first four lines of the function definition, we set
        some default parameter values (which we will explain in the next
        section) and load the packages we use to manipulate and simulate
        data.<xref ref-type="fn" rid="fn2">2</xref> In our case study,
        each subject (<monospace>n_subjects</monospace> in total) is
        assumed to respond to each item (i.e., CT scan;
        <monospace>n_items</monospace> in total). Thus, the
        <monospace>add_random</monospace> command creates a
        fully-crossed <monospace>data.frame</monospace> with
        <monospace>n_subjects</monospace> <inline-formula><alternatives><tex-math><![CDATA[\times]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>×</mml:mi></mml:math></alternatives></inline-formula>
        <monospace>n_items</monospace> rows. We add a between-subject
        effect with the <monospace>add_between</monospace> command,
        simulating that about <inline-formula><alternatives><tex-math><![CDATA[25\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>25</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
        of subjects are experts. The next two lines simulate that in
        <inline-formula><alternatives><tex-math><![CDATA[\frac{2}{3}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mfrac><mml:mn>2</mml:mn><mml:mn>3</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>
        of trials, subjects will be presented with AI advice, and if
        advice is presented, the advice will be correct in about
        <inline-formula><alternatives><tex-math><![CDATA[80\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>80</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
        of cases (the variable <monospace>advice_correct</monospace> is
        always 0 when no advice is presented). Next, we simulate one
        random effect for each subject (<monospace>u0s</monospace>) and
        for each item (<monospace>u0i</monospace>). As assumed by
        standard GLMMs, the <monospace>add_ranef</monospace> function
        draws the random effects from a normal distribution with a mean
        0 and a standard deviation specified by the user. With all
        design variables done, we are ready to simulate our model
        equation outlined in the last section. The linear predictor
        variable <monospace>linpred</monospace>
        (<inline-formula><alternatives><tex-math><![CDATA[\eta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>η</mml:mi></mml:math></alternatives></inline-formula>
        in the GLMM model equations) combines the predictor variables,
        random effects, and model parameters as assumed by our model. We
        then transform the linear predictor with the inverse-link
        function to compute <monospace>y_prob</monospace>, the
        probability that the subject correctly solved the item (in R,
        the inverse-logit link is computed with
        <monospace>plogis</monospace> and the logit link with
        <monospace>qlogis</monospace>). In the final step, we simulate
        the binary dependent variable <monospace>y_bin</monospace>
        (i.e., whether the subject makes an accurate diagnostic decision
        for the CT scan) by – for each trial – drawing from a Bernoulli
        distribution with success probability
        <monospace>y_prob</monospace>.</p>
          </sec>
        </sec>
      </sec>
      <sec id="step-3-specify-the-population-parameters">
        <title>Step 3: Specify the population parameters</title>
        <sec id="theory-2">
          <title>THEORY</title>
          <p>In the absence of previous studies with the same design or
      pilot data, researchers require strategies on how to specify the
      population parameters used in their data simulation. Population
      parameters are all model parameters estimated in a GLMM, in
      particular the regression coefficients of the fixed effects and
      the standard deviation of the random effects (and the correlation
      between random effects in more complicated models). In contrast to
      non-hierarchical linear regression, common heuristics based on
      standardized effect sizes are less useful or not even available
      for GLMMs. Our strategies to specify population parameters will
      require access to domain knowledge from domain experts. Because
      most domain knowledge can only be expressed in unstandardized
      measurement units of a specific application, we argue that
      unstandardized effect sizes are usually preferable over
      standardized effect sizes for tailored simulation-based sample
      size planning. The basic idea of all strategies is how the data
      generating process implied by certain values of population
      parameters can be quantified or visualized in an intuitive way
      that enables a calibration of population parameters based on the
      available knowledge of domain experts.</p>
          <p>Although we use frequentist model estimation in our tutorial,
      many strategies described in this chapter are inspired by research
      on how to monitor the plausibility of model assumptions in applied
      Bayesian statistics
      (<xref alt="Gelman et al., 2020" rid="ref-gelmanBayesianWorkflow2020" ref-type="bibr">Gelman
      et al., 2020</xref>).</p>
        </sec>
        <sec id="practice-2">
          <title>PRACTICE</title>
          <p>When introducing the simulation function for our case study, we
      have used theoretically plausible values as defaults for all model
      parameters (<inline-formula><alternatives><tex-math><![CDATA[\beta_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_e]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_a]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_c]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_{ea}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_{ec}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>),
      but have not talked about where these numbers came from.</p>
          <p>The starting point for all parameter values in our present case
      study were based on results from distantly related study designs
      in the literature. Additionally, we had repeated discussions with
      our affiliated domain experts in radiology to check whether our
      assumptions seem plausible.</p>
          <p>We now outline our main strategy to determine plausible
      parameter values for the fixed effects
      (<inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters): Unfortunately, the model parameters in a binomial
      GLMM are hard to interpret in isolation because 1) the
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters are connected to the modeled probability via the
      non-linear inverse-logit link, and 2) we also have to consider the
      random effects. The most simple interpretation, that allows us to
      ignore the random effects for now, works by imagining a subject
      with average ability (<inline-formula><alternatives><tex-math><![CDATA[u_{0s} = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>)
      responding to an item (i.e., CT scan) with average difficulty
      (<inline-formula><alternatives><tex-math><![CDATA[u_{0i} = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).
      Then the model implied probability that such a person solves such
      an item accurately is given by:</p>
          <p><disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      P(Y=1|\mathbf{X=x}, \mathbf{U} = \mathbf{0}) = \\
      = \text{inverse\_logit}[&\beta_0 + \beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s + \\
      &\beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}]
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mrow><mml:mi>𝐗</mml:mi><mml:mo mathvariant="bold">=</mml:mo><mml:mi>𝐱</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mn>𝟎</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mo stretchy="false" form="prefix">[</mml:mo></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      In fact, we would only need the full equation if the subject is an
      expert and correct advice is presented. In all other experimental
      conditions, some terms drop from the equation because they are
      multiplied by <inline-formula><alternatives><tex-math><![CDATA[0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0</mml:mn></mml:math></alternatives></inline-formula>.
      For example, the probability that a non-expert with average
      ability solves an item with average difficulty when no advice is
      presented, only requires the intercept:
      <disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      P(Y=1| advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) = \\
      = \text{inverse\_logit}[\beta_0]
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      We can revert this perspective by choosing plausible probability
      values based on domain knowledge and deriving the parameter values
      implied by these probabilities for each experimental
      condition.</p>
          <fig id="tbl-probtable">
            <caption>
              <p>Table 1: Assumed probabilities that an average
        subject solves an average item in each experimental
        condition.</p>
            </caption>
            <table-wrap>
              <table>
                <colgroup>
                  <col width="16%"/>
                  <col width="33%"/>
                  <col width="51%"/>
                </colgroup>
                <thead>
                  <tr>
                    <th align="left">Experimental condition</th>
                    <th align="left">
                      <inline-formula>
                        <alternatives>
                          <tex-math><![CDATA[P(Y=1 \mid \mathbf{X=x}, \mathbf{U} = \mathbf{0})]]></tex-math>
                          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                            <mml:mrow>
                              <mml:mi>P</mml:mi>
                              <mml:mrow>
                                <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                <mml:mi>Y</mml:mi>
                                <mml:mo>=</mml:mo>
                                <mml:mn>1</mml:mn>
                                <mml:mo>∣</mml:mo>
                                <mml:mrow>
                                  <mml:mi>𝐗</mml:mi>
                                  <mml:mo mathvariant="bold">=</mml:mo>
                                  <mml:mi>𝐱</mml:mi>
                                </mml:mrow>
                                <mml:mo>,</mml:mo>
                                <mml:mi>𝐔</mml:mi>
                                <mml:mo>=</mml:mo>
                                <mml:mn>𝟎</mml:mn>
                                <mml:mo stretchy="true" form="postfix">)</mml:mo>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:math>
                        </alternatives>
                      </inline-formula>
                    </th>
                    <th align="left">Implied equation</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td align="left">no advice, no expert</td>
                    <td align="left">0.70</td>
                    <td align="left">
                      <inline-formula>
                        <alternatives>
                          <tex-math><![CDATA[logit(0.70) = \beta_0]]></tex-math>
                          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                <mml:mn>0.70</mml:mn>
                                <mml:mo stretchy="true" form="postfix">)</mml:mo>
                              </mml:mrow>
                              <mml:mo>=</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                            </mml:mrow>
                          </mml:math>
                        </alternatives>
                      </inline-formula>
                    </td>
                  </tr>
                  <tr>
                    <td align="left">no advice, expert</td>
                    <td align="left">0.90</td>
                    <td align="left">
                      <inline-formula>
                        <alternatives>
                          <tex-math><![CDATA[logit(0.90) = \beta_0 + \beta_e]]></tex-math>
                          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                <mml:mn>0.90</mml:mn>
                                <mml:mo stretchy="true" form="postfix">)</mml:mo>
                              </mml:mrow>
                              <mml:mo>=</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>e</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:math>
                        </alternatives>
                      </inline-formula>
                    </td>
                  </tr>
                  <tr>
                    <td align="left">false advice, no expert</td>
                    <td align="left">0.40</td>
                    <td align="left">
                      <inline-formula>
                        <alternatives>
                          <tex-math><![CDATA[logit(0.40) = \beta_0 + \beta_a]]></tex-math>
                          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                <mml:mn>0.40</mml:mn>
                                <mml:mo stretchy="true" form="postfix">)</mml:mo>
                              </mml:mrow>
                              <mml:mo>=</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>a</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:math>
                        </alternatives>
                      </inline-formula>
                    </td>
                  </tr>
                  <tr>
                    <td align="left">false advice, expert</td>
                    <td align="left">0.85</td>
                    <td align="left">
                      <inline-formula>
                        <alternatives>
                          <tex-math><![CDATA[logit(0.85) = \beta_0 + \beta_e + \beta_{a} + \beta_{ea}]]></tex-math>
                          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                <mml:mn>0.85</mml:mn>
                                <mml:mo stretchy="true" form="postfix">)</mml:mo>
                              </mml:mrow>
                              <mml:mo>=</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>e</mml:mi>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>a</mml:mi>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mrow>
                                  <mml:mi>e</mml:mi>
                                  <mml:mi>a</mml:mi>
                                </mml:mrow>
                              </mml:msub>
                            </mml:mrow>
                          </mml:math>
                        </alternatives>
                      </inline-formula>
                    </td>
                  </tr>
                  <tr>
                    <td align="left">correct advice, no expert</td>
                    <td align="left">0.90</td>
                    <td align="left">
                      <inline-formula>
                        <alternatives>
                          <tex-math><![CDATA[logit(0.90) = \beta_0 + \beta_a + \beta_c]]></tex-math>
                          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                <mml:mn>0.90</mml:mn>
                                <mml:mo stretchy="true" form="postfix">)</mml:mo>
                              </mml:mrow>
                              <mml:mo>=</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>a</mml:mi>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>c</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:math>
                        </alternatives>
                      </inline-formula>
                    </td>
                  </tr>
                  <tr>
                    <td align="left">correct advice, expert</td>
                    <td align="left">0.95</td>
                    <td align="left">
                      <inline-formula>
                        <alternatives>
                          <tex-math><![CDATA[logit(0.95) = \beta_0 + \beta_e + \beta_a + \beta_c + \beta_{ea} + \beta_{ec}]]></tex-math>
                          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                            <mml:mrow>
                              <mml:mi>l</mml:mi>
                              <mml:mi>o</mml:mi>
                              <mml:mi>g</mml:mi>
                              <mml:mi>i</mml:mi>
                              <mml:mi>t</mml:mi>
                              <mml:mrow>
                                <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                <mml:mn>0.95</mml:mn>
                                <mml:mo stretchy="true" form="postfix">)</mml:mo>
                              </mml:mrow>
                              <mml:mo>=</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mn>0</mml:mn>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>e</mml:mi>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>a</mml:mi>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mi>c</mml:mi>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mrow>
                                  <mml:mi>e</mml:mi>
                                  <mml:mi>a</mml:mi>
                                </mml:mrow>
                              </mml:msub>
                              <mml:mo>+</mml:mo>
                              <mml:msub>
                                <mml:mi>β</mml:mi>
                                <mml:mrow>
                                  <mml:mi>e</mml:mi>
                                  <mml:mi>c</mml:mi>
                                </mml:mrow>
                              </mml:msub>
                            </mml:mrow>
                          </mml:math>
                        </alternatives>
                      </inline-formula>
                    </td>
                  </tr>
                </tbody>
              </table>
            </table-wrap>
          </fig>
          <p><xref alt="Table 1" rid="tbl-probtable">Table 1</xref> shows
      our set of assumptions concerning the probability that an average
      subject solves an average item for each experimental condition, as
      well as the corresponding equations implied by the model. The
      table can be used to compute the implied values for the
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters, starting with the first equation and reinserting the
      computed <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      values in all following equations (<monospace>b_0</monospace>
      stands for the intercept <inline-formula><alternatives><tex-math><![CDATA[\beta_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>,
      <monospace>b_e</monospace> for the slope
      <inline-formula><alternatives><tex-math><![CDATA[\beta_e]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      and so on):</p>
          <code language="r script">b_0 &lt;- qlogis(0.7)
b_e &lt;- qlogis(0.9) - b_0
b_a &lt;- qlogis(0.4) - b_0
b_ea &lt;- qlogis(0.85) - b_0 - b_e - b_a
b_c &lt;- qlogis(0.9) - b_0 - b_a
b_ec &lt;- qlogis(0.95) - b_0 - b_e - b_a - b_c - b_ea
c(b_0 = b_0, b_e = b_e, b_a = b_a, b_c = b_c, b_ea = b_ea, b_ec = b_ec)</code>
          <preformat>       b_0        b_e        b_a        b_c       b_ea       b_ec 
 0.8472979  1.3499267 -1.2527630  2.6026897  0.7901394 -1.3928518 </preformat>
          <p>It is always possible to double-check these computations by
      transforming the parameter values back to probabilities, e.g. 
      <disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      P(Y=1|expert = 1, advice\_present = 1, advice\_correct = 1, u_{0s} = 0, u_{0i} = 0) = \\
      = inverse\_logit[\beta_0 + \beta_e + \beta_a + \beta_c + \beta_{ea} + \beta_{ec}]
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
          <p>which we compute in R as:</p>
          <code language="r script">plogis(b_0 + b_e + b_a + b_c + b_ea + b_ec)</code>
          <preformat>[1] 0.95</preformat>
          <p>This leaves us with the question on how to determine plausible
      values for the two remaining model parameters
      (<inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>)
      that are the standard deviations for the random intercepts. For
      this, we introduce two more strategies.</p>
        </sec>
        <sec id="insightful-descriptive-statistics">
          <title>Insightful descriptive statistics</title>
          <sec id="theory-3">
            <title>THEORY</title>
            <p>The mathematical structure of GLMMs determines which patterns
        in data would be produced by the model, if a specific set of
        values for the population parameters would be specified. The
        knowledge of how to simulate from a GLMM enables us to compute
        insightful descriptive statistics that can be compared to
        available domain knowledge much more easily than the opaque
        values of model parameters. For example, domain experts might
        not be able to directly choose plausible values for the
        coefficients in a logistic regression model (which are measured
        on the log-odds scale). However, they should be able to reason
        about the expected ratio of the binary dependent variable in
        different experimental conditions, i.e. which relative frequency
        they expect to observe (on average). The job of the analyst who
        is familiar with the mathematical structure of the GLMM is to
        produce the model implied value of the insightful descriptive
        statistic expected by the domain expert. Although insightful
        descriptive statistics usually depend on the model parameters in
        a non-linear way, it is not necessary to solve the exact
        relationship mathematically. Instead, one can simply adjust the
        population parameters by trial and error until the model implied
        quantities produce the desired result.</p>
          </sec>
          <sec id="practice-3">
            <title>PRACTICE</title>
            <p>In the last section, we showed how we can derive the model
        implied probability that a subject with average ability solves
        an item with average difficulty for each experimental condition.
        Although these derivations are straightforward, it is important
        not to misinterpret their implications: In binomial GLMMs, the
        average probability to solve an item (averaged across persons of
        varying ability and items of varying difficulty) is
        <bold>not</bold> equal to the probability that a person with
        average ability solves an item with average difficulty
        (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021" ref-type="bibr">Fahrmeir
        et al., 2021</xref>). The first perspective implies a so-called
        marginal interpretation, while the second one implies a
        conditional interpretation.</p>
            <p>For example, we determined the <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
        parameters in a way that corresponds to a desired conditional
        probability of <inline-formula><alternatives><tex-math><![CDATA[0.95]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0.95</mml:mn></mml:math></alternatives></inline-formula>,
        that an expert with average ability solves an item with average
        difficulty when presented with correct advice (the conditional
        perspective). However, even if the model were true, we would not
        observe that 95% of experts responding to items presented with
        correct advice from a big sample of subjects drawn from their
        natural distribution of ability, and items drawn from their
        natural distribution of difficulty (the marginal perspective).
        How much the two probabilities differ depends on the standard
        deviations of the random intercepts (the two probabilities are
        only equal if both standard deviations would be zero). We want
        to use the model implied observed proportion of correct
        diagnoses in each experimental condition as an insightful
        descriptive statistics to determine plausible values for the
        random effect standard deviations.</p>
            <p>We will simulate a large dataset (for which the observed
        values of the descriptive statistic will be close to their model
        implied true values) and simply compute the relative frequency
        of correct diagnoses for each experimental condition.</p>
            <code language="r script">library(tidyverse)
set.seed(1)
dat &lt;- simulate(n_subjects = 3000, n_items = 3000,
  sd_u0s = 0.5, sd_u0i = 0.5)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
 "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
 "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
 "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  group_by(condition) |&gt;
  summarize(relative_frequency = sum(y_bin) / n())</code>
            <preformat># A tibble: 6 × 2
  condition                 relative_frequency
  &lt;fct&gt;                                  &lt;dbl&gt;
1 no expert, no advice                   0.683
2 expert, no advice                      0.881
3 no expert, wrong advice                0.409
4 expert, wrong advice                   0.828
5 no expert, correct advice              0.883
6 expert, correct advice                 0.938</preformat>
            <p>We tried using these descriptive statistics to judge together
        with domain experts whether our chosen values for the random
        effect standard deviations would produce data that align with
        out domain expertise. However, although the result was deemed
        plausible, these statistics were not informative enough to
        determine a final set of plausible parameter values. For this
        reason, we will additionally look at insightful model based
        quantities.</p>
          </sec>
        </sec>
        <sec id="insightful-model-based-quantities">
          <title>Insightful model based quantities</title>
          <sec id="theory-4">
            <title>THEORY</title>
            <p>Because GLMMs are complicated models, descriptive statistics
        alone are usually not enough to specify plausible values for all
        model parameters. This is especially true for the standard
        deviation of random effects that have non-linear (and often
        unexpected) effects on the model-implied results. An important
        advantage of data simulation (where one has full control over
        parameter values and sample sizes) is that one can produce
        insightful model based quantities that can never be directly
        observed in an actual empirical dataset. For example, in a
        logistic model with random intercepts for participants, one can
        produce a visualization of the implied distribution of the
        probability that a participant on average solves a cognitive
        task. Although domain knowledge will probably not suffice to
        specify this distribution completely, it should be possible to
        rule out implausible boundary conditions. For example, the
        domain expert might deem it implausible that the 5% most able
        participants have a probability of more than 0.99 to solve the
        difficult cognitive task.</p>
          </sec>
          <sec id="practice-4">
            <title>PRACTICE</title>
            <p>The discussed inequality of conditional and marginal effects
        in GLMMs
        (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021" ref-type="bibr">Fahrmeir
        et al., 2021</xref>) makes their interpretation more difficult.
        One must be careful when specifying parameter values based on
        previous studies or pilot data that use the marginal
        interpretation (e.g., a pilot study providing an estimate of how
        often radiologists make an accurate diagnosis based on brain
        scans). However, this does not mean that we cannot use the
        marginal interpretation (average probability across persons and
        items) to inform plausible parameter values: When parameter
        values have been selected, we can compute the implied marginal
        distributions and compare this information to our domain
        knowledge. Then, we can iteratively adjust the parameter values
        until we are satisfied with the implied distributions. In the
        last section, we simulated a large dataset and computed
        descriptive statistics, the relative frequencies of correct
        diagnoses, for each experimental condition. We will now use the
        model implied probability of each simulated data point (stored
        in the variable <monospace>y_prob</monospace>) to visualize the
        whole model implied marginal distribution of correct diagnoses
        for each experimental condition.</p>
            <code language="r script">library(ggdist)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
"no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
"no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
"no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))</code>
            <fig id="fig-margdist1">
              <caption>
                <p>Figure 1: Marginal distributions including means,
          66% and 95% confidence intervals for all experimental
          conditions.</p>
              </caption>
              <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-margdist1-1.png"/>
            </fig>
            <p><xref alt="Figure 1" rid="fig-margdist1">Figure 1</xref>
        shows the model implied marginal distributions, including the
        mean, 66% and 95% intervals. We can see that, indeed, the
        average probabilities (black dots) slightly differ from the
        probabilities of average subjects and items considered in the
        previous section. This difference increases with the variability
        of the random effects. We can use plots like the one above as a
        useful tool to decide whether the specified standard deviations
        of the subject and item random intercepts
        (<inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
        and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>)
        are reasonable by comparing the ranges and overlap between
        conditions to domain knowledge.</p>
            <fig id="fig-margdist2">
              <caption>
                <p>Figure 2: Marginal distributions including means,
          66% and 95% confidence intervals for all experimental
          conditions while setting the standard deviation of item random
          intercepts to 0.01.</p>
              </caption>
              <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-margdist2-1.png"/>
            </fig>
            <p>In the next plot, we have set the item standard deviation to
        almost zero (<inline-formula><alternatives><tex-math><![CDATA[\sigma_I = 0.01]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).
        This gives us a better way to see the variability between
        persons. As an example,
        <xref alt="Figure 2" rid="fig-margdist2">Figure 2</xref> reveals
        a number of implicit assumptions about the comparison between
        experts and non-experts: With wrong advice, virtually all
        experts have a higher probability of making a correct diagnosis
        compared to non-experts when considering only items with average
        difficulty. In contrast, there is considerable overlap in
        probability between experts and non-experts with no advice and
        even higher overlap with correct advice. Patterns like these
        should be considered carefully and discussed with the domain
        experts. Parameter values (<inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
        parameters, and <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>)
        should be adjusted if the implications do not seem reasonable.
        We could also have a closer look at variability between items by
        setting the subject standard deviation to almost zero
        (<inline-formula><alternatives><tex-math><![CDATA[\sigma_S = 0.01]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).</p>
            <p>The final plot demonstrates that these plots are also useful
        for spotting standard deviations that are specified too high.
        For <xref alt="Figure 3" rid="fig-margdist3">Figure 3</xref> we
        have set <inline-formula><alternatives><tex-math><![CDATA[\sigma_S = 3]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
        and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I = 3]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
        This implies that in each experimental condition, the
        probabilities that a subject solves an item are usually close to
        either 0 or 1, which is not a plausible assumption. These high
        standard deviations do not account for the inherent variability
        and complexity of human performance. For example, we would
        expect that a participant with low ability compared to other
        task experts to solve a difficult item with a probability
        substantially larger than zero even when presented with wrong
        advice.</p>
            <fig id="fig-margdist3">
              <caption>
                <p>Figure 3: Marginal distributions including means,
          66% and 95% confidence intervals for all experimental
          conditions while setting the standard deviation of subject and
          item random intercepts to 3.</p>
              </caption>
              <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-margdist3-1.png"/>
            </fig>
          </sec>
        </sec>
        <sec id="iterative-process-with-domain-experts">
          <title>Iterative process with domain experts</title>
          <sec id="theory-5">
            <title>THEORY</title>
            <p>In our experience, the gathering of domain knowledge by
        domain experts and the consecutive specification of population
        parameter values used in data simulation is not a one-time event
        but rather an iterative process. In a first step, domain experts
        can be interviewed to “elicit” their domain knowledge about how
        the future data of the planned study is expected to look like.
        As most domain experts are no experts in statistical modeling
        and GLMMs, they often struggle without further guidance to
        communicate their knowledge in a way that is useful when
        specifying the parameters for data simulation. For this reason,
        we suggest that after an initial unstructured interview of
        domain experts, the analyst who is familiar with the structure
        of the GLMM under study selects an initial set of insightful
        descriptive statistics and model based quantities. Then they
        reenter into an iterative discussion where some set of
        population values are selected and the plausibility of resulting
        implied quantities are discussed with the domain experts. Then,
        the population parameters are updated based on this discussion
        until the domain experts are satisfied with the final result.
        During this process, the monitored model based quantities and
        descriptive statistics can be updated or extended to capture as
        much available domain knowledge as possible.</p>
            <sec id="practice-5">
              <title>PRACTICE</title>
              <p>All parameter values in our present case study have been
          determined based on repeated discussions with our affiliated
          domain experts in Radiology to validate our assumptions.
          Initially, we reviewed the literature to establish a
          reasonable baseline performance rate for examining head CT
          scans for intracranial hemorrhage. Existing studies indicate
          that radiologists typically demonstrate high accuracies, often
          exceeding or hovering around 90%, while interns have been
          shown to perform below 80%, and medical students fall even
          shorter. For simplicity, we assumed plausible probability
          values of .90 for experts and .70 for non-experts,
          respectively. Our experts confirmed that these values are
          realistic baselines for reviewing diverse head CT images
          without AI assistance. Subsequently, we consulted several
          published papers investigating the effect of correct and
          incorrect advice on decision-making performance in other
          settings. From their findings, we inferred that both experts
          and non-experts should benefit from correct and suffer losses
          from incorrect advice. However, the magnitude of these effects
          should be substantially greater for non-experts, given their
          demonstrated reliance on advice compared to experts. We
          further validated the plausibility of our estimated gains and
          losses with the collaborating radiologists. For our
          simulation, we used the probabilities of average participants
          to solve an average case, as shown in Table 1.</p>
            </sec>
          </sec>
        </sec>
      </sec>
      <sec id="step-4-estimate-the-statistical-model">
        <title>Step 4: Estimate the statistical model</title>
        <sec id="theory-6">
          <title>THEORY</title>
          <p>At this point, the researcher is capable of producing a
      simulated dataset similar to the actual dataset that will later be
      collected in the planned study. The next step is to specify how
      the statistical model shall be estimated in the actual study
      collected later. This usually includes the selection of 1) a
      statistical framework (e.g., frequentist statistics), 2) a
      software package that is capable of estimating the model class of
      interest (e.g., the lme4 R package), 3) an estimation algorithm
      (e.g., the default optimizer “bobyqa”), and 4) the specific model
      structure including all fixed effects, random effects, and the
      model family of the dependent variable.
      Note that this does not always mean that one will specify the same
      GLMM that was used when specifying the data generating process. On
      the one hand, using a simpler model for data simulation than for
      model estimation can be a useful strategy in scenarios where
      making plausible assumptions for complicated random effect
      structures and interactions is not feasible. On the other hand,
      using a more complex model for data simulation than for model
      estimation can be a useful strategy in scenarios where one has
      specific domain knowledge about aspects of the data generating
      process that are still difficult to estimate with the current
      state-of-the-art in multilevel modeling.</p>
        </sec>
        <sec id="practice-6">
          <title>PRACTICE</title>
          <p>In our case study, we use the lme4 R package
      (<xref alt="Bates et al., 2015" rid="ref-batesFittingLinearMixedEffects2015" ref-type="bibr">Bates
      et al., 2015</xref>), which is a state-of-the-art tool for fitting
      frequentist GLMMs.<xref ref-type="fn" rid="fn3">3</xref> For the
      current example, we simulate data according to our model, in which
      100 subjects respond to 50 items (we use
      <monospace>set.seed</monospace> to make the simulation
      reproducible). However, for the sake of the exercise, we can
      imagine that this would be real data resulting from our future
      experiment and think about how we would analyze this data.</p>
          <code language="r script">library(tidyverse)
set.seed(1)
dat &lt;- simulate(n_subjects = 100, n_items = 50)</code>
          <p>The lme4 package uses a special syntax for model specification.
      Our specific GLMM is represented by the formula:</p>
          <code language="r script">library(lme4)
f &lt;- y_bin ~ 1 + expert + advice_present + advice_correct + 
  expert:advice_present + expert:advice_correct +
  (1|subject) + (1|item)</code>
          <p>The first two lines look similar to any linear model in R
      (general intercept indicated by <monospace>1</monospace>; main
      effects indicated by variable names in the dataset; interactions
      indicated by <monospace>variable1:variable2</monospace>). The
      third line specifies a random intercept for each subject
      <monospace>(1|subject)</monospace> and for each item
      <monospace>(1|item)</monospace>. The complete set of rules for the
      syntax is outlined in Bates et al.
      (<xref alt="2015" rid="ref-batesFittingLinearMixedEffects2015" ref-type="bibr">2015</xref>)
      and in the documentation of the lme4 package.</p>
          <p>In lme4, a GLMM is fitted with the <monospace>glmer</monospace>
      function. By setting
      <monospace>family =  "binomial"</monospace>, we request
      a binomial GLMM appropriate for our binary dependent variable
      <monospace>y_bin</monospace> (the binomial GLMM uses the canonical
      logit link by default), which is defined as an accurate (1)
      vs. inaccurate (0) diagnosis.</p>
          <code language="r script">fit &lt;- glmer(f, data = dat, family = "binomial")</code>
          <p>We can inspect the estimates for all model parameters with the
      <monospace>summary</monospace> command:</p>
          <code language="r script">summary(fit)</code>
          <preformat>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: 
y_bin ~ 1 + expert + advice_present + advice_correct + expert:advice_present +  
    expert:advice_correct + (1 | subject) + (1 | item)
   Data: dat

     AIC      BIC   logLik deviance df.resid 
  4149.4   4201.6  -2066.7   4133.4     4992 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-5.7669  0.2125  0.3046  0.4317  2.1056 

Random effects:
 Groups  Name        Variance Std.Dev.
 subject (Intercept) 0.3148   0.5611  
 item    (Intercept) 0.1624   0.4029  
Number of obs: 5000, groups:  subject, 100; item, 50

Fixed effects:
                      Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)             1.0339     0.1103   9.374  &lt; 2e-16 ***
expert                  1.1849     0.2096   5.654 1.56e-08 ***
advice_present         -1.3436     0.1206 -11.143  &lt; 2e-16 ***
advice_correct          2.6154     0.1273  20.540  &lt; 2e-16 ***
expert:advice_present   1.0589     0.2940   3.601 0.000317 ***
expert:advice_correct  -1.8104     0.2915  -6.210 5.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) expert advc_p advc_c exprt:dvc_p
expert      -0.377                                 
advic_prsnt -0.349  0.176                          
advic_crrct  0.023  0.001 -0.668                   
exprt:dvc_p  0.143 -0.448 -0.412  0.276            
exprt:dvc_c -0.008  0.004  0.292 -0.435 -0.686     </preformat>
          <p>In the lme4 output, the <monospace>Estimate</monospace> column
      in the <monospace>Fixed effects</monospace> table contains the
      estimates for the <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters, while the <monospace>Std.Dev.</monospace> column in
      the <monospace>Random effects</monospace> table contains the
      estimates for <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
      and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>.</p>
        </sec>
      </sec>
      <sec id="step-5-compute-the-estimate">
        <title>Step 5: Compute the estimate</title>
        <sec id="theory-7">
          <title>THEORY</title>
          <p>In previous steps, we have defined the theoretical estimand,
      written a data simulation function and specified how to estimate a
      GLMM using simulated data. The next step is to specify how to
      compute a concrete point estimate of the theoretical estimand
      within the framework of the fitted GLMM. For some research
      question, the estimate corresponds with a single regression
      coefficient. In more complicated scenarios, the estimate is
      computed from a combination of coefficients. Beyond computing the
      point estimate, we have already discussed that both hypothesis
      testing and interval estimation can be used to answer the research
      question. The decision on testing or estimating is then followed
      by selecting the specific statistical method that shall be applied
      to compute the HT(s) or CI(s) (e.g., compute HTs and CIs with the
      marginaleffects R package using the delta method).</p>
        </sec>
        <sec id="practice-7">
          <title>PRACTICE</title>
          <p>In the estimand section, we have translated a verbal
      description of our research question into four probability
      statements that are specified outside of any specific statistical
      model. For a concrete estimate within the context of our specified
      GLMM, we must compute the following probability contrasts:</p>
          <p>
            <disp-formula>
              <alternatives>
                <tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math>
                <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                  <mml:mtable>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mi>Y</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>s</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>n</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>o</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>e</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>s</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>i</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mspace width="1.0em"/>
                        <mml:mo>−</mml:mo>
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mi>Y</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>s</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>n</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>o</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>e</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>s</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>i</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:math>
              </alternatives>
            </disp-formula>
            <disp-formula>
              <alternatives>
                <tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math>
                <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                  <mml:mtable>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mi>Y</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>s</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>n</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>o</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>e</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>s</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>i</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mspace width="1.0em"/>
                        <mml:mo>−</mml:mo>
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mi>Y</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>s</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>n</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>o</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>e</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>s</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>i</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:math>
              </alternatives>
            </disp-formula>
          </p>
          <p>
            <disp-formula>
              <alternatives>
                <tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math>
                <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                  <mml:mtable>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mi>Y</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>s</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>n</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>o</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>e</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>s</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>i</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd columnalign="right" style="text-align: right"/>
                      <mml:mtd columnalign="left" style="text-align: left">
                        <mml:mspace width="1.0em"/>
                        <mml:mo>−</mml:mo>
                        <mml:mi>P</mml:mi>
                        <mml:mrow>
                          <mml:mo stretchy="true" form="prefix">(</mml:mo>
                          <mml:mi>Y</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                          <mml:mo stretchy="false" form="prefix">|</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>s</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>n</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>a</mml:mi>
                          <mml:mi>d</mml:mi>
                          <mml:mi>v</mml:mi>
                          <mml:mi>i</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>_</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>o</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>c</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:mi>e</mml:mi>
                          <mml:mi>x</mml:mi>
                          <mml:mi>p</mml:mi>
                          <mml:mi>e</mml:mi>
                          <mml:mi>r</mml:mi>
                          <mml:mi>t</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>s</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo>,</mml:mo>
                          <mml:msub>
                            <mml:mi>u</mml:mi>
                            <mml:mrow>
                              <mml:mn>0</mml:mn>
                              <mml:mi>i</mml:mi>
                            </mml:mrow>
                          </mml:msub>
                          <mml:mo>=</mml:mo>
                          <mml:mn>0</mml:mn>
                          <mml:mo stretchy="true" form="postfix">)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:math>
              </alternatives>
            </disp-formula>
          </p>
          <p><disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mspace width="1.0em"/><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      We have already discussed how to compute the involved
      probabilities in the section on specifying population parameters.
      Plugging in the model equation of the GLMM produces an equation on
      how to compute each contrast if all model parameters were known.
      When we want to estimate the above contrasts based on
      <italic>observed</italic> data, the only difference is that model
      parameters are not known and we instead use the corresponding
      parameter <italic>estimates</italic>.</p>
          <p>We could use our knowledge of the structure of the GLMM to
      determine the exact formula needed to compute the contrasts of
      interest and then plug in the parameter estimates manually from
      the <monospace>summary(fit)</monospace> output. However, this
      would be tedious and we can use R to compute this contrast without
      doing the math. Using the first contrast <italic>(correct advice,
      expert) - (no advice, expert)</italic> as our example, we could
      apply the <monospace>predict</monospace> function of the lme4
      package to compute the predicted probability for a correct
      diagnosis based on our fitted model, plug in the two sets of
      predictor values, and compute the difference between the two
      estimated probabilities.</p>
          <code language="r script">grid1 &lt;- data.frame(advice_present = c(1, 0), advice_correct = c(1, 0), 
  expert = c(1, 1))
grid1</code>
          <preformat>  advice_present advice_correct expert
1              1              1      1
2              0              0      1</preformat>
          <code language="r script">pred &lt;- predict(fit, newdata = grid1, type = "response", re.form = NA)
pred</code>
          <preformat>       1        2 
0.939292 0.901923 </preformat>
          <code language="r script">pred[1] - pred[2]</code>
          <preformat>         1 
0.03736901 </preformat>
          <p>The argument <monospace>type = "response"</monospace>
      specifies that predictions are made on the probability scale
      (instead of the log-odds scale of the
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters), while <monospace>re.form = NA</monospace> sets all
      random effects to 0. We could use this method to compute point
      estimates for all four contrasts that are part of our estimand.
      However, depending on whether we are interested in hypothesis
      testing or parameter estimation, we also need a method to compute
      HTs or CI. The marginaleffects package
      (<xref alt="Arel-Bundock, 2024" rid="ref-R-marginaleffects" ref-type="bibr">Arel-Bundock,
      2024</xref>) is a very flexible, increasingly popular package to
      compute HTs and CIs for contrasts with a variety of statistical
      models, including GLMMs estimated with lme4. First, we specify a
      grid of all combinations of predictor variable and then compute
      estimated probabilities for all experimental conditions in our
      experiment with the <monospace>predictions</monospace>
      function:</p>
          <code language="r script">library(tidyverse)
library(marginaleffects)
library(tinytable)
grid2 &lt;- expand_grid(advice_present = 0:1, 
  advice_correct = 0:1, expert = 0:1)
grid2</code>
          <preformat># A tibble: 8 × 3
  advice_present advice_correct expert
           &lt;int&gt;          &lt;int&gt;  &lt;int&gt;
1              0              0      0
2              0              0      1
3              0              1      0
4              0              1      1
5              1              0      0
6              1              0      1
7              1              1      0
8              1              1      1</preformat>
          <code language="r script">preds &lt;- predictions(fit, newdata = grid2, 
  type = "response", re.form = NA)
print(preds, style = "tinytable") |&gt; theme_tt(theme = "resize")</code>
          <table-wrap>
            <table>
              <colgroup>
                <col width="9%"/>
                <col width="11%"/>
                <col width="7%"/>
                <col width="9%"/>
                <col width="7%"/>
                <col width="7%"/>
                <col width="8%"/>
                <col width="14%"/>
                <col width="14%"/>
                <col width="8%"/>
              </colgroup>
              <thead>
                <tr>
                  <th>Estimate</th>
                  <th>Std. Error</th>
                  <th>z</th>
                  <th>Pr(&gt;|z|)</th>
                  <th>S</th>
                  <th>2.5 %</th>
                  <th>97.5 %</th>
                  <th>advice_present</th>
                  <th>advice_correct</th>
                  <th>expert</th>
                </tr>
              </thead>
              <tfoot>
                <tr>
                  <td colspan="10">Columns: rowid, estimate, std.error,
              statistic, p.value, s.value, conf.low, conf.high,
              advice_present, advice_correct, expert, y_bin</td>
                </tr>
              </tfoot>
              <tbody>
                <tr>
                  <td>0.738</td>
                  <td>0.02134</td>
                  <td>34.6</td>
                  <td>&lt;0.001</td>
                  <td>867.2</td>
                  <td>0.696</td>
                  <td>0.779</td>
                  <td>0</td>
                  <td>0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.902</td>
                  <td>0.01739</td>
                  <td>51.9</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.868</td>
                  <td>0.936</td>
                  <td>0</td>
                  <td>0</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>0.975</td>
                  <td>0.00421</td>
                  <td>231.6</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.966</td>
                  <td>0.983</td>
                  <td>0</td>
                  <td>1</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.954</td>
                  <td>0.01454</td>
                  <td>65.6</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.925</td>
                  <td>0.982</td>
                  <td>0</td>
                  <td>1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>0.423</td>
                  <td>0.03221</td>
                  <td>13.1</td>
                  <td>&lt;0.001</td>
                  <td>128.6</td>
                  <td>0.360</td>
                  <td>0.486</td>
                  <td>1</td>
                  <td>0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.874</td>
                  <td>0.02793</td>
                  <td>31.3</td>
                  <td>&lt;0.001</td>
                  <td>711.4</td>
                  <td>0.819</td>
                  <td>0.928</td>
                  <td>1</td>
                  <td>0</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>0.909</td>
                  <td>0.00967</td>
                  <td>94.1</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.890</td>
                  <td>0.928</td>
                  <td>1</td>
                  <td>1</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.939</td>
                  <td>0.01091</td>
                  <td>86.1</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.918</td>
                  <td>0.961</td>
                  <td>1</td>
                  <td>1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td colspan="10">Type: response</td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
          <p>The point estimates for all experimental conditions are
      reported in the <monospace>Estimate</monospace> column. Note that
      the output also contains the two missing by design conditions that
      will never be observed in the actual study
      (<inline-formula><alternatives><tex-math><![CDATA[advice\_present = 0, advice\_correct = 1, expert = 1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
      and <inline-formula><alternatives><tex-math><![CDATA[advice\_present = 0, advice\_correct = 1, expert = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).
      This is no problem as long as we never interpret those estimates.
      Next, we use the estimated probabilities to compute the four
      specific contrasts that are part of our estimand. For this we must
      specify which rows in <monospace>probs</monospace> have to be
      subtracted from each other. We will use the
      <monospace>hypotheses</monospace> function to compute our four
      contrasts of interest together with HTs and CIs. We use the
      default inference options of the marginaleffects package that
      compute HTs and CIs based on the approximate delta method.</p>
          <code language="r script">contrasts &lt;- preds |&gt; 
  hypotheses(hypothesis = c(
    "b8 = b2",  # (correct advice, expert) - (no advice, expert)
    "b2 = b6",  # (no advice, expert) - (wrong advice, expert) 
    "b7 = b1",  # (correct advice, no expert) - (no advice, no expert)
    "b1 = b5"), # (no advice, no expert) - (wrong advice, no expert)
    equivalence = c(0, 0))
print(contrasts, style = "tinytable") |&gt; theme_tt(theme = "resize")</code>
          <table-wrap>
            <table>
              <colgroup>
                <col width="6%"/>
                <col width="9%"/>
                <col width="10%"/>
                <col width="6%"/>
                <col width="9%"/>
                <col width="6%"/>
                <col width="9%"/>
                <col width="7%"/>
                <col width="10%"/>
                <col width="10%"/>
                <col width="10%"/>
              </colgroup>
              <thead>
                <tr>
                  <th>Term</th>
                  <th>Estimate</th>
                  <th>Std. Error</th>
                  <th>z</th>
                  <th>Pr(&gt;|z|)</th>
                  <th>S</th>
                  <th>2.5 %</th>
                  <th>97.5 %</th>
                  <th>p (NonSup)</th>
                  <th>p (NonInf)</th>
                  <th>p (Equiv)</th>
                </tr>
              </thead>
              <tfoot>
                <tr>
                  <td colspan="11">Columns: term, estimate, std.error,
              statistic, p.value, s.value, conf.low, conf.high,
              statistic.noninf, statistic.nonsup, p.value.noninf,
              p.value.nonsup, p.value.equiv</td>
                </tr>
              </tfoot>
              <tbody>
                <tr>
                  <td>b8=b2</td>
                  <td>0.0374</td>
                  <td>0.0162</td>
                  <td>2.31</td>
                  <td>0.021</td>
                  <td>5.6</td>
                  <td>0.00563</td>
                  <td>0.0691</td>
                  <td>0.989</td>
                  <td>0.0105</td>
                  <td>0.989</td>
                </tr>
                <tr>
                  <td>b2=b6</td>
                  <td>0.0282</td>
                  <td>0.0279</td>
                  <td>1.01</td>
                  <td>0.312</td>
                  <td>1.7</td>
                  <td>-0.02653</td>
                  <td>0.0830</td>
                  <td>0.844</td>
                  <td>0.1562</td>
                  <td>0.844</td>
                </tr>
                <tr>
                  <td>b7=b1</td>
                  <td>0.1717</td>
                  <td>0.0173</td>
                  <td>9.93</td>
                  <td>&lt;0.001</td>
                  <td>74.8</td>
                  <td>0.13780</td>
                  <td>0.2056</td>
                  <td>1.000</td>
                  <td>&lt;0.001</td>
                  <td>1.000</td>
                </tr>
                <tr>
                  <td>b1=b5</td>
                  <td>0.3145</td>
                  <td>0.0280</td>
                  <td>11.24</td>
                  <td>&lt;0.001</td>
                  <td>95.0</td>
                  <td>0.25965</td>
                  <td>0.3693</td>
                  <td>1.000</td>
                  <td>&lt;0.001</td>
                  <td>1.000</td>
                </tr>
                <tr>
                  <td colspan="11">Type: response</td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
          <p>The expression <monospace>"b8 = b2"</monospace> is
      special syntax to subtract the estimate in row number 8 from the
      estimate in row number 2 in the
      <monospace>probs</monospace>-output. The argument
      <monospace>equivalence = c(0, 0)</monospace> can be used to
      compute one-sided p-values, testing whether the contrast in the
      population is smaller than 0 (<monospace>p (NonSub)</monospace>
      column) or greater than 0 (<monospace>p (NonInf)</monospace>
      column). The point estimates for four contrasts are reported in
      the <monospace>Estimate</monospace> column. Note that to
      facilitate interpretation, we arranged the contrasts in a way that
      we theoretically expect positive values for all four of them.</p>
          <sec id="hypothesis-testing">
            <title>Hypothesis testing</title>
            <p>If we chose hypothesis testing for our case study, we would
        test a combined null hypothesis <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
        that consists of four separate null hypotheses:
        <disp-formula><alternatives><tex-math><![CDATA[
        \begin{aligned}
        H_{01}:\ & P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 1, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
        H_{02}:\ &P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
        H_{03}:\ &P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 0, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
        H_{04}:\ & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
        \end{aligned}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>03</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>04</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
        The combined null hypothesis <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
        should only be rejected if <bold>all</bold> individual null
        hypotheses are rejected (i.e., intersection-union setting;
        <xref alt="Dmitrienko &amp; D’Agostino, 2013" rid="ref-dmitrienkoTraditionalMultiplicityAdjustment2013" ref-type="bibr">Dmitrienko
        &amp; D’Agostino, 2013</xref>). In such cases, the error
        probabilities do not accumulate, and we would waste power when
        correcting for multiple tests.</p>
            <p>With a standard significance level of
        <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
        we would not reject all four null hypotheses (the p-value in the
        <monospace>p (NonInf)</monospace> column for the second
        hypothesis is not significant) and therefore also not reject the
        combined null hypothesis for this particular (simulated)
        dataset. Note that this decision would be wrong because we have
        simulated the data such that the combined alternative hypothesis
        <inline-formula><alternatives><tex-math><![CDATA[H_1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
        is actually true in the population.</p>
          </sec>
          <sec id="interval-estimation">
            <title>Interval estimation</title>
            <p>If we chose parameter estimation for our case study, we would
        focus on the two-sided CIs of the four contrasts of interest.
        With a standard confidence level of
        <inline-formula><alternatives><tex-math><![CDATA[1 - \alpha = 0.95]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
        plausible values are clearly in the positive range for the
        first, third and fourth contrast, while both negative and
        positive values seem plausible for the second contrast. Note
        that due to the constrained range of the probability scale, the
        width of the CI differs between the four contrasts (which is the
        expected behavior for binomial GLMMs). The smallest width is
        observed for the first contrast (expert with correct advice
        vs. expert without advice) where both underlying probabilities
        are close to 1. The largest width is observed for the fourth
        contrast (non-expert with wrong advice vs. non-expert without
        advice), where both underlying probabilities are closer to
        0.5.</p>
          </sec>
        </sec>
      </sec>
      <sec id="step-6-perform-repeated-simulations">
        <title>Step 6: Perform repeated simulations</title>
        <sec id="theory-8">
          <title>THEORY</title>
          <p>Conducting all previous steps enables the analyst to 1)
      simulate a dataset, 2) estimate a GLMM, and 3) compute HTs or CIs
      for estimands of interest, mirroring the analysis that will later
      be performed for the actual dataset of the planned study. The last
      missing piece is to write code to perform the above steps
      repeatedly and allow for a setting using different sample sizes.
      On a conceptual level, we first require a function that takes as
      input the sample size and the full set of population parameter
      values. When planning for power, the function should return the
      p-value(s) of the HT(s) of interest when conducted on the
      simulated dataset. When planning for precision, the function
      should return the width of the CI(s) of interest. Secondly, we
      must run this function repeatedly with the same sample size and
      population parameters. Because even fitting GLMMs with frequentist
      methods can quickly become time-consuming, it is recommended to
      use parallel computing, that is running simulations on multiple
      cores of the computer at the same time to reduce total run time.
      Thirdly, the results of the repeated simulation must be collected
      and aggregated. When planning for power, we compute the relative
      frequency of (a) significant p-value(s) across repeated
      simulations. When planning for precision, we compute the average
      width of the CI(s). Lastly, we have to repeat the complete
      simulation for different sample sizes, to determine how big the
      sample must be in order to achieve the targeted power or
      precision.</p>
        </sec>
        <sec id="practice-8">
          <title>PRACTICE</title>
          <p>We are finally ready to run our simulation-based sample size
      planning analyses to plan for power and for precision. Wrapping
      the <monospace>simulate</monospace> function already constructed
      earlier, the helper function
      <monospace>sim_and_analyse</monospace> performs all previous steps
      (simulate a dataset, fit a GLMM, compute p-values and CIs) in a
      single command.</p>
          <code language="r script">sim_and_analyse &lt;- function(
  formula_chr = "y_bin ~ 1 + expert + advice_present + advice_correct + 
    expert:advice_present + expert:advice_correct + (1|subject) + (1|item)",
  contrasts = c("b8 = b2", "b2 = b6", "b7 = b1", "b1 = b5"), ...){
  require(lme4)
  require(marginaleffects)
  require(tidyr)
  # simulate data
  dat &lt;- simulate(...)
  # fit model
  model &lt;- glmer(as.formula(formula_chr), data = dat, family = "binomial")
  # compute contrasts
  contr_df &lt;- expand_grid(advice_present = 0:1, advice_correct = 0:1,
    expert = 0:1)
  predictions(model, newdata = contr_df, type = "response", re.form = NA) |&gt;
    hypotheses(hypothesis = contrasts, equivalence = c(0, 0)) |&gt;
    data.frame()
}</code>
          <p>Simulation-based sample size planning can quickly become
      computationally intensive when we repeatedly simulate data and fit
      models for different parameter combinations or sample sizes. Thus,
      we use the future
      (<xref alt="Bengtsson, 2021" rid="ref-R-RJ-2021-048" ref-type="bibr">Bengtsson,
      2021</xref>) and furrr
      (<xref alt="Vaughan &amp; Dancho, 2022" rid="ref-R-furrr" ref-type="bibr">Vaughan
      &amp; Dancho, 2022</xref>) packages to perform computations in
      parallel. First, we enable parallelization with the
      <monospace>plan</monospace> function and specify how many parallel
      cores (“workers”) of our computer to use (users can find out the
      maximum number of cores on their computer with the command
      <monospace>parallel::detectCores()</monospace>), and set a seed to
      make the simulation reproducible.</p>
          <code language="r script">library(future)
plan("multisession", workers = 6)
set.seed(2)</code>
          <p>The next code chunk specifies a simulation grid with different
      settings for both the number of subjects
      (<monospace>n_subjects</monospace>) and the number of items
      (<monospace>n_items</monospace>), each combination being repeated
      <monospace>rep</monospace> times. We chose 300 repetitions for the
      data simulation at hand as it strikes a balance between achieving
      a robust statistical estimate and remaining computationally
      feasible. With the current settings, this simulation takes about
      one hour on a MacBook Pro from 2020 with M1 chip and 16 GB working
      memory. If you want to quickly experiment with the code yourself,
      a setting with <monospace>workers = 4</monospace> and
      <monospace>rep = 5</monospace> should finish in less than 5
      minutes, even on smaller machines.</p>
          <code language="r script">library(furrr)
sim_result &lt;- crossing(
  rep = 1:300,
  n_subjects = c(100, 150, 200, 250),
  n_items = c(10, 30, 50, 70)
) |&gt;
  mutate(res = future_pmap(., sim_and_analyse, 
    .options = furrr_options(seed = TRUE))) |&gt;
  unnest(col = res)</code>
          <p>The result of this computation is a data frame that contains
      the p-values and CIs of all specified contrasts for each simulated
      dataset. In some iterations (predominantly in conditions with
      small sample sizes), model estimation did not converge with the
      lme4 package. When the model fails to converge, it means that the
      statistical model being fitted to the data failed to reach a
      stable or valid solution during the estimation process. We do not
      remove these results because non-convergence can also happen when
      analyzing the real data we plan to collect, thus, we want to
      factor in this possibility to keep our simulation more
      realistic.</p>
          <sec id="power-results">
            <title>Power results</title>
            <p>For our exemplary combined hypothesis, power is defined as
        the (long-run) percentage of simulations in which all four
        p-values of our individual hypotheses are significant at the
        <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
        level. Based on our simulation outcomes, we compute a power
        estimate for each combination of
        <monospace>n_subjects</monospace> <inline-formula><alternatives><tex-math><![CDATA[\times]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>×</mml:mi></mml:math></alternatives></inline-formula>
        <monospace>n_items</monospace> (including 95% CIs) and visualize
        the results with the following
        code.<xref ref-type="fn" rid="fn4">4</xref></p>
            <code language="r script">library(binom)
alpha &lt;- 0.05
power &lt;- sim_result |&gt;
  pivot_wider(names_from = term, names_sep = "_", 
    values_from = estimate:p.value.equiv) |&gt;
  group_by(n_subjects, n_items) |&gt; 
  summarise(
    power = mean(`p.value.noninf_b1=b5` &lt; alpha &amp; 
        `p.value.noninf_b8=b2` &lt; alpha &amp; `p.value.noninf_b2=b6` &lt; alpha &amp; 
        `p.value.noninf_b7=b1` &lt; alpha), 
    n_sig = sum(`p.value.noninf_b1=b5` &lt; alpha &amp; 
        `p.value.noninf_b8=b2` &lt; alpha &amp; `p.value.noninf_b2=b6` &lt; alpha &amp; 
        `p.value.noninf_b7=b1` &lt; alpha),
    n = n(),
    ci.lwr = binom.confint(n_sig, n, method = "wilson")$lower,
    ci.upr = binom.confint(n_sig, n, method = "wilson")$upper, 
    .groups = "drop")
power |&gt;
  mutate(across(c(n_subjects, n_items), factor)) |&gt;
  ggplot(aes(n_subjects, n_items, fill = power)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.2f \n [%.2f; %.2f]", 
                                power, ci.lwr, ci.upr)), 
    color = "white", size = 4) +
  scale_fill_viridis_c(limits = c(0, 1)) +
  xlab("number of subjects") + ylab("number of items")</code>
            <fig id="fig-finalpwr">
              <caption>
                <p>Figure 4: Simulation-based power estimates
          including 95% confidence interval of the case study for
          different numbers of subjects and items, based on a
          significance level of 0.05.</p>
              </caption>
              <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-finalpwr-1.png"/>
            </fig>
            <p>As should be the case, power estimates in
        <xref alt="Figure 4" rid="fig-finalpwr">Figure 4</xref> increase
        with both the number of subjects and the number of items. The
        CIs reported here indicate how precisely power was estimated by
        our simulation. Higher precision (which would be reflected in
        narrower CIs) could be obtained by increasing the number of
        repetitions (<monospace>rep</monospace>) in the simulation. In
        practice, data simulations are often run multiple times with
        adjusted combinations of sample sizes. When running for the
        first time, it might be revealed that power is way too low (or
        much higher than required) for some combinations of
        <monospace>n_subjects</monospace> and
        <monospace>n_items</monospace>. When narrowing down the best
        combination that achieves sufficient power while at the same
        time striking a good balance of how many subjects and items are
        practically feasible, later rounds of data simulation will
        typically include a smaller grid of sample sizes combined with a
        higher number of repetitions. This will assure high precision
        for the final power estimates, which are then used for the
        sample size justification of the future study.</p>
            <p>Much has been written on the optimal amount of power to
        target in empirical research. The most prominent heuristic is to
        target a power of 0.8 (when combined with a type I error rate of
        <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>),
        but depending on the research goals of the study, there are
        often good reasons to move away from this standard depending on
        the research goals and resource constraints
        (<xref alt="Lakens, Adolfi, et al., 2018" rid="ref-lakensJustifyYourAlpha2018" ref-type="bibr">Lakens,
        Adolfi, et al., 2018</xref>;
        <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022" ref-type="bibr">Lakens,
        2022a</xref>). When target power has been specified, the number
        of subjects and the number of items in our study design can be
        traded against each other based on practical considerations. For
        the sake of the example, let the targeted power be indeed about
        0.8, using an <inline-formula><alternatives><tex-math><![CDATA[\alpha]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>α</mml:mi></mml:math></alternatives></inline-formula>
        of 0.05 to detect an effect of the expected size implied by our
        data simulation. This could be achieved by collecting data from
        200 subjects (about 25% of which will be experts), each
        completing the same 50 items (with advice present in about 67%
        of cases, which is correct in about 80% of cases with present
        advice). If collecting data from 200 subjects is not feasible,
        an alternative would be to recruit 150 subjects but increase the
        length of the experiment to over 70 items. However, 70 items
        might take too long to complete for the radiologists
        participating in the study, who have a busy schedule. The
        simulation suggests that it might also be possible to plan a
        shorter experiment with only 30 items if it is feasible to
        recruit an even higher number of subjects (&gt; 250, to be
        determined by additional rounds of power analysis). Design
        parameters that also affect power, and which could be
        investigated in the simulation to find a more optimal trade-off,
        are the ratio of experts, the frequency of whether advice is
        presented and whether it is correct.</p>
          </sec>
          <sec id="precision-results">
            <title>Precision results</title>
            <p>When planning for precision, one could monitor the width of
        all four CIs at the same time. However, because the CIs of the
        four contrasts strongly differ in width, it is not trivial to
        decide which width one should target when deciding on the
        appropriate sample size. In contrast to planning for power,
        there are no common standards on how to specify the targeted
        precision. For our example, we use a simple heuristic but we
        strongly encourage readers to think about better alternatives
        that are appropriate in their own applications. Our simulations
        show that the smallest CI can be expected for the first contrast
        (expert with correct advice vs. expert without advice). The true
        contrast in probability for an average expert and an average
        item in this condition is
        <monospace>plogis(b_0 + b_e + b_a + b_c + b_ea + b_ec) - plogis(b_0 + b_e) =</monospace>
        <inline-formula><alternatives><tex-math><![CDATA[0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0.05</mml:mn></mml:math></alternatives></inline-formula>.
        We want the width of this CI to be smaller than 0.1. This would
        mean that if the point estimate happens to be close to the true
        value, the plausible values inside of a 95% CI would all be
        positive.</p>
            <p>Thus in our example, precision is defined as the (long-run)
        average width of a 95% CI for the probability contrast between
        experts with correct advice and experts without advice. Of
        course, lower width implies better precision. Based on our
        simulation outcomes, we compute the precision estimate for each
        combination of <monospace>n_subjects</monospace>
        <inline-formula><alternatives><tex-math><![CDATA[\times]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>×</mml:mi></mml:math></alternatives></inline-formula>
        <monospace>n_items</monospace> (including 95% CIs) and visualize
        the results with the following code.</p>
            <code language="r script">precision &lt;- sim_result |&gt;
  pivot_wider(names_from = term, names_sep = "_", 
    values_from = estimate:p.value.equiv) |&gt;
  group_by(n_subjects, n_items) |&gt;
  mutate(width = `conf.high_b8=b2` - `conf.low_b8=b2`) |&gt;
  summarise(precision = mean(width),
    ci.lwr = t.test(width)$conf.int[1],
    ci.upr = t.test(width)$conf.int[2], 
    .groups = "drop")
precision |&gt;
  mutate(across(c(n_subjects, n_items), factor)) |&gt;
  ggplot(aes(n_subjects, n_items, fill = precision)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.2f \n [%.2f; %.2f]", 
                                precision, ci.lwr, ci.upr)), 
    color = "white", size = 4) +
  scale_fill_viridis_c(limits = c(0, 0.3), direction = -1) +
  guides(fill = guide_legend(reverse=FALSE))</code>
            <fig id="fig-finalprecision">
              <caption>
                <p>Figure 5: Simulation-based precision estimates
          (expected width of confidence intervals) including 95%
          confidence interval of the case study for different numbers of
          subjects and items, based on a confidence level of
          0.95.</p>
              </caption>
              <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-finalprecision-1.png"/>
            </fig>
            <p>As should be the case, precision estimates in
        <xref alt="Figure 5" rid="fig-finalprecision">Figure 5</xref>
        increase (i.e., average width of CI decreases) with both the
        number of subjects and the number of items. The CIs reported
        here indicate how precisely the expected width of the CI for our
        focal contrast was estimated by our simulation. Applying our
        simple heuristic of targeting an expected width smaller than
        0.1, we see the same trade-off between the number of subjects
        and the number of items as with planning for power. We could
        either choose 100 subjects and 30 items or 200 subjects and 10
        items. Note that our simple heuristic for determining sample
        size in the planning for precision scenario was quite liberal.
        This is reflected by the result that we would need a smaller
        sample size than in the planning for power scenario. With a more
        conservative precision target, the result is generally the
        opposite: As a rule, precise parameter estimates usually require
        bigger samples than null hypothesis testing.</p>
          </sec>
        </sec>
      </sec>
      <sec id="sensitivity-analysis">
        <title>Sensitivity analysis</title>
        <p>In our case study, we have performed simulation-based sample size
    planning from a single set of parameter values that reflect our
    assumptions of an expected effect size. Instead of extracting this
    expected effect size from meta-analyses or pilot data, which has
    been the main focus of previous tutorials (e.g.,
    <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021" ref-type="bibr">Kumle
    et al., 2021</xref>), we have demonstrated some strategies to
    determine plausible parameter values in GLMMs based on domain
    knowledge. Domain knowledge can be considered a vague theoretical
    model about the data-generating process that is less formal and can
    only be accessed by a back-and-forth exchange in which domain
    experts assess the plausibility of simulated data. When sample sizes
    are chosen based on the results of our simulation-based power
    analysis, a future study will be informative to reject the null
    hypothesis if an effect of our <italic>expected size</italic> is
    present (or estimate the effect with satisfying precision). However,
    if the true effect is indeed smaller, power (or precision) will be
    lower, and the study might not be sufficiently informative. A
    common, more conservative strategy for sample size justification is
    to perform sample size planning for the smallest effect size of
    interest (SESOI). An effect smaller than the SESOI would be
    considered too small to be interesting or practically meaningful,
    even if the effect is not actually zero
    (<xref alt="King, 2011" rid="ref-kingPointMinimalImportant2011" ref-type="bibr">King,
    2011</xref>;
    <xref alt="Lakens, Scheel, et al., 2018" rid="ref-lakensEquivalenceTestingPsychological2018" ref-type="bibr">Lakens,
    Scheel, et al., 2018</xref>). For strategies on the even more
    difficult task of specifying a plausible SESOI, as well as a
    thorough discussion of various topics concerning power analysis, see
    (<xref alt="Lakens, 2022b" rid="ref-lakensImprovingYourStatistical2022" ref-type="bibr">Lakens,
    2022b</xref>). When domain knowledge or formal theories about the
    research topic of interest are too vague to specify a meaningful
    SESOI, it is still recommended to demonstrate power or precision for
    different effect sizes in what is called <italic>sensitivity power
    analysis</italic>. By simulating power (or precision) for different
    effect sizes (in addition to the different number of subjects and
    items), one can make sure that power (or precision) would still be
    sufficient to detect smaller effect sizes than our expected effect
    or at least get an impression of how strongly power (or precision)
    depends on the size of the true effect. For our case study that
    investigates combined hypotheses in a GLMM modeling framework,
    sensitivity analysis would require manually specifying additional
    sets of plausible parameter values that reflect scenarios with
    smaller or larger differences between groups with respect to our
    specific research question. Power (or precision) could then be
    simulated for several of these scenarios (across different numbers
    of subjects and items, as considered earlier).</p>
      </sec>
    </sec>
    <sec id="conclusion-and-outlook">
      <title>Conclusion and outlook</title>
      <p>The goal of this tutorial was to teach researchers how to perform
  tailored simulation-based sample size planning for GLMMs. Beyond the
  specifics of our concrete case study, we want to outline six
  developments regarding the future role of simulation-based sample size
  planning in experimental research:</p>
      <p>In light of the ongoing replication crisis and an existing
  literature full of underpowered studies, there is a growing need for
  simulation-based sample size planning in experimental research: In
  order to conduct informative research, GLMMs offer a flexible
  statistical framework to analyze complex experimental study designs.
  However, existing formula-based heuristics and user-friendly software
  tools for a priori power analysis are often not sufficient. Therefore,
  simulation-based power analysis is becoming increasingly needed since
  it provides experimental researchers with a tailored approach to
  estimating required sample sizes before data collection.</p>
      <p>Managing data simulations more easily with discrete predictor
  variables: Simulation-based sample size planning becomes more
  manageable when all predictor variables are discrete (like in the
  presented case study) and fixed by the study design. This allows
  researchers to focus on simulating outcome variables while avoiding
  the need for complex simulations of predictor values, which would
  introduce additional assumptions. By simplifying the simulation
  process, researchers can obtain reliable estimates for power or
  precision without compromising realistic assumptions about the
  data-generating process implied by the study design.</p>
      <p>Teaching data simulation skills: The ability to conduct
  simulation-based sample size planning is a valuable skill that should
  be taught to experimental researchers. By incorporating such training
  into research methods courses and workshops, researchers can gain a
  deeper understanding of statistical power or precision, and improve
  the quality of their experimental designs. Equipping researchers with
  the knowledge and tools to perform simulation-based sample size
  planning enables them to make informed decisions and enhance the rigor
  of their studies. The need to reason about how to simulate plausible
  data that is in line with the research hypothesis, while not violating
  domain expertise on how plausible data should look, might also
  contribute to planning more insightful studies that can answer more
  precise research questions
  (<xref alt="Yarkoni, 2022" rid="ref-yarkoniGeneralizabilityCrisis2022" ref-type="bibr">Yarkoni,
  2022</xref>).</p>
      <p>Addressing the mismatch in effort perception: There is often a
  significant disconnect between the amount of effort required to
  perform tailored simulation-based sample size planning and the
  perceived effort estimated by researchers and collaborators in
  experimental research. Many researchers request simulation-based power
  analyses from statisticians or methodological experts without fully
  comprehending the complexity and time-consuming nature of these
  tailored simulations. It is crucial to raise awareness about the
  effort involved to ensure realistic expectations and effective
  collaboration between researchers and methodological experts.</p>
      <p>Recognizing the value of simulation-based design analysis: Tailored
  data simulations and power analyses are not mere technicalities; they
  are valuable research contributions that deserve recognition in
  experimental research. They offer insights into the robustness and
  sensitivity of experimental designs, helping researchers make informed
  decisions about sample sizes, effect sizes, and statistical power or
  precision. Their importance can be reflected by allocating them a
  separate publication or incorporating them as a significant component
  of stage 1 preregistered reports
  (<xref alt="Chambers &amp; Tzavella, 2022" rid="ref-chambersPresentFutureRegistered2022" ref-type="bibr">Chambers
  &amp; Tzavella, 2022</xref>).</p>
      <p>Integration with Open Science and preregistration practices:
  Simulation-based sample size planning aligns well with the principles
  of Open Science and preregistration in experimental research. When
  researchers have access to simulated data based on their pre-specified
  model, analyzing the collected dataset becomes straightforward and
  unambiguous. By preregistering their simulation-based sample size
  plan, researchers enhance the transparency and accountability of their
  experimental procedures, contributing to the credibility and
  reproducibility of research.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="ref-albersWhenPowerAnalyses2018a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Albers</surname>
              <given-names>Casper</given-names>
            </name>
            <name>
              <surname>Lakens</surname>
              <given-names>Daniël</given-names>
            </name>
          </person-group>
          <article-title>When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias</article-title>
          <source>Journal of Experimental Social Psychology</source>
          <year iso-8601-date="2018-01">2018</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-05">2024</year>
            <month>06</month>
            <day>05</day>
          </date-in-citation>
          <volume>74</volume>
          <issn>00221031</issn>
          <pub-id pub-id-type="doi">10.1016/j.jesp.2017.09.004</pub-id>
          <fpage>187</fpage>
          <lpage>195</lpage>
        </element-citation>
      </ref>
      <ref id="ref-arendStatisticalPowerTwolevel2019">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Arend</surname>
              <given-names>Matthias G.</given-names>
            </name>
            <name>
              <surname>Schäfer</surname>
              <given-names>Thomas</given-names>
            </name>
          </person-group>
          <article-title>Statistical power in two-level models: A tutorial based on Monte Carlo simulation.</article-title>
          <source>Psychological Methods</source>
          <year iso-8601-date="2019-02">2019</year>
          <month>02</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-08">2023</year>
            <month>08</month>
            <day>08</day>
          </date-in-citation>
          <volume>24</volume>
          <issue>1</issue>
          <issn>1939-1463, 1082-989X</issn>
          <pub-id pub-id-type="doi">10.1037/met0000195</pub-id>
          <fpage>1</fpage>
          <lpage>19</lpage>
        </element-citation>
      </ref>
      <ref id="ref-batesFittingLinearMixedEffects2015">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bates</surname>
              <given-names>Douglas</given-names>
            </name>
            <name>
              <surname>Mächler</surname>
              <given-names>Martin</given-names>
            </name>
            <name>
              <surname>Bolker</surname>
              <given-names>Ben</given-names>
            </name>
            <name>
              <surname>Walker</surname>
              <given-names>Steve</given-names>
            </name>
          </person-group>
          <article-title>Fitting Linear Mixed-Effects Models Using Lme4</article-title>
          <source>Journal of Statistical Software</source>
          <year iso-8601-date="2015">2015</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2022-07-14">2022</year>
            <month>07</month>
            <day>14</day>
          </date-in-citation>
          <volume>67</volume>
          <issue>1</issue>
          <issn>1548-7660</issn>
          <pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-brooksGlmmTMBBalancesSpeed2017">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brooks</surname>
              <given-names>Mollie</given-names>
              <suffix>E.</suffix>
            </name>
            <name>
              <surname>Kristensen</surname>
              <given-names>Kasper</given-names>
            </name>
            <name>
              <surname>Benthem</surname>
              <given-names>van</given-names>
              <suffix>J.</suffix>
            </name>
            <name>
              <surname>Magnusson</surname>
              <given-names>Arni</given-names>
            </name>
            <name>
              <surname>Berg</surname>
              <given-names>Casper</given-names>
              <suffix>W.</suffix>
            </name>
            <name>
              <surname>Nielsen</surname>
              <given-names>Anders</given-names>
            </name>
            <name>
              <surname>Skaug</surname>
              <given-names>Hans</given-names>
              <suffix>J.</suffix>
            </name>
            <name>
              <surname>Mächler</surname>
              <given-names>Martin</given-names>
            </name>
            <name>
              <surname>Bolker</surname>
              <given-names>Benjamin</given-names>
              <suffix>M.</suffix>
            </name>
          </person-group>
          <article-title>glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling</article-title>
          <source>The R Journal</source>
          <year iso-8601-date="2017">2017</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-05-24">2024</year>
            <month>05</month>
            <day>24</day>
          </date-in-citation>
          <volume>9</volume>
          <issue>2</issue>
          <issn>2073-4859</issn>
          <pub-id pub-id-type="doi">10.32614/RJ-2017-066</pub-id>
          <fpage>378</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-brysbaertPowerAnalysisEffect2018">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Brysbaert</surname>
              <given-names>Marc</given-names>
            </name>
            <name>
              <surname>Stevens</surname>
              <given-names>Michaël</given-names>
            </name>
          </person-group>
          <article-title>Power Analysis and Effect Size in Mixed Effects Models: A Tutorial</article-title>
          <source>Journal of Cognition</source>
          <year iso-8601-date="2018-01">2018</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2022-07-14">2022</year>
            <month>07</month>
            <day>14</day>
          </date-in-citation>
          <volume>1</volume>
          <issue>1</issue>
          <issn>2514-4820</issn>
          <pub-id pub-id-type="doi">10.5334/joc.10</pub-id>
          <fpage>9</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-burknerAdvancedBayesianMultilevel2018">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bürkner</surname>
              <given-names>Paul-Christian</given-names>
            </name>
          </person-group>
          <article-title>Advanced Bayesian Multilevel Modeling with the R Package brms</article-title>
          <source>The R Journal</source>
          <year iso-8601-date="2018">2018</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-05-24">2024</year>
            <month>05</month>
            <day>24</day>
          </date-in-citation>
          <volume>10</volume>
          <issue>1</issue>
          <issn>2073-4859</issn>
          <pub-id pub-id-type="doi">10.32614/RJ-2018-017</pub-id>
          <fpage>395</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-burknerBrmsPackageBayesian2017">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bürkner</surname>
              <given-names>Paul-Christian</given-names>
            </name>
          </person-group>
          <article-title>Brms: An R Package for Bayesian Multilevel Models Using Stan</article-title>
          <source>Journal of Statistical Software</source>
          <year iso-8601-date="2017-08">2017</year>
          <month>08</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-11">2023</year>
            <month>08</month>
            <day>11</day>
          </date-in-citation>
          <volume>80</volume>
          <issn>1548-7660</issn>
          <pub-id pub-id-type="doi">10.18637/jss.v080.i01</pub-id>
          <fpage>1</fpage>
          <lpage>28</lpage>
        </element-citation>
      </ref>
      <ref id="ref-chambersPresentFutureRegistered2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chambers</surname>
              <given-names>Christopher D.</given-names>
            </name>
            <name>
              <surname>Tzavella</surname>
              <given-names>Loukia</given-names>
            </name>
          </person-group>
          <article-title>The past, present and future of Registered Reports</article-title>
          <source>Nature Human Behaviour</source>
          <publisher-name>Nature Publishing Group</publisher-name>
          <year iso-8601-date="2022-01">2022</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-09-11">2023</year>
            <month>09</month>
            <day>11</day>
          </date-in-citation>
          <volume>6</volume>
          <issue>1</issue>
          <issn>2397-3374</issn>
          <pub-id pub-id-type="doi">10.1038/s41562-021-01193-7</pub-id>
          <fpage>29</fpage>
          <lpage>42</lpage>
        </element-citation>
      </ref>
      <ref id="ref-cohenPowerPrimer1992">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cohen</surname>
              <given-names>Jacob</given-names>
            </name>
          </person-group>
          <article-title>A power primer.</article-title>
          <source>Psychological Bulletin</source>
          <year iso-8601-date="1992">1992</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-04">2024</year>
            <month>06</month>
            <day>04</day>
          </date-in-citation>
          <volume>112</volume>
          <issue>1</issue>
          <issn>1939-1455, 0033-2909</issn>
          <pub-id pub-id-type="doi">10.1037/0033-2909.112.1.155</pub-id>
          <fpage>155</fpage>
          <lpage>159</lpage>
        </element-citation>
      </ref>
      <ref id="ref-cummingNewStatisticsWhy2014">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cumming</surname>
              <given-names>Geoff</given-names>
            </name>
          </person-group>
          <article-title>The New Statistics: Why and How</article-title>
          <source>Psychological Science</source>
          <year iso-8601-date="2014-01">2014</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-04">2024</year>
            <month>06</month>
            <day>04</day>
          </date-in-citation>
          <volume>25</volume>
          <issue>1</issue>
          <issn>0956-7976, 1467-9280</issn>
          <pub-id pub-id-type="doi">10.1177/0956797613504966</pub-id>
          <fpage>7</fpage>
          <lpage>29</lpage>
        </element-citation>
      </ref>
      <ref id="ref-debruineUnderstandingMixedEffectsModels2021">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>DeBruine</surname>
              <given-names>Lisa</given-names>
            </name>
            <name>
              <surname>Barr</surname>
              <given-names>Dale J.</given-names>
            </name>
          </person-group>
          <article-title>Understanding Mixed-Effects Models Through Data Simulation</article-title>
          <source>Advances in Methods and Practices in Psychological Science</source>
          <publisher-name>SAGE Publications Inc</publisher-name>
          <year iso-8601-date="2021-01">2021</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2022-07-14">2022</year>
            <month>07</month>
            <day>14</day>
          </date-in-citation>
          <volume>4</volume>
          <issue>1</issue>
          <issn>2515-2459</issn>
          <pub-id pub-id-type="doi">10.1177/2515245920965119</pub-id>
          <fpage>2515245920965119</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-deffnerCausalFrameworkCrossCultural2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Deffner</surname>
              <given-names>Dominik</given-names>
            </name>
            <name>
              <surname>Rohrer</surname>
              <given-names>Julia M.</given-names>
            </name>
            <name>
              <surname>McElreath</surname>
              <given-names>Richard</given-names>
            </name>
          </person-group>
          <article-title>A Causal Framework for Cross-Cultural Generalizability</article-title>
          <source>Advances in Methods and Practices in Psychological Science</source>
          <year iso-8601-date="2022-07">2022</year>
          <month>07</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2022-12-01">2022</year>
            <month>12</month>
            <day>01</day>
          </date-in-citation>
          <volume>5</volume>
          <issue>3</issue>
          <issn>2515-2459, 2515-2467</issn>
          <pub-id pub-id-type="doi">10.1177/25152459221106366</pub-id>
          <fpage>251524592211063</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-dmitrienkoTraditionalMultiplicityAdjustment2013">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dmitrienko</surname>
              <given-names>Alex</given-names>
            </name>
            <name>
              <surname>D’Agostino</surname>
              <given-names>Ralph</given-names>
            </name>
          </person-group>
          <article-title>Traditional multiplicity adjustment methods in clinical trials</article-title>
          <source>Statistics in Medicine</source>
          <year iso-8601-date="2013-12">2013</year>
          <month>12</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-18">2023</year>
            <month>08</month>
            <day>18</day>
          </date-in-citation>
          <volume>32</volume>
          <issue>29</issue>
          <issn>02776715</issn>
          <pub-id pub-id-type="doi">10.1002/sim.5990</pub-id>
          <fpage>5172</fpage>
          <lpage>5218</lpage>
        </element-citation>
      </ref>
      <ref id="ref-fahrmeirRegressionModelsMethods2021">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Fahrmeir</surname>
              <given-names>Ludwig</given-names>
            </name>
            <name>
              <surname>Kneib</surname>
              <given-names>Thomas</given-names>
            </name>
            <name>
              <surname>Lang</surname>
              <given-names>Stefan</given-names>
            </name>
            <name>
              <surname>Marx</surname>
              <given-names>Brian D.</given-names>
            </name>
          </person-group>
          <source>Regression: Models, Methods and Applications</source>
          <publisher-name>Springer Berlin Heidelberg</publisher-name>
          <publisher-loc>Berlin, Heidelberg</publisher-loc>
          <year iso-8601-date="2021">2021</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-18">2023</year>
            <month>08</month>
            <day>18</day>
          </date-in-citation>
          <isbn>978-3-662-63881-1 978-3-662-63882-8</isbn>
          <pub-id pub-id-type="doi">10.1007/978-3-662-63882-8</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-gelmanBayesianWorkflow2020">
        <element-citation>
          <person-group person-group-type="author">
            <name>
              <surname>Gelman</surname>
              <given-names>Andrew</given-names>
            </name>
            <name>
              <surname>Vehtari</surname>
              <given-names>Aki</given-names>
            </name>
            <name>
              <surname>Simpson</surname>
              <given-names>Daniel</given-names>
            </name>
            <name>
              <surname>Margossian</surname>
              <given-names>Charles C.</given-names>
            </name>
            <name>
              <surname>Carpenter</surname>
              <given-names>Bob</given-names>
            </name>
            <name>
              <surname>Yao</surname>
              <given-names>Yuling</given-names>
            </name>
            <name>
              <surname>Kennedy</surname>
              <given-names>Lauren</given-names>
            </name>
            <name>
              <surname>Gabry</surname>
              <given-names>Jonah</given-names>
            </name>
            <name>
              <surname>Bürkner</surname>
              <given-names>Paul-Christian</given-names>
            </name>
            <name>
              <surname>Modrák</surname>
              <given-names>Martin</given-names>
            </name>
          </person-group>
          <article-title>Bayesian Workflow</article-title>
          <publisher-name>arXiv</publisher-name>
          <year iso-8601-date="2020-11">2020</year>
          <month>11</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-04-09">2024</year>
            <month>04</month>
            <day>09</day>
          </date-in-citation>
          <uri>https://arxiv.org/abs/2011.01808</uri>
        </element-citation>
      </ref>
      <ref id="ref-gomilaMissingDataExperiments2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gomila</surname>
              <given-names>Robin</given-names>
            </name>
            <name>
              <surname>Clark</surname>
              <given-names>Chelsey S.</given-names>
            </name>
          </person-group>
          <article-title>Missing data in experiments: Challenges and solutions.</article-title>
          <source>Psychological Methods</source>
          <year iso-8601-date="2022-04">2022</year>
          <month>04</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-05">2024</year>
            <month>06</month>
            <day>05</day>
          </date-in-citation>
          <volume>27</volume>
          <issue>2</issue>
          <issn>1939-1463, 1082-989X</issn>
          <pub-id pub-id-type="doi">10.1037/met0000361</pub-id>
          <fpage>143</fpage>
          <lpage>155</lpage>
        </element-citation>
      </ref>
      <ref id="ref-greenSIMRPackagePower2016a">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Green</surname>
              <given-names>Peter</given-names>
            </name>
            <name>
              <surname>MacLeod</surname>
              <given-names>Catriona J.</given-names>
            </name>
          </person-group>
          <article-title>SIMR : An R package for power analysis of generalized linear mixed models by simulation</article-title>
          <source>Methods in Ecology and Evolution</source>
          <person-group person-group-type="editor">
            <name>
              <surname>Nakagawa</surname>
              <given-names>Shinichi</given-names>
            </name>
          </person-group>
          <year iso-8601-date="2016-04">2016</year>
          <month>04</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-08">2024</year>
            <month>06</month>
            <day>08</day>
          </date-in-citation>
          <volume>7</volume>
          <issue>4</issue>
          <issn>2041-210X, 2041-210X</issn>
          <pub-id pub-id-type="doi">10.1111/2041-210X.12504</pub-id>
          <fpage>493</fpage>
          <lpage>498</lpage>
        </element-citation>
      </ref>
      <ref id="ref-kainPracticalGuidePower2015">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kain</surname>
              <given-names>Morgan P.</given-names>
            </name>
            <name>
              <surname>Bolker</surname>
              <given-names>Ben M.</given-names>
            </name>
            <name>
              <surname>McCoy</surname>
              <given-names>Michael W.</given-names>
            </name>
          </person-group>
          <article-title>A practical guide and power analysis for GLMMs: Detecting among treatment variation in random effects</article-title>
          <source>PeerJ</source>
          <year iso-8601-date="2015-09">2015</year>
          <month>09</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-08">2024</year>
            <month>06</month>
            <day>08</day>
          </date-in-citation>
          <volume>3</volume>
          <issn>2167-8359</issn>
          <pub-id pub-id-type="doi">10.7717/peerj.1226</pub-id>
          <fpage>e1226</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-kelleySampleSizePlanning2006">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kelley</surname>
              <given-names>Ken</given-names>
            </name>
            <name>
              <surname>Rausch</surname>
              <given-names>Joseph R.</given-names>
            </name>
          </person-group>
          <article-title>Sample size planning for the standardized mean difference: Accuracy in parameter estimation via narrow confidence intervals.</article-title>
          <source>Psychological Methods</source>
          <year iso-8601-date="2006">2006</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-03-13">2024</year>
            <month>03</month>
            <day>13</day>
          </date-in-citation>
          <volume>11</volume>
          <issue>4</issue>
          <issn>1939-1463, 1082-989X</issn>
          <pub-id pub-id-type="doi">10.1037/1082-989X.11.4.363</pub-id>
          <fpage>363</fpage>
          <lpage>385</lpage>
        </element-citation>
      </ref>
      <ref id="ref-kingPointMinimalImportant2011">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>King</surname>
              <given-names>Madeleine T</given-names>
            </name>
          </person-group>
          <article-title>A point of minimal important difference (MID): A critique of terminology and methods</article-title>
          <source>Expert Review of Pharmacoeconomics &amp; Outcomes Research</source>
          <year iso-8601-date="2011-04">2011</year>
          <month>04</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-18">2023</year>
            <month>08</month>
            <day>18</day>
          </date-in-citation>
          <volume>11</volume>
          <issue>2</issue>
          <issn>1473-7167, 1744-8379</issn>
          <pub-id pub-id-type="doi">10.1586/erp.11.9</pub-id>
          <fpage>171</fpage>
          <lpage>184</lpage>
        </element-citation>
      </ref>
      <ref id="ref-kruschkeBayesianNewStatistics2018">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kruschke</surname>
              <given-names>John K.</given-names>
            </name>
            <name>
              <surname>Liddell</surname>
              <given-names>Torrin M.</given-names>
            </name>
          </person-group>
          <article-title>The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective</article-title>
          <source>Psychonomic Bulletin &amp; Review</source>
          <year iso-8601-date="2018-02">2018</year>
          <month>02</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-04">2024</year>
            <month>06</month>
            <day>04</day>
          </date-in-citation>
          <volume>25</volume>
          <issue>1</issue>
          <issn>1069-9384, 1531-5320</issn>
          <pub-id pub-id-type="doi">10.3758/s13423-016-1221-4</pub-id>
          <fpage>178</fpage>
          <lpage>206</lpage>
        </element-citation>
      </ref>
      <ref id="ref-kumleEstimatingPowerGeneralized2021">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kumle</surname>
              <given-names>Levi</given-names>
            </name>
            <name>
              <surname>Võ</surname>
              <given-names>Melissa L.-H.</given-names>
            </name>
            <name>
              <surname>Draschkow</surname>
              <given-names>Dejan</given-names>
            </name>
          </person-group>
          <article-title>Estimating power in (generalized) linear mixed models: An open introduction and tutorial in R</article-title>
          <source>Behavior Research Methods</source>
          <year iso-8601-date="2021-12">2021</year>
          <month>12</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2022-07-07">2022</year>
            <month>07</month>
            <day>07</day>
          </date-in-citation>
          <volume>53</volume>
          <issue>6</issue>
          <issn>1554-3528</issn>
          <pub-id pub-id-type="doi">10.3758/s13428-021-01546-0</pub-id>
          <fpage>2528</fpage>
          <lpage>2543</lpage>
        </element-citation>
      </ref>
      <ref id="ref-lafitSelectionNumberParticipants2021">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lafit</surname>
              <given-names>Ginette</given-names>
            </name>
            <name>
              <surname>Adolf</surname>
              <given-names>Janne K.</given-names>
            </name>
            <name>
              <surname>Dejonckheere</surname>
              <given-names>Egon</given-names>
            </name>
            <name>
              <surname>Myin-Germeys</surname>
              <given-names>Inez</given-names>
            </name>
            <name>
              <surname>Viechtbauer</surname>
              <given-names>Wolfgang</given-names>
            </name>
            <name>
              <surname>Ceulemans</surname>
              <given-names>Eva</given-names>
            </name>
          </person-group>
          <article-title>Selection of the Number of Participants in Intensive Longitudinal Studies: A User-Friendly Shiny App and Tutorial for Performing Power Analysis in Multilevel Regression Models That Account for Temporal Dependencies</article-title>
          <source>Advances in Methods and Practices in Psychological Science</source>
          <year iso-8601-date="2021-01">2021</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-08">2023</year>
            <month>08</month>
            <day>08</day>
          </date-in-citation>
          <volume>4</volume>
          <issue>1</issue>
          <issn>2515-2459, 2515-2467</issn>
          <pub-id pub-id-type="doi">10.1177/2515245920978738</pub-id>
          <fpage>251524592097873</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-lakensEquivalenceTestingPsychological2018">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lakens</surname>
              <given-names>Daniël</given-names>
            </name>
            <name>
              <surname>Scheel</surname>
              <given-names>Anne M.</given-names>
            </name>
            <name>
              <surname>Isager</surname>
              <given-names>Peder M.</given-names>
            </name>
          </person-group>
          <article-title>Equivalence Testing for Psychological Research: A Tutorial</article-title>
          <source>Advances in Methods and Practices in Psychological Science</source>
          <year iso-8601-date="2018-06">2018</year>
          <month>06</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-05">2024</year>
            <month>06</month>
            <day>05</day>
          </date-in-citation>
          <volume>1</volume>
          <issue>2</issue>
          <issn>2515-2459, 2515-2467</issn>
          <pub-id pub-id-type="doi">10.1177/2515245918770963</pub-id>
          <fpage>259</fpage>
          <lpage>269</lpage>
        </element-citation>
      </ref>
      <ref id="ref-lakensImprovingYourStatistical2022">
        <element-citation>
          <person-group person-group-type="author">
            <name>
              <surname>Lakens</surname>
              <given-names>Daniël</given-names>
            </name>
          </person-group>
          <article-title>Improving Your Statistical Inferences</article-title>
          <publisher-name>Zenodo</publisher-name>
          <year iso-8601-date="2022-04">2022</year>
          <month>04</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-09">2023</year>
            <month>08</month>
            <day>09</day>
          </date-in-citation>
          <pub-id pub-id-type="doi">10.5281/ZENODO.6409077</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-lakensJustifyYourAlpha2018">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lakens</surname>
              <given-names>Daniël</given-names>
            </name>
            <name>
              <surname>Adolfi</surname>
              <given-names>Federico G.</given-names>
            </name>
            <name>
              <surname>Albers</surname>
              <given-names>Casper J.</given-names>
            </name>
            <name>
              <surname>Anvari</surname>
              <given-names>Farid</given-names>
            </name>
            <name>
              <surname>Apps</surname>
              <given-names>Matthew A. J.</given-names>
            </name>
            <name>
              <surname>Argamon</surname>
              <given-names>Shlomo E.</given-names>
            </name>
            <name>
              <surname>Baguley</surname>
              <given-names>Thom</given-names>
            </name>
            <name>
              <surname>Becker</surname>
              <given-names>Raymond B.</given-names>
            </name>
            <name>
              <surname>Benning</surname>
              <given-names>Stephen D.</given-names>
            </name>
            <name>
              <surname>Bradford</surname>
              <given-names>Daniel E.</given-names>
            </name>
            <name>
              <surname>Buchanan</surname>
              <given-names>Erin M.</given-names>
            </name>
            <name>
              <surname>Caldwell</surname>
              <given-names>Aaron R.</given-names>
            </name>
            <name>
              <surname>Van Calster</surname>
              <given-names>Ben</given-names>
            </name>
            <name>
              <surname>Carlsson</surname>
              <given-names>Rickard</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Sau-Chin</given-names>
            </name>
            <name>
              <surname>Chung</surname>
              <given-names>Bryan</given-names>
            </name>
            <name>
              <surname>Colling</surname>
              <given-names>Lincoln J.</given-names>
            </name>
            <name>
              <surname>Collins</surname>
              <given-names>Gary S.</given-names>
            </name>
            <name>
              <surname>Crook</surname>
              <given-names>Zander</given-names>
            </name>
            <name>
              <surname>Cross</surname>
              <given-names>Emily S.</given-names>
            </name>
            <name>
              <surname>Daniels</surname>
              <given-names>Sameera</given-names>
            </name>
            <name>
              <surname>Danielsson</surname>
              <given-names>Henrik</given-names>
            </name>
            <name>
              <surname>DeBruine</surname>
              <given-names>Lisa</given-names>
            </name>
            <name>
              <surname>Dunleavy</surname>
              <given-names>Daniel J.</given-names>
            </name>
            <name>
              <surname>Earp</surname>
              <given-names>Brian D.</given-names>
            </name>
            <name>
              <surname>Feist</surname>
              <given-names>Michele I.</given-names>
            </name>
            <name>
              <surname>Ferrell</surname>
              <given-names>Jason D.</given-names>
            </name>
            <name>
              <surname>Field</surname>
              <given-names>James G.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>Nicholas W.</given-names>
            </name>
            <name>
              <surname>Friesen</surname>
              <given-names>Amanda</given-names>
            </name>
            <name>
              <surname>Gomes</surname>
              <given-names>Caio</given-names>
            </name>
            <name>
              <surname>Gonzalez-Marquez</surname>
              <given-names>Monica</given-names>
            </name>
            <name>
              <surname>Grange</surname>
              <given-names>James A.</given-names>
            </name>
            <name>
              <surname>Grieve</surname>
              <given-names>Andrew P.</given-names>
            </name>
            <name>
              <surname>Guggenberger</surname>
              <given-names>Robert</given-names>
            </name>
            <name>
              <surname>Grist</surname>
              <given-names>James</given-names>
            </name>
            <name>
              <surname>van Harmelen</surname>
              <given-names>Anne-Laura</given-names>
            </name>
            <name>
              <surname>Hasselman</surname>
              <given-names>Fred</given-names>
            </name>
            <name>
              <surname>Hochard</surname>
              <given-names>Kevin D.</given-names>
            </name>
            <name>
              <surname>Hoffarth</surname>
              <given-names>Mark R.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>Nicholas P.</given-names>
            </name>
            <name>
              <surname>Ingre</surname>
              <given-names>Michael</given-names>
            </name>
            <name>
              <surname>Isager</surname>
              <given-names>Peder M.</given-names>
            </name>
            <name>
              <surname>Isotalus</surname>
              <given-names>Hanna K.</given-names>
            </name>
            <name>
              <surname>Johansson</surname>
              <given-names>Christer</given-names>
            </name>
            <name>
              <surname>Juszczyk</surname>
              <given-names>Konrad</given-names>
            </name>
            <name>
              <surname>Kenny</surname>
              <given-names>David A.</given-names>
            </name>
            <name>
              <surname>Khalil</surname>
              <given-names>Ahmed A.</given-names>
            </name>
            <name>
              <surname>Konat</surname>
              <given-names>Barbara</given-names>
            </name>
            <name>
              <surname>Lao</surname>
              <given-names>Junpeng</given-names>
            </name>
            <name>
              <surname>Larsen</surname>
              <given-names>Erik Gahner</given-names>
            </name>
            <name>
              <surname>Lodder</surname>
              <given-names>Gerine M. A.</given-names>
            </name>
            <name>
              <surname>Lukavský</surname>
              <given-names>Jiří</given-names>
            </name>
            <name>
              <surname>Madan</surname>
              <given-names>Christopher R.</given-names>
            </name>
            <name>
              <surname>Manheim</surname>
              <given-names>David</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>Stephen R.</given-names>
            </name>
            <name>
              <surname>Martin</surname>
              <given-names>Andrea E.</given-names>
            </name>
            <name>
              <surname>Mayo</surname>
              <given-names>Deborah G.</given-names>
            </name>
            <name>
              <surname>McCarthy</surname>
              <given-names>Randy J.</given-names>
            </name>
            <name>
              <surname>McConway</surname>
              <given-names>Kevin</given-names>
            </name>
            <name>
              <surname>McFarland</surname>
              <given-names>Colin</given-names>
            </name>
            <name>
              <surname>Nio</surname>
              <given-names>Amanda Q. X.</given-names>
            </name>
            <name>
              <surname>Nilsonne</surname>
              <given-names>Gustav</given-names>
            </name>
            <name>
              <surname>de Oliveira</surname>
              <given-names>Cilene Lino</given-names>
            </name>
            <name>
              <surname>de Xivry</surname>
              <given-names>Jean-Jacques Orban</given-names>
            </name>
            <name>
              <surname>Parsons</surname>
              <given-names>Sam</given-names>
            </name>
            <name>
              <surname>Pfuhl</surname>
              <given-names>Gerit</given-names>
            </name>
            <name>
              <surname>Quinn</surname>
              <given-names>Kimberly A.</given-names>
            </name>
            <name>
              <surname>Sakon</surname>
              <given-names>John J.</given-names>
            </name>
            <name>
              <surname>Saribay</surname>
              <given-names>S. Adil</given-names>
            </name>
            <name>
              <surname>Schneider</surname>
              <given-names>Iris K.</given-names>
            </name>
            <name>
              <surname>Selvaraju</surname>
              <given-names>Manojkumar</given-names>
            </name>
            <name>
              <surname>Sjoerds</surname>
              <given-names>Zsuzsika</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>Samuel G.</given-names>
            </name>
            <name>
              <surname>Smits</surname>
              <given-names>Tim</given-names>
            </name>
            <name>
              <surname>Spies</surname>
              <given-names>Jeffrey R.</given-names>
            </name>
            <name>
              <surname>Sreekumar</surname>
              <given-names>Vishnu</given-names>
            </name>
            <name>
              <surname>Steltenpohl</surname>
              <given-names>Crystal N.</given-names>
            </name>
            <name>
              <surname>Stenhouse</surname>
              <given-names>Neil</given-names>
            </name>
            <name>
              <surname>Świątkowski</surname>
              <given-names>Wojciech</given-names>
            </name>
            <name>
              <surname>Vadillo</surname>
              <given-names>Miguel A.</given-names>
            </name>
            <name>
              <surname>Van Assen</surname>
              <given-names>Marcel A. L. M.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>Matt N.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>Samantha E.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>Donald R.</given-names>
            </name>
            <name>
              <surname>Yarkoni</surname>
              <given-names>Tal</given-names>
            </name>
            <name>
              <surname>Ziano</surname>
              <given-names>Ignazio</given-names>
            </name>
            <name>
              <surname>Zwaan</surname>
              <given-names>Rolf A.</given-names>
            </name>
          </person-group>
          <article-title>Justify your alpha</article-title>
          <source>Nature Human Behaviour</source>
          <year iso-8601-date="2018-03">2018</year>
          <month>03</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2022-03-17">2022</year>
            <month>03</month>
            <day>17</day>
          </date-in-citation>
          <volume>2</volume>
          <issue>3</issue>
          <issn>2397-3374</issn>
          <pub-id pub-id-type="doi">10.1038/s41562-018-0311-x</pub-id>
          <fpage>168</fpage>
          <lpage>171</lpage>
        </element-citation>
      </ref>
      <ref id="ref-lakensSampleSizeJustification2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lakens</surname>
              <given-names>Daniël</given-names>
            </name>
          </person-group>
          <article-title>Sample Size Justification</article-title>
          <source>Collabra: Psychology</source>
          <year iso-8601-date="2022-03">2022</year>
          <month>03</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-04-24">2023</year>
            <month>04</month>
            <day>24</day>
          </date-in-citation>
          <volume>8</volume>
          <issue>1</issue>
          <issn>2474-7394</issn>
          <pub-id pub-id-type="doi">10.1525/collabra.33267</pub-id>
          <fpage>33267</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-lanePowerStrugglesEstimating2018">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lane</surname>
              <given-names>Sean P.</given-names>
            </name>
            <name>
              <surname>Hennes</surname>
              <given-names>Erin P.</given-names>
            </name>
          </person-group>
          <article-title>Power struggles: Estimating sample size for multilevel relationships research</article-title>
          <source>Journal of Social and Personal Relationships</source>
          <year iso-8601-date="2018-01">2018</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-08">2023</year>
            <month>08</month>
            <day>08</day>
          </date-in-citation>
          <volume>35</volume>
          <issue>1</issue>
          <issn>0265-4075, 1460-3608</issn>
          <pub-id pub-id-type="doi">10.1177/0265407517710342</pub-id>
          <fpage>7</fpage>
          <lpage>31</lpage>
        </element-citation>
      </ref>
      <ref id="ref-littleStatisticalAnalysisMissing2014">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Little</surname>
              <given-names>Roderick J. A.</given-names>
            </name>
            <name>
              <surname>Rubin</surname>
              <given-names>Donald B.</given-names>
            </name>
          </person-group>
          <source>Statistical Analysis with Missing Data</source>
          <publisher-name>Wiley</publisher-name>
          <publisher-loc>Somerset</publisher-loc>
          <year iso-8601-date="2014">2014</year>
          <edition>2nd ed</edition>
          <isbn>978-1-118-62588-0</isbn>
        </element-citation>
      </ref>
      <ref id="ref-lundbergWhatYourEstimand2021">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lundberg</surname>
              <given-names>Ian</given-names>
            </name>
            <name>
              <surname>Johnson</surname>
              <given-names>Rebecca</given-names>
            </name>
            <name>
              <surname>Stewart</surname>
              <given-names>Brandon M.</given-names>
            </name>
          </person-group>
          <article-title>What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory</article-title>
          <source>American Sociological Review</source>
          <year iso-8601-date="2021-06">2021</year>
          <month>06</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-03-13">2024</year>
            <month>03</month>
            <day>13</day>
          </date-in-citation>
          <volume>86</volume>
          <issue>3</issue>
          <issn>0003-1224, 1939-8271</issn>
          <pub-id pub-id-type="doi">10.1177/00031224211004187</pub-id>
          <fpage>532</fpage>
          <lpage>565</lpage>
        </element-citation>
      </ref>
      <ref id="ref-maxwellSampleSizePlanning2008">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Maxwell</surname>
              <given-names>Scott E.</given-names>
            </name>
            <name>
              <surname>Kelley</surname>
              <given-names>Ken</given-names>
            </name>
            <name>
              <surname>Rausch</surname>
              <given-names>Joseph R.</given-names>
            </name>
          </person-group>
          <article-title>Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation</article-title>
          <source>Annual Review of Psychology</source>
          <year iso-8601-date="2008-01">2008</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-08">2023</year>
            <month>08</month>
            <day>08</day>
          </date-in-citation>
          <volume>59</volume>
          <issue>1</issue>
          <issn>0066-4308, 1545-2085</issn>
          <pub-id pub-id-type="doi">10.1146/annurev.psych.59.103006.093735</pub-id>
          <fpage>537</fpage>
          <lpage>563</lpage>
        </element-citation>
      </ref>
      <ref id="ref-mcelreathStatisticalRethinkingBayesian2020">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>McElreath</surname>
              <given-names>Richard</given-names>
            </name>
          </person-group>
          <source>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</source>
          <publisher-name>Chapman and Hall/CRC</publisher-name>
          <year iso-8601-date="2020-03">2020</year>
          <month>03</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-04">2024</year>
            <month>06</month>
            <day>04</day>
          </date-in-citation>
          <edition>2</edition>
          <isbn>978-0-429-02960-8</isbn>
          <pub-id pub-id-type="doi">10.1201/9780429029608</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-murayamaSummarystatisticsbasedPowerAnalysis2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Murayama</surname>
              <given-names>Kou</given-names>
            </name>
            <name>
              <surname>Usami</surname>
              <given-names>Satoshi</given-names>
            </name>
            <name>
              <surname>Sakaki</surname>
              <given-names>Michiko</given-names>
            </name>
          </person-group>
          <article-title>Summary-statistics-based power analysis: A new and practical method to determine sample size for mixed-effects modeling.</article-title>
          <source>Psychological Methods</source>
          <year iso-8601-date="2022-01">2022</year>
          <month>01</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-08-07">2023</year>
            <month>08</month>
            <day>07</day>
          </date-in-citation>
          <issn>1939-1463, 1082-989X</issn>
          <pub-id pub-id-type="doi">10.1037/met0000330</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-preacherComputationalToolsProbing2006">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Preacher</surname>
              <given-names>Kristopher J.</given-names>
            </name>
            <name>
              <surname>Curran</surname>
              <given-names>Patrick J.</given-names>
            </name>
            <name>
              <surname>Bauer</surname>
              <given-names>Daniel J.</given-names>
            </name>
          </person-group>
          <article-title>Computational Tools for Probing Interactions in Multiple Linear Regression, Multilevel Modeling, and Latent Curve Analysis</article-title>
          <source>Journal of Educational and Behavioral Statistics</source>
          <year iso-8601-date="2006-12">2006</year>
          <month>12</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-05">2024</year>
            <month>06</month>
            <day>05</day>
          </date-in-citation>
          <volume>31</volume>
          <issue>4</issue>
          <issn>1076-9986, 1935-1054</issn>
          <pub-id pub-id-type="doi">10.3102/10769986031004437</pub-id>
          <fpage>437</fpage>
          <lpage>448</lpage>
        </element-citation>
      </ref>
      <ref id="ref-riesthuisSimulationBasedPowerAnalyses2024">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Riesthuis</surname>
              <given-names>Paul</given-names>
            </name>
          </person-group>
          <article-title>Simulation-Based Power Analyses for the Smallest Effect Size of Interest: A Confidence-Interval Approach for Minimum-Effect and Equivalence Testing</article-title>
          <source>Advances in Methods and Practices in Psychological Science</source>
          <publisher-name>SAGE Publications Inc</publisher-name>
          <year iso-8601-date="2024-04">2024</year>
          <month>04</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-04-23">2024</year>
            <month>04</month>
            <day>23</day>
          </date-in-citation>
          <volume>7</volume>
          <issue>2</issue>
          <issn>2515-2459</issn>
          <pub-id pub-id-type="doi">10.1177/25152459241240722</pub-id>
          <fpage>25152459241240722</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-schadHowCapitalizePriori2020">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Schad</surname>
              <given-names>Daniel J.</given-names>
            </name>
            <name>
              <surname>Vasishth</surname>
              <given-names>Shravan</given-names>
            </name>
            <name>
              <surname>Hohenstein</surname>
              <given-names>Sven</given-names>
            </name>
            <name>
              <surname>Kliegl</surname>
              <given-names>Reinhold</given-names>
            </name>
          </person-group>
          <article-title>How to capitalize on a priori contrasts in linear (mixed) models: A tutorial</article-title>
          <source>Journal of Memory and Language</source>
          <year iso-8601-date="2020-02">2020</year>
          <month>02</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-05">2024</year>
            <month>06</month>
            <day>05</day>
          </date-in-citation>
          <volume>110</volume>
          <issn>0749596X</issn>
          <pub-id pub-id-type="doi">10.1016/j.jml.2019.104038</pub-id>
          <fpage>104038</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-uyguntuncEpistemicPragmaticFunction2023">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Uygun Tunç</surname>
              <given-names>Duygu</given-names>
            </name>
            <name>
              <surname>Tunç</surname>
              <given-names>Mehmet Necip</given-names>
            </name>
            <name>
              <surname>Lakens</surname>
              <given-names>Daniël</given-names>
            </name>
          </person-group>
          <article-title>The epistemic and pragmatic function of dichotomous claims based on statistical hypothesis tests</article-title>
          <source>Theory &amp; Psychology</source>
          <year iso-8601-date="2023-06">2023</year>
          <month>06</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-06-04">2024</year>
            <month>06</month>
            <day>04</day>
          </date-in-citation>
          <volume>33</volume>
          <issue>3</issue>
          <issn>0959-3543, 1461-7447</issn>
          <pub-id pub-id-type="doi">10.1177/09593543231160112</pub-id>
          <fpage>403</fpage>
          <lpage>423</lpage>
        </element-citation>
      </ref>
      <ref id="ref-westfallStatisticalPowerOptimal2014">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Westfall</surname>
              <given-names>Jacob</given-names>
            </name>
            <name>
              <surname>Kenny</surname>
              <given-names>David A.</given-names>
            </name>
            <name>
              <surname>Judd</surname>
              <given-names>Charles M.</given-names>
            </name>
          </person-group>
          <article-title>Statistical power and optimal design in experiments in which samples of participants respond to samples of stimuli</article-title>
          <source>Journal of Experimental Psychology: General</source>
          <publisher-name>American Psychological Association</publisher-name>
          <publisher-loc>US</publisher-loc>
          <year iso-8601-date="2014">2014</year>
          <volume>143</volume>
          <issn>1939-2222</issn>
          <pub-id pub-id-type="doi">10.1037/xge0000014</pub-id>
          <fpage>2020</fpage>
          <lpage>2045</lpage>
        </element-citation>
      </ref>
      <ref id="ref-wickhamDataScienceImport2023">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Wickham</surname>
              <given-names>Hadley</given-names>
            </name>
            <name>
              <surname>Çetinkaya-Rundel</surname>
              <given-names>Mine</given-names>
            </name>
            <name>
              <surname>Grolemund</surname>
              <given-names>Garrett</given-names>
            </name>
          </person-group>
          <source>R for data science: Import, tidy, transform, visualize, and model data</source>
          <publisher-name>O’Reilly</publisher-name>
          <publisher-loc>Beijing Boston Farnham Sebastopol Tokyo</publisher-loc>
          <year iso-8601-date="2023">2023</year>
          <edition>2nd edition</edition>
          <isbn>978-1-4920-9740-2</isbn>
        </element-citation>
      </ref>
      <ref id="ref-wickhamWelcomeTidyverse2019">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wickham</surname>
              <given-names>Hadley</given-names>
            </name>
            <name>
              <surname>Averick</surname>
              <given-names>Mara</given-names>
            </name>
            <name>
              <surname>Bryan</surname>
              <given-names>Jennifer</given-names>
            </name>
            <name>
              <surname>Chang</surname>
              <given-names>Winston</given-names>
            </name>
            <name>
              <surname>McGowan</surname>
              <given-names>Lucy</given-names>
            </name>
            <name>
              <surname>François</surname>
              <given-names>Romain</given-names>
            </name>
            <name>
              <surname>Grolemund</surname>
              <given-names>Garrett</given-names>
            </name>
            <name>
              <surname>Hayes</surname>
              <given-names>Alex</given-names>
            </name>
            <name>
              <surname>Henry</surname>
              <given-names>Lionel</given-names>
            </name>
            <name>
              <surname>Hester</surname>
              <given-names>Jim</given-names>
            </name>
            <name>
              <surname>Kuhn</surname>
              <given-names>Max</given-names>
            </name>
            <name>
              <surname>Pedersen</surname>
              <given-names>Thomas</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>Evan</given-names>
            </name>
            <name>
              <surname>Bache</surname>
              <given-names>Stephan</given-names>
            </name>
            <name>
              <surname>Müller</surname>
              <given-names>Kirill</given-names>
            </name>
            <name>
              <surname>Ooms</surname>
              <given-names>Jeroen</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>David</given-names>
            </name>
            <name>
              <surname>Seidel</surname>
              <given-names>Dana</given-names>
            </name>
            <name>
              <surname>Spinu</surname>
              <given-names>Vitalie</given-names>
            </name>
            <name>
              <surname>Takahashi</surname>
              <given-names>Kohske</given-names>
            </name>
            <name>
              <surname>Vaughan</surname>
              <given-names>Davis</given-names>
            </name>
            <name>
              <surname>Wilke</surname>
              <given-names>Claus</given-names>
            </name>
            <name>
              <surname>Woo</surname>
              <given-names>Kara</given-names>
            </name>
            <name>
              <surname>Yutani</surname>
              <given-names>Hiroaki</given-names>
            </name>
          </person-group>
          <article-title>Welcome to the Tidyverse</article-title>
          <source>Journal of Open Source Software</source>
          <year iso-8601-date="2019-11">2019</year>
          <month>11</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2024-05-21">2024</year>
            <month>05</month>
            <day>21</day>
          </date-in-citation>
          <volume>4</volume>
          <issue>43</issue>
          <issn>2475-9066</issn>
          <pub-id pub-id-type="doi">10.21105/joss.01686</pub-id>
          <fpage>1686</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-yarkoniGeneralizabilityCrisis2022">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yarkoni</surname>
              <given-names>Tal</given-names>
            </name>
          </person-group>
          <article-title>The generalizability crisis</article-title>
          <source>Behavioral and Brain Sciences</source>
          <year iso-8601-date="2022">2022</year>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2022-11-30">2022</year>
            <month>11</month>
            <day>30</day>
          </date-in-citation>
          <volume>45</volume>
          <issn>0140-525X, 1469-1825</issn>
          <pub-id pub-id-type="doi">10.1017/S0140525X20001685</pub-id>
          <fpage>e1</fpage>
          <lpage/>
        </element-citation>
      </ref>
      <ref id="ref-zimmerSampleSizePlanning2022">
        <element-citation>
          <person-group person-group-type="author">
            <name>
              <surname>Zimmer</surname>
              <given-names>Felix</given-names>
            </name>
            <name>
              <surname>Henninger</surname>
              <given-names>Mirka</given-names>
            </name>
            <name>
              <surname>Debelak</surname>
              <given-names>Rudolf</given-names>
            </name>
          </person-group>
          <article-title>Sample Size Planning for Complex Study Designs: A Tutorial for the mlpwr Package</article-title>
          <publisher-name>PsyArXiv</publisher-name>
          <year iso-8601-date="2022-10">2022</year>
          <month>10</month>
          <date-in-citation content-type="access-date">
            <year iso-8601-date="2023-04-24">2023</year>
            <month>04</month>
            <day>24</day>
          </date-in-citation>
          <pub-id pub-id-type="doi">10.31234/osf.io/r9w6t</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-R-faux">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>DeBruine</surname>
              <given-names>Lisa</given-names>
            </name>
          </person-group>
          <source>Faux: Simulation for factorial designs</source>
          <publisher-name>Zenodo</publisher-name>
          <year iso-8601-date="2023">2023</year>
          <uri>https://debruine.github.io/faux/</uri>
          <pub-id pub-id-type="doi">10.5281/zenodo.2669586</pub-id>
        </element-citation>
      </ref>
      <ref id="ref-R-furrr">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Vaughan</surname>
              <given-names>Davis</given-names>
            </name>
            <name>
              <surname>Dancho</surname>
              <given-names>Matt</given-names>
            </name>
          </person-group>
          <source>Furrr: Apply mapping functions in parallel using futures</source>
          <year iso-8601-date="2022">2022</year>
          <uri>https://github.com/DavisVaughan/furrr</uri>
        </element-citation>
      </ref>
      <ref id="ref-R-RJ-2021-048">
        <element-citation publication-type="article-journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bengtsson</surname>
              <given-names>Henrik</given-names>
            </name>
          </person-group>
          <article-title>A unifying framework for parallel and distributed processing in r using futures</article-title>
          <source>The R Journal</source>
          <year iso-8601-date="2021">2021</year>
          <volume>13</volume>
          <issue>2</issue>
          <uri>https://doi.org/10.32614/RJ-2021-048</uri>
          <pub-id pub-id-type="doi">10.32614/RJ-2021-048</pub-id>
          <fpage>208</fpage>
          <lpage>227</lpage>
        </element-citation>
      </ref>
      <ref id="ref-R-marginaleffects">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Arel-Bundock</surname>
              <given-names>Vincent</given-names>
            </name>
          </person-group>
          <source>Marginaleffects: Predictions, comparisons, slopes, marginal means, and hypothesis tests</source>
          <year iso-8601-date="2024">2024</year>
          <uri>https://marginaleffects.com/</uri>
        </element-citation>
      </ref>
    </ref-list>
    <fn-group>
      <fn id="fn1">
        <label>1</label>
        <p>Note that a different estimand would be the
    so-called average treatment effect (ATE). For the ATE, the
    probability contrast is defined for each combination of expert and
    scan, and then these contrasts are averaged across all experts and
    scans from the target population
    (<xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021" ref-type="bibr">Lundberg
    et al., 2021</xref>).</p>
      </fn>
      <fn id="fn2">
        <label>2</label>
        <p>The faux package
    (<xref alt="DeBruine, 2023" rid="ref-R-faux" ref-type="bibr">DeBruine,
    2023</xref>) contains useful functions when simulating factorial
    designs, including random effects.</p>
      </fn>
      <fn id="fn3">
        <label>3</label>
        <p>For Bayesian GLMMs, the brms R package is
    currently the most prominent option
    (<xref alt="Bürkner, 2017" rid="ref-burknerBrmsPackageBayesian2017" ref-type="bibr">Bürkner,
    2017</xref>).</p>
      </fn>
      <fn id="fn4">
        <label>4</label>
        <p>This code was inspired by the “Mixed Design
    Simulation” vignette of the faux package at
    <ext-link ext-link-type="uri" xlink:href="https://debruine.github.io/faux/articles/sim_mixed.html">https://debruine.github.io/faux/articles/sim_mixed.html</ext-link>.</p>
      </fn>
    </fn-group>
  </back>
  <sub-article article-type="notebook" id="nb-6-nb-article">
    <front-stub>
      <title-group>
        <article-title>A Tutorial on Tailored Simulation-Based Sample Size
Planning for Experimental Designs with Generalized Linear Mixed
Models</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" equal-contrib="yes">
          <contrib-id contrib-id-type="orcid">0000-0002-2388-553X</contrib-id>
          <name>
            <surname>Pargent</surname>
            <given-names>Florian</given-names>
          </name>
          <string-name>Florian Pargent</string-name>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">formal
analysis</role>
          <role vocab="https://credit.niso.org" vocab-term="methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">methodology</role>
          <role vocab="https://credit.niso.org" vocab-term="visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">visualization</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu-nb-article">a</xref>
          <xref ref-type="deceased" rid="equal-1-nb-article">‡</xref>
        </contrib>
        <contrib contrib-type="author" equal-contrib="yes" corresp="yes">
          <contrib-id contrib-id-type="orcid">0000-0001-6728-2063</contrib-id>
          <name>
            <surname>Koch</surname>
            <given-names>Timo K.</given-names>
          </name>
          <string-name>Timo K. Koch</string-name>
          <email>timo.koch@unisg.ch</email>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">formal
analysis</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu-nb-article">a</xref>
          <xref ref-type="aff" rid="aff-2-nb-article">b</xref>
          <xref ref-type="corresp" rid="cor-2-nb-article">*</xref>
          <xref ref-type="deceased" rid="equal-2-nb-article">‡</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Kleine</surname>
            <given-names>Anne-Kathrin</given-names>
          </name>
          <string-name>Anne-Kathrin Kleine</string-name>
          <role vocab="https://credit.niso.org" vocab-term="formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">formal
analysis</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu-nb-article">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Lermer</surname>
            <given-names>Eva</given-names>
          </name>
          <string-name>Eva Lermer</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">conceptualization</role>
          <role>funding aquisition</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu-nb-article">a</xref>
          <xref ref-type="aff" rid="aff-3-nb-article">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Gaube</surname>
            <given-names>Susanne</given-names>
          </name>
          <string-name>Susanne Gaube</string-name>
          <role vocab="https://credit.niso.org" vocab-term="conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">conceptualization</role>
          <role vocab="https://credit.niso.org" vocab-term="supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">supervision</role>
          <role vocab="https://credit.niso.org" vocab-term="writing – review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">editing</role>
          <xref ref-type="aff" rid="lmu-nb-article">a</xref>
          <xref ref-type="aff" rid="aff-4-nb-article">d</xref>
        </contrib>
      </contrib-group>
      <aff id="lmu-nb-article">
        <institution content-type="dept">Department of Psychology</institution>
        <institution-wrap>
          <institution>LMU Munich</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-2-nb-article">
        <institution content-type="dept">Institute of Behavioral Science &amp;
Technology</institution>
        <institution-wrap>
          <institution>University of St. Gallen</institution>
        </institution-wrap>
        <addr-line>Torstrasse 25</addr-line>
        <city>St. Gallen</city>
        <country>Switzerland</country>
        <postal-code>9000</postal-code>
      </aff>
      <aff id="aff-3-nb-article">
        <institution content-type="dept">Department of Business
Psychology</institution>
        <institution-wrap>
          <institution>Technical University of Applied Sciences
Augsburg</institution>
        </institution-wrap>
      </aff>
      <aff id="aff-4-nb-article">
        <institution content-type="dept">Global Business School for
Health</institution>
        <institution-wrap>
          <institution>University College London</institution>
        </institution-wrap>
      </aff>
      <author-notes>
        <corresp id="cor-2-nb-article">timo.koch@unisg.ch</corresp>
        <fn id="equal-1-nb-article" fn-type="equal" symbol="‡">
          <p>Florian
Pargent</p>
        </fn>
        <fn id="equal-2-nb-article" fn-type="equal" symbol="‡">
          <p>Timo K.
Koch</p>
        </fn>
      </author-notes>
      <abstract>
When planning experimental research, determining an appropriate sample
size and using suitable statistical models are crucial for robust and
informative results. The recent replication crisis underlines the need
for more rigorous statistical methodology and adequately powered
designs. Generalized linear mixed models (GLMMs) offer a flexible
statistical framework to analyze experimental data with complex (e.g.,
dependent and hierarchical) data structures. However, available methods
and software for a priori sample size planning for GLMMs are often
limited to specific designs. Tailored data simulation approaches are a
more flexible alternative. Based on a practical case study, the current
tutorial equips researchers with a step-by-step guide and corresponding
code for conducting tailored a priori sample size planning with GLMMs.
We not only focus on power analysis but also explain how to use the
precision of parameter estimates to determine appropriate sample sizes.
We conclude with an outlook on the increasing importance of
simulation-based sample size planning.
</abstract>
    </front-stub>
    <body>
      <sec specific-use="notebook-content">
        <code language="r script">library("tidyverse")</code>
        <boxed-text>
          <preformat>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</preformat>
        </boxed-text>
        <code language="r script">library("faux")</code>
        <boxed-text>
          <preformat>
************
Welcome to faux. For support and examples visit:
https://debruine.github.io/faux/
- Get and set global package options with: faux_options()
************</preformat>
        </boxed-text>
        <code language="r script">library("lme4")</code>
        <boxed-text>
          <preformat>Loading required package: Matrix

Attaching package: 'Matrix'

The following objects are masked from 'package:tidyr':

    expand, pack, unpack</preformat>
        </boxed-text>
        <code language="r script">library("multcomp")</code>
        <boxed-text>
          <preformat>Loading required package: mvtnorm
Loading required package: survival
Loading required package: TH.data
Loading required package: MASS

Attaching package: 'MASS'

The following object is masked from 'package:dplyr':

    select


Attaching package: 'TH.data'

The following object is masked from 'package:MASS':

    geyser</preformat>
        </boxed-text>
        <code language="r script">library("marginaleffects")
library("tinytable")
library("future")</code>
        <boxed-text>
          <preformat>
Attaching package: 'future'

The following object is masked from 'package:survival':

    cluster</preformat>
        </boxed-text>
        <code language="r script">library("furrr")
library("binom")
library("papaja")</code>
        <boxed-text>
          <preformat>Loading required package: tinylabels</preformat>
        </boxed-text>
        <code language="r script">r_refs("r-references.bib", append = FALSE)</code>
      </sec>
      <sec id="introduction-nb-article">
        <title>Introduction</title>
        <p>When planning experimental research, it is essential to determine
  an appropriate sample size and to use appropriate statistical models
  to analyze the data to ensure that the results obtained are both
  robust and informative
  (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
  2022a</xref>). The recent replication crisis has illustrated many
  challenges surrounding the reproducibility and reliability of study
  findings
  (<xref alt="Yarkoni, 2022" rid="ref-yarkoniGeneralizabilityCrisis2022-nb-article" ref-type="bibr">Yarkoni,
  2022</xref>). As a result, there is a growing need for more rigorous
  statistical methodology and the adoption of adequately powered
  experimental designs. Multiple easy-to-use software solutions exist
  for simple statistical models and experimental designs. However, many
  researchers lack the skills and tools to conduct “a priori” (i.e.,
  before data collection) sample size planning for more complex research
  designs such as flexible generalized linear mixed models (GLMM)
  framework. In the present work, we provide a tutorial on how to
  determine adequate sample sizes by performing tailored
  simulation-based sample size planning for GLMMs. After introducing
  some theoretical background on sample size planning, we review
  existing software solutions in R and discuss under which circumstances
  tailored data simulations are necessary. Then we describe general
  steps and decisions involved in tailored data simulation. To
  illustrate the details of these steps, we finish with a hypothetical
  case study from the field of human-AI (artificial intelligence)
  interaction research.</p>
        <p>To benefit most of this tutorial paper, we recommend readers to
  familiarise themselves with basic statistical concepts like hypothesis
  tests (HTs) and their statistical power as well as confidence
  intervals (CIs) and their precision
  (<xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021-nb-article" ref-type="bibr">Kumle
  et al., 2021</xref>;
  <xref alt="Lakens, 2022b" rid="ref-lakensImprovingYourStatistical2022-nb-article" ref-type="bibr">Lakens,
  2022b</xref>;
  <xref alt="Riesthuis, 2024" rid="ref-riesthuisSimulationBasedPowerAnalyses2024-nb-article" ref-type="bibr">Riesthuis,
  2024</xref>). Some knowledge of causal inference is useful but not
  necessary
  (<xref alt="Deffner et al., 2022" rid="ref-deffnerCausalFrameworkCrossCultural2022-nb-article" ref-type="bibr">Deffner
  et al., 2022</xref>;
  <xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021-nb-article" ref-type="bibr">Lundberg
  et al., 2021</xref>). In addition, readers should have a rough
  understanding of R
  (<xref alt="Wickham et al., 2023" rid="ref-wickhamDataScienceImport2023-nb-article" ref-type="bibr">Wickham
  et al., 2023</xref>) and how to simulate data. For data simulation, we
  use functions from the tidyverse
  (<xref alt="Wickham et al., 2019" rid="ref-wickhamWelcomeTidyverse2019-nb-article" ref-type="bibr">Wickham
  et al., 2019</xref>) and the faux package
  (<xref alt="DeBruine, 2023" rid="ref-R-faux-nb-article" ref-type="bibr">DeBruine,
  2023</xref>). Finally, readers should be familiar with regression
  modeling in general and GLMMs in particular. In this tutorial, we
  simulate data by manually specifying the model equation of a GLMM that
  represents our assumed data generating process
  (<xref alt="DeBruine &amp; Barr, 2021" rid="ref-debruineUnderstandingMixedEffectsModels2021-nb-article" ref-type="bibr">DeBruine
  &amp; Barr, 2021</xref>). It is not necessary to understand the
  technical details of how GLMMs are estimated. However it is crucial to
  understand the structure of a basic GLMM (e.g., logistic regression
  with random intercepts) and how the model assumes that the values in
  the dependent variable are determined by the predictor variables and
  the random effects.</p>
      </sec>
      <sec id="theoretical-background-nb-article">
        <title>Theoretical background</title>
        <sec id="planning-for-statistical-power-or-precision-nb-article">
          <title>Planning for statistical power or precision</title>
          <p>Conducting research with insufficiently large sample sizes can
    have many negative consequences. First, experiments may yield
    inconclusive or misleading results, hindering the accumulation of
    knowledge. Second, studies that are doomed to never finding a
    postulated effect waste resources by consuming time, effort, and
    funding without delivering meaningful results. For these reasons,
    many journals and funding bodies now require that a justification of
    sample size is included in study protocols and grant proposals,
    recognizing its significance in ensuring robust and meaningful
    findings. Although scientists often do not justify sample size or
    use general heuristics from the literature, resource constraints
    often play an important role
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
    2022a</xref>). But ideally, a suitable sample size should be
    determined a priori (i.e., before the study is conducted) based on
    some meaningful computation to ensure that the study will be able to
    fulfill its purpose.</p>
          <p>The majority of empirical studies in psychology and other social
    sciences apply hypothesis testing. As a consequence, the dominant
    approach for determining an adequate sample size is based on power
    analysis (i.e., planning for power)
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
    2022a</xref>;
    <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008-nb-article" ref-type="bibr">Maxwell
    et al., 2008</xref>). Statistical power is defined as the
    probability that a HT has a significant p-value when analyzing
    repeated samples from a population with a true effect of some
    pre-specified size
    (<xref alt="Cohen, 1992" rid="ref-cohenPowerPrimer1992-nb-article" ref-type="bibr">Cohen,
    1992</xref>). Less formally, power is described as the probability
    that a HT correctly rejects the null hypothesis when the alternative
    hypothesis is true. If the sample size (i.e., the number of
    participants and/or stimuli) used for data collection is
    insufficient to detect the effects or relationships being
    investigated with high probability, the study is considered
    “underpowered”. When planning for power, a target is set for the
    statistical power of a HT of interest. Assuming some effect size of
    interest and a desired significance level, a minimum sample size can
    be determined that, on average, would guarantee reaching this
    target. Although it is recommended to justify the desired
    significance level and power
    (<xref alt="Lakens, Adolfi, et al., 2018" rid="ref-lakensJustifyYourAlpha2018-nb-article" ref-type="bibr">Lakens,
    Adolfi, et al., 2018</xref>), most empirical studies adopt the
    heuristic of <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives><tex-math><![CDATA[1 - \beta = 0.80]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.80</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
          <p>In contrast to power analysis, sample size planning can also be
    based on the precision of parameter estimates (i.e., planning for
    precision or planning for accuracy)
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
    2022a</xref>;
    <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008-nb-article" ref-type="bibr">Maxwell
    et al., 2008</xref>). Not all research questions are best answered
    using hypothesis testing. It has been argued that basic research
    rarely requires making discrete decisions on whether some effect has
    been “discovered” and should thus shift from a hypothesis testing
    towards an estimation framework
    (<xref alt="Cumming, 2014" rid="ref-cummingNewStatisticsWhy2014-nb-article" ref-type="bibr">Cumming,
    2014</xref>;
    <xref alt="Kruschke &amp; Liddell, 2018" rid="ref-kruschkeBayesianNewStatistics2018-nb-article" ref-type="bibr">Kruschke
    &amp; Liddell, 2018</xref>;
    <xref alt="McElreath, 2020" rid="ref-mcelreathStatisticalRethinkingBayesian2020-nb-article" ref-type="bibr">McElreath,
    2020</xref>). Although this view is not without critique
    (<xref alt="Uygun Tunç et al., 2023" rid="ref-uyguntuncEpistemicPragmaticFunction2023-nb-article" ref-type="bibr">Uygun
    Tunç et al., 2023</xref>), at least for exploratory or pilot studies
    where little previous research has been conducted, more scientists
    seem to agree that simply estimating the effects of interest and
    making the estimation uncertainty transparent by reporting CIs is
    more useful. Assuming that no HTs are conducted for a planned study,
    power analysis is not relevant for sample size planning.
    Nonetheless, the sample size still has a crucial effect on how
    informative the planned study will be, because an effect of interest
    is estimated more precisely with bigger samples. In the precision
    framework, the target quantity commonly used for sample size
    planning is the expected width of a CI
    (<xref alt="Kelley &amp; Rausch, 2006" rid="ref-kelleySampleSizePlanning2006-nb-article" ref-type="bibr">Kelley
    &amp; Rausch, 2006</xref>;
    <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
    2022a</xref>;
    <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008-nb-article" ref-type="bibr">Maxwell
    et al., 2008</xref>). The values inside a CI are often interpreted
    as plausible values for the quantity of interest it is supposed to
    estimate. More formally, a CI with confidence level 0.95 provides
    the smallest interval with the property that upon repeated sampling,
    95% of individual CIs would include the true quantity of interest.
    Thus, a narrow CI is more informative about the size of the true
    effect than a wide interval. Apart from the desired confidence
    level, the width of a CI depends strongly on the sample size.
    Because bigger samples carry more information, they lead to smaller
    CIs. When planning for precision, a target can be set for the
    expected width of a CI of interest. Assuming some effect size of
    interest and a desired confidence level, a minimum sample size can
    be determined that, on average, would guarantee reaching this
    target. Because planning for precision is still rare, there are no
    common heuristics on how to choose the desired width of the CI
    (<xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
    2022a</xref>).</p>
        </sec>
        <sec id="generalized-linear-mixed-models-glmms-nb-article">
          <title>Generalized linear mixed models (GLMMs)</title>
          <p>As study designs become more complex, psychological researchers
    require more sophisticated statistical models to capture the nuanced
    relationships and grouping structures introduced by them
    (<xref alt="Yarkoni, 2022" rid="ref-yarkoniGeneralizabilityCrisis2022-nb-article" ref-type="bibr">Yarkoni,
    2022</xref>). GLMMs (also called multilevel models) are gaining
    increasing popularity because they offer great flexibility
    (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021-nb-article" ref-type="bibr">Fahrmeir
    et al., 2021</xref>). GLMMs are an extension of LMMs (Linear Mixed
    Models), which are, in turn, extensions of linear regression models
    that account for correlated data, including hierarchical structures
    (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021-nb-article" ref-type="bibr">Fahrmeir
    et al., 2021</xref>). In this context, correlated data means that
    the value in the outcome variable for one observation may be related
    to the value of another observation in a systematic way that is not
    already accounted for by the usual (fixed) predictor variables
    (e.g., age of participants). This correlation can arise for various
    reasons: For instance, responses to some stimuli from some
    participants might be more similar because the same person was
    measured twice (repeated measurements), participants come from the
    same neighborhood (clustering), or participants responded to the
    same stimulus (stimulus effects). Thus, modeling such correlations
    is important whenever the data has a clear structure, while the
    grouping variables can be hierarchically nested (e.g., grouping
    variables students and schools: each student belongs to exactly one
    school) or cross-classified (e.g., grouping variables students and
    math exercises: each student is presented with several math
    exercises). LMMs are used when the outcome variable is continuous
    and follows a normal distribution. They allow for the modeling of
    fixed effects, which capture the relationships between the usual
    predictors and the outcome, as well as random effects, which account
    for the different types of correlation structure and grouping
    effects. Random effects are typically assumed to follow a normal
    distribution with a mean of zero and a variance that quantifies the
    heterogeneity across groups. GLMMs extend the LMM framework to
    accommodate non-normally distributed continuous and categorical
    outcome variables. GLMMs involve a link function that connects the
    linear combination of predictor variables to the expected value of
    the outcome variable. The link function allows for modeling the
    relationship between predictors and the outcome in a non-linear way
    that is appropriate for the specific distribution family of the
    outcome variable. For example, think of an experiment with different
    design factors (e.g., picture positions, headline aesthetics)
    impacting the likelihood of users clicking on an online
    advertisement. The participants’ behavior is measured repeatedly
    over several sessions. The click patterns of participants in one
    session are likely to be correlated with their previous sessions and
    the outcome variable is binary (click/no click) for each session,
    which follows a binomial distribution.</p>
        </sec>
      </sec>
      <sec id="simulation-based-sample-size-planning-with-glmms-nb-article">
        <title>Simulation-based sample size planning with GLMMs</title>
        <p>To our knowledge, existing approaches for sample size planning for
  GLMMs have exclusively focused on planning for power. Power analysis
  methods for multilevel models can be categorized into formula-based
  methods and simulation-based methods
  (<xref alt="Murayama et al., 2022" rid="ref-murayamaSummarystatisticsbasedPowerAnalysis2022-nb-article" ref-type="bibr">Murayama
  et al., 2022</xref>). Formula-based methods rely on formulas to
  calculate power directly while simulation-based methods rely on
  repeatedly simulating data with a known true effect size and
  estimating power empirically (i.e., what percentage of simulated
  datasets produces a significant p-value). Available formula-based
  software packages for multilevel models often do not include GLMMs or
  are limited to very simple designs
  (<xref alt="Murayama et al., 2022" rid="ref-murayamaSummarystatisticsbasedPowerAnalysis2022-nb-article" ref-type="bibr">Murayama
  et al., 2022</xref>;
  <xref alt="Westfall et al., 2014" rid="ref-westfallStatisticalPowerOptimal2014-nb-article" ref-type="bibr">Westfall
  et al., 2014</xref>), making it necessary to build data simulations
  tailored specifically to the study design. A number of tutorials have
  been published describing how to perform such simulation-based power
  analysis for multilevel models
  (<xref alt="Arend &amp; Schäfer, 2019" rid="ref-arendStatisticalPowerTwolevel2019-nb-article" ref-type="bibr">Arend
  &amp; Schäfer, 2019</xref>;
  <xref alt="Brysbaert &amp; Stevens, 2018" rid="ref-brysbaertPowerAnalysisEffect2018-nb-article" ref-type="bibr">Brysbaert
  &amp; Stevens, 2018</xref>;
  <xref alt="DeBruine &amp; Barr, 2021" rid="ref-debruineUnderstandingMixedEffectsModels2021-nb-article" ref-type="bibr">DeBruine
  &amp; Barr, 2021</xref>;
  <xref alt="Green &amp; MacLeod, 2016" rid="ref-greenSIMRPackagePower2016a-nb-article" ref-type="bibr">Green
  &amp; MacLeod, 2016</xref>;
  <xref alt="Kain et al., 2015" rid="ref-kainPracticalGuidePower2015-nb-article" ref-type="bibr">Kain
  et al., 2015</xref>;
  <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021-nb-article" ref-type="bibr">Kumle
  et al., 2021</xref>;
  <xref alt="Lafit et al., 2021" rid="ref-lafitSelectionNumberParticipants2021-nb-article" ref-type="bibr">Lafit
  et al., 2021</xref>;
  <xref alt="Zimmer et al., 2022" rid="ref-zimmerSampleSizePlanning2022-nb-article" ref-type="bibr">Zimmer
  et al., 2022</xref>). However, many of these tutorials focus on linear
  mixed models (LMMs) and the common study designs (but see
  <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021-nb-article" ref-type="bibr">Kumle
  et al., 2021</xref>, for a tutorial that also covers more advanced
  settings). This narrow focus provides limited guidance for researchers
  faced with more complex study designs, especially when little prior
  knowledge about plausible effect sizes is available (see the
  discussion in
  <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021-nb-article" ref-type="bibr">Kumle
  et al., 2021</xref>). Simulation-based power analysis with GLMMs
  requires making a range of assumptions: The (conditional) distribution
  assumption specifies the distributional family for the outcome
  variable. Assumptions about the random effects include the assumption
  of normality (i.e., that the random effects follow a normal
  distribution) and the covariance structure among the random effects
  (i.e., if and how they are correlated). Making these decisions
  requires understanding the underlying assumptions of the model and
  ensuring they align with the characteristics of the data being
  analyzed. Existing tutorials often rely on heuristics for specifying
  variance components (e.g., the standard deviation of random
  intercepts) or assume that results from meta-analyses or data from
  pilot studies are available to determine plausible values for all
  model parameters. However, in practice, knowledge about those
  parameters from prior studies is often limited, which makes specifying
  assumptions a practical challenge (see the discussion in
  (<xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008-nb-article" ref-type="bibr">Maxwell
  et al., 2008</xref>) and
  (<xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021-nb-article" ref-type="bibr">Kumle
  et al., 2021</xref>)).</p>
        <p>INSERT TABLE 1 HERE!</p>
        <p>In Table 1, we give a short review of existing R packages that can
  be used for power analysis for GLMMs.</p>
      </sec>
      <sec id="when-to-use-tailored-data-simulation-nb-article">
        <title>When to use tailored data simulation?</title>
        <p>Performing tailored simulation-based sample size planning is more
  complicated and time-consuming than using the existing software tools
  outlined in TABLE 1. The most important circumstances under which
  tailored simulation-based sample size planning is necessary are 1)
  complex study designs, 2) complex statistical hypotheses, 3) planning
  for precision, 4) no available prior studies or pilot data.</p>
        <p>Requirements of real-world studies are often more complex than the
  simplified designs assumed by many user-friendly software packages for
  sample size planning. One frequent issue in applied data analysis is
  missing data, and there can be various reasons for this
  (<xref alt="Little &amp; Rubin, 2014" rid="ref-littleStatisticalAnalysisMissing2014-nb-article" ref-type="bibr">Little
  &amp; Rubin, 2014</xref>). For example, data can be missing completely
  at random (e.g., because an electronic measurement device randomly
  failed for some technical reasons). Alternatively, subjects might
  systematically drop out or produce missing data, but this dropout can
  be explained by some attributes also measured in the dataset (e.g.,
  older subjects have a higher probability to refuse answering a
  question on income). In a more complicated scenario, missing data in
  some variable is caused by the measured attribute itself (e.g.,
  wealthy people are more likely to refuse reporting their income).
  Moreover, many experimental designs contain conditions in which values
  of the predictor variables are missing by design. This can make data
  analysis more complicated because predictors have to be coded in
  specific ways that prevent the estimated GLMM from becoming
  unidentified. Whether missing data has an effect on the sample size
  planning depends on our theoretical assumptions on how the missingness
  is caused. However, it is often challenging to decide whether missing
  data can be safely ignored in the data analysis and sample size
  planning process based on a merely theoretical approach
  (<xref alt="Gomila &amp; Clark, 2022" rid="ref-gomilaMissingDataExperiments2022-nb-article" ref-type="bibr">Gomila
  &amp; Clark, 2022</xref>). Tailored simulation-based approaches offer
  the possibility to include the assumed process of how data become
  missing in the data simulation, thereby determining the required
  sample based on simulated datasets that contain missing values (for an
  example, see
  <xref alt="Lane &amp; Hennes, 2018" rid="ref-lanePowerStrugglesEstimating2018-nb-article" ref-type="bibr">Lane
  &amp; Hennes, 2018</xref>). As a byproduct, the simulated datasets can
  also be used to test whether the intended data analysis provides the
  expected (unbiased) results, despite the missing data. Although GLMMs
  can handle a large variety of outcome variables, researchers are
  becoming increasingly aware that many datasets might profit from even
  more sophisticated models. Common examples are zero-inflated outcomes,
  censoring, and nonlinear predictor effects that can be modeled with
  the R packages glmmTMB
  (<xref alt="Brooks et al., 2017" rid="ref-brooksGlmmTMBBalancesSpeed2017-nb-article" ref-type="bibr">Brooks
  et al., 2017</xref>) or brms
  (<xref alt="Bürkner, 2018" rid="ref-burknerAdvancedBayesianMultilevel2018-nb-article" ref-type="bibr">Bürkner,
  2018</xref>). Tailored simulation-based approaches do not share the
  same limitation than the existing software solutions for power
  analysis that focus exclusively on GLMMs. As long as there is a
  software package available to estimate the model of interest, it is
  always possible to perform tailored simulation-based sample size
  planning.</p>
        <p>The most common hypotheses tested in psychological research are of
  the type <inline-formula><alternatives><tex-math><![CDATA[H_0: \beta = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
  where <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
  is a slope or intercept of a regression model. However, many research
  questions in psychology actually require testing more complex
  statistical hypotheses. In the new era of preregistration and
  registered reports
  (<xref alt="Chambers &amp; Tzavella, 2022" rid="ref-chambersPresentFutureRegistered2022-nb-article" ref-type="bibr">Chambers
  &amp; Tzavella, 2022</xref>), most research questions should be tested
  with directed hypotheses because good theories at least postulate
  whether some psychological effect of interest is positive or negative.
  Even better theories should be able to specify the smallest effect
  sizes of interest (SESOI) that must be exceeded if the effect has any
  practical relevance
  (<xref alt="Lakens, Scheel, et al., 2018" rid="ref-lakensEquivalenceTestingPsychological2018-nb-article" ref-type="bibr">Lakens,
  Scheel, et al., 2018</xref>). In combination, this might require a
  test such as <inline-formula><alternatives><tex-math><![CDATA[H_0: \beta \leq 0.1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mi>β</mml:mi><mml:mo>≤</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  More elaborate research questions often require testing hypotheses
  that consist of a combination of model parameters, for example testing
  simple slopes
  (<xref alt="Preacher et al., 2006" rid="ref-preacherComputationalToolsProbing2006-nb-article" ref-type="bibr">Preacher
  et al., 2006</xref>) with a hypothesis such as
  <inline-formula><alternatives><tex-math><![CDATA[H_0: \beta_0 + \beta_1 \leq 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  If the research question consists only of a single hypothesis of this
  sort, it might be possible to reduce the hypothesis to a single
  regression coefficient by clever coding and/or centering of predictor
  variables. However, interesting research questions often consist of
  combined hypotheses that consist of more than one separate statistical
  hypothesis (for a tutorial on contrast analysis in GLMMs, see
  <xref alt="Schad et al., 2020" rid="ref-schadHowCapitalizePriori2020-nb-article" ref-type="bibr">Schad
  et al., 2020</xref>). For example, a combined null hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  might consist of two single null hypotheses
  <inline-formula><alternatives><tex-math><![CDATA[H_{01}: \beta_1 \leq 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
  and <inline-formula><alternatives><tex-math><![CDATA[H_{02}: \beta_0 + \beta_1 \leq 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
  For some research questions, the combined null hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  would be rejected if both <inline-formula><alternatives><tex-math><![CDATA[H_{01}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  <italic>AND</italic> <inline-formula><alternatives><tex-math><![CDATA[H_{02}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  are rejected. For other research questions, the combined null
  hypothesis <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  would be rejected if <inline-formula><alternatives><tex-math><![CDATA[H_{01}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  <italic>OR</italic> <inline-formula><alternatives><tex-math><![CDATA[H_{02}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  <italic>OR</italic> both are rejected. If the global hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  is combined with <italic>OR</italic>, the p-values of the single
  hypotheses must be corrected for multiple testing to avoid
  <inline-formula><alternatives><tex-math><![CDATA[\alpha]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>α</mml:mi></mml:math></alternatives></inline-formula>-inflation
  for the global hypothesis
  (<xref alt="Dmitrienko &amp; D’Agostino, 2013" rid="ref-dmitrienkoTraditionalMultiplicityAdjustment2013-nb-article" ref-type="bibr">Dmitrienko
  &amp; D’Agostino, 2013</xref>). However, if the global hypothesis
  <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
  is combined with <italic>AND</italic>, a correction for multiple
  testing is not necessary but rather a mistake that unnecessarily
  reduces the power of the global HT. None of the software packages for
  sample size planning in table X can handle combined hypotheses as
  discussed here and only some can handle directed hypotheses. In
  contrast, our case study will demonstrate how we can test directed
  combined hypotheses with tailored simulation-based sample size
  planning.</p>
        <p>Although planning for precision
  (<xref alt="Cumming, 2014" rid="ref-cummingNewStatisticsWhy2014-nb-article" ref-type="bibr">Cumming,
  2014</xref>;
  <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
  2022a</xref>;
  <xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008-nb-article" ref-type="bibr">Maxwell
  et al., 2008</xref>) has been increasingly discussed as a useful
  strategy for empirical research, all available software packages for
  sample size planning with GLMMs are based on power analysis.
  Therefore, researchers that want to want to apply an estimation
  strategy in their studies, without testing any statistical hypotheses,
  currently cannot use the software packages outlined in TABLE 1.
  However, tailored simulation-based sample size planning can easily
  handle the planning for precision approach
  (<xref alt="Maxwell et al., 2008" rid="ref-maxwellSampleSizePlanning2008-nb-article" ref-type="bibr">Maxwell
  et al., 2008</xref>). The only change in procedure is that instead of
  computing HTs for each simulated dataset and estimating statistical
  power across repetitions, CIs are computed for each simulated dataset,
  and the expected width is estimated.</p>
        <p>All frameworks for sample size planning require the user to make
  assumptions about the expected effect size. Assuming the true effect
  is of this size (or greater), one can compute the (minimum) power of a
  HT or the (maximum) expected width of a CI. Existing software packages
  for sample size planning for GLMMs usually require to provide the
  assumed effect in the unit of some standardized measure of effect
  size. When the researcher has access to similar studies or pilot data,
  providing such standardized effect sizes is feasible. However, note
  that choosing effect sizes based on small pilot studies is generally
  not recommended, as those estimates can be heavily biased
  (<xref alt="Albers &amp; Lakens, 2018" rid="ref-albersWhenPowerAnalyses2018a-nb-article" ref-type="bibr">Albers
  &amp; Lakens, 2018</xref>;
  <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
  2022a</xref>). Providing an informed standardized effect size can be
  an almost impossible challenge when no prior studies of pilot data are
  available. This problem is further exacerbated by the fact that GLMMs
  are so flexible that general heuristics of what should be considered a
  small effect do not exist or are difficult to defend. In our
  experience, using domain knowledge to construct a tailored data
  simulation is the only solution to determine plausible effect sizes in
  the absence of prior evidence. It would be possible to use these
  tailored simulations to extract plausible values for standardized
  effect sizes that could then be inserted in existing software packages
  for sample size planning. However, we would argue that when tailored
  data simulations necessary to determine effect sizes anyway,
  performing the whole sample size planning in a customized way is
  preferred over using the existing software packages.</p>
      </sec>
      <sec id="general-steps-in-tailored-simulation-based-sample-size-planning-nb-article">
        <title>General steps in tailored simulation-based sample size
  planning</title>
        <p>Although the details differ depending on the specific study
  characteristics, each tailored simulation-based sample size planning
  requires a series of steps and decisions. We will introduce each step
  in a theoretical section, followed by the practical application based
  on a hypothetical case study. All code in this manuscript and
  simulation results are available in the project’s repository on the
  Open Science Framework
  (<ext-link ext-link-type="uri" xlink:href="https://osf.io/dhwf4/">https://osf.io/dhwf4/</ext-link>).</p>
        <sec id="step-1-define-the-estimand-nb-article">
          <title>Step 1: Define the estimand</title>
          <sec id="theory-nb-article">
            <title>THEORY</title>
            <p>The first step in every research process should be a clear
      definition of the theoretical <italic>estimand</italic>
      (<xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021-nb-article" ref-type="bibr">Lundberg
      et al., 2021</xref>), i.e. the theoretical quantity which is
      necessary to answer a specific research question. The estimand
      consists of a quantity, that can be described for each unit under
      investigation and a clear definition of the target population, for
      which the quantity is of interest. For example, an estimand might
      be the probability that a clinical psychologists makes the correct
      diagnosis for a psychiatric patient with major depression,
      averaged across all clinical psychologists and depressed patients
      in psychiatric institutions in Germany.</p>
            <p>The estimand should always be defined outside of any
      statistical model, because there are usually a range of
      statistical methods that can be used to estimate the same
      estimand, depending on the study design (e.g., a randomized
      experiment) that will produce the observed data in the planned
      study. For many common research questions in psychology, the
      estimand can be expressed as a statistical quantity that can be
      estimated with a regression model, for example a single
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      coefficient. However, this is not possible for all estimands,
      which is why the literature discusses many estimation strategies
      beyond regression
      (<xref alt="Deffner et al., 2022" rid="ref-deffnerCausalFrameworkCrossCultural2022-nb-article" ref-type="bibr">Deffner
      et al., 2022</xref>;
      <xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021-nb-article" ref-type="bibr">Lundberg
      et al., 2021</xref>).</p>
          </sec>
          <sec id="practice-nb-article">
            <title>PRACTICE</title>
            <p>In the present hypothetical case study, we consider the
      effectiveness of feedback provided by an artificial intelligence
      (AI) embedded in a diagnostic decision support system. The context
      is a clinical setting, where expert radiologists and students
      under training must detect bleeding based on head scans from
      computer tomography (CT). In the investigated AI-enabled
      diagnostic decision support system, an AI model can provide
      initial diagnostic advice, which can be used as guidance by the
      humans who are required to make the final diagnostic decision. The
      research goal is to validate the effectiveness of the AI-enabled
      advice. We consider the AI-enabled advice as effective, if the
      following pattern holds, which we will first describe
      verbally:</p>
            <p>
              <italic>We expect that for BOTH expert radiologists and medical
      students, correct AI-advice leads to a higher probability of
      accurately diagnosing a CT scan compared to no AI-advice
      presented, AND, we expect that for BOTH experts and non-experts,
      incorrect advice leads to a lower probability of accurately
      diagnosing a CT scan compared to no advice presented.</italic>
            </p>
            <p>It becomes clear that our estimand consists of four comparisons
      between experimental conditions
      (<xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021-nb-article" ref-type="bibr">Lundberg
      et al., 2021</xref>). However, the verbal description is still
      somewhat vague, which is why we try to give a more precise
      expression for each comparison:</p>
            <p>
              <disp-formula>
                <alternatives>
                  <tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{correct advice, average expert, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{no advice, average expert, average scan})
      \end{aligned}
      ]]></tex-math>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                    <mml:mtable>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mtext mathvariant="normal">correct advice, average expert, average scan</mml:mtext>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mspace width="1.0em"/>
                          <mml:mo>−</mml:mo>
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mtext mathvariant="normal">no advice, average expert, average scan</mml:mtext>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:math>
                </alternatives>
              </disp-formula>
            </p>
            <p>
              <disp-formula>
                <alternatives>
                  <tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{no advice, average expert, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{wrong advice, average expert, average scan})
      \end{aligned}
      ]]></tex-math>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                    <mml:mtable>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mtext mathvariant="normal">no advice, average expert, average scan</mml:mtext>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mspace width="1.0em"/>
                          <mml:mo>−</mml:mo>
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mtext mathvariant="normal">wrong advice, average expert, average scan</mml:mtext>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:math>
                </alternatives>
              </disp-formula>
              <disp-formula>
                <alternatives>
                  <tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{correct advice, average student, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{no advice, average student, average scan})
      \end{aligned}
      ]]></tex-math>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                    <mml:mtable>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mtext mathvariant="normal">correct advice, average student, average scan</mml:mtext>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mspace width="1.0em"/>
                          <mml:mo>−</mml:mo>
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mtext mathvariant="normal">correct diagnosis</mml:mtext>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mtext mathvariant="normal">no advice, average student, average scan</mml:mtext>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:math>
                </alternatives>
              </disp-formula>
            </p>
            <p><disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      & P(\text{correct diagnosis} | \text{no advice, average student, average scan}) \\
      & \quad - P(\text{correct diagnosis} | \text{wrong advice, average student, average scan})
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtext mathvariant="normal">correct diagnosis</mml:mtext><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mtext mathvariant="normal">no advice, average student, average scan</mml:mtext><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mspace width="1.0em"/><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mtext mathvariant="normal">correct diagnosis</mml:mtext><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mtext mathvariant="normal">wrong advice, average student, average scan</mml:mtext><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      For example, the first expression is concerned with the difference
      between the probability that a correct diagnosis is made if
      correct AI-advice is presented and the probability that a correct
      diagnosis is made if no AI-advice is presented. This contrast is
      quantified for a hypothetical <italic>typical</italic> expert and
      a <italic>typical</italic> scan, where <italic>typical</italic> is
      usually defined as an average score on all attributes of the
      expert or scan.<xref ref-type="fn" rid="fn1-nb-article">1</xref>. To complete
      our definition of the estimand, we have to define our target
      population that consists of persons, stimuli, and AI-advice: With
      respect to persons, we are only interested in expert radiologists
      and medical students at German universities. With respect to
      stimuli, we are only interested in the head CT scans made from
      subjects that do or do not suffer from intracerebral hemorrhage.
      Lastly, we are only interested in AI-advice given by a specific
      AI-enabled diagnostic decision support system.</p>
            <p>Although the estimand is initially defined outside of any
      statistical model, it is only useful if we find a way to estimate
      it based on observed data. For our exemplary research question, it
      is possible to construct an experimental study, where all
      participants are confronted with the same set of head CT scans,
      but the kind of AI-advice given for each scan is randomly assigned
      within participants. This random intervention allows us to produce
      an empirical estimate of our estimand, although, in reality, each
      person receives only one kind of AI-advice (correct advice, wrong
      advice, no advice) for each scan. We will see later how each of
      the probability expressions in our estimand can be modeled with
      the same GLMM. Estimating this GLMM based on the data observed in
      our planned study will produce an estimate for each probability,
      and these estimates can then be combined to compute an estimate
      for each of the four probability contrasts. For pedagogical
      reasons, we will skip the concrete definition of our estimate
      until we have discussed how to simulate data based on a concrete
      GLMM in the next section.</p>
          </sec>
        </sec>
        <sec id="step-2-simulate-the-data-generating-process-nb-article">
          <title>Step 2: Simulate the data generating process</title>
          <sec id="theory-1-nb-article">
            <title>THEORY</title>
            <p>When the estimand has been defined, the next step in the
      research process is to write code that simulates the (assumed)
      data generating process of the planned study. This requires
      specifying a generative process for all predictor variables used
      in the final data analysis. While such assumptions can be quite
      challenging for observational studies or continuous predictor
      variables, this is less of a problem for experimental studies with
      only categorical predictor variables. When all predictor variables
      have been simulated, one can use the structure of a suitable GLMM
      to simulate the dependent variable. To simulate the GLMM, one
      requires plausible values for all model parameters. We will
      discuss strategies on how these values can be obtained later.
      Because we have full control over the data generating process in a
      tailored simulation, it is possible to model specific aspects of
      the planned study, like data missing by design or assuming that
      some subjects might drop out. The quality of the results of the
      sample size planning crucially depends on the plausibility of the
      simulated data generating process. However, we would argue that
      even a strongly simplified data generating process (e.g. only a
      small number of interaction effects; only random intercepts and no
      random slopes; assuming that data is missing completely at random)
      can yield informative results.</p>
          </sec>
          <sec id="practice-1-nb-article">
            <title>PRACTICE</title>
            <p>In our case study, we simulate data for an experiment where the
      diagnostic performance of users of an AI-enabled diagnostic
      decision support system will be evaluated. Radiologists (task
      experts) and students/interns (non experts) review a series of
      head computer tomography (CT) scans to assess the presence of a
      bleeding. An AI model provides initial diagnostic advice to assist
      their decision-making. In the control condition, no AI advice is
      presented. When AI advice is given, this advice can be either
      correct or incorrect. The type of advice (no advice, wrong advice,
      correct advice) is randomized within subjects across brain scans.
      After reviewing a CT scan, participants deliver a medical
      diagnosis (bleeding or no bleeding), which may be either accurate
      or inaccurate. This experimental design introduces some missing
      values by design since the advice is neither correct nor incorrect
      when no advice is present, which must be taken into account when
      simulating and analyzing the data. In this example, recruiting
      task experts (i.e., radiologists) is more challenging due to their
      limited availability, while non-experts (i.e., students/interns)
      are more readily accessible. The goal of simulation-based sample
      size planning is to determine how many task experts and
      non-experts must be recruited to achieve sufficient statistical
      power or precision in the planned experiment.</p>
            <sec id="our-specific-glmm-nb-article">
              <title>Our specific GLMM</title>
              <p>In a GLMM, the expected value of the dependent variable
        <inline-formula><alternatives><tex-math><![CDATA[Y]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
        conditioned on the vector of predictor variables
        <inline-formula><alternatives><tex-math><![CDATA[\mathbf{X}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐗</mml:mi></mml:math></alternatives></inline-formula>
        and random effects <inline-formula><alternatives><tex-math><![CDATA[\mathbf{U}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐔</mml:mi></mml:math></alternatives></inline-formula>,
        transformed by a link function <inline-formula><alternatives><tex-math><![CDATA[g()]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>
        is modeled as a linear combination
        <inline-formula><alternatives><tex-math><![CDATA[\eta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>η</mml:mi></mml:math></alternatives></inline-formula>
        of the predictor variables <inline-formula><alternatives><tex-math><![CDATA[\mathbf{X}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐗</mml:mi></mml:math></alternatives></inline-formula>,
        the random effects <inline-formula><alternatives><tex-math><![CDATA[\mathbf{U}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝐔</mml:mi></mml:math></alternatives></inline-formula>
        and the model parameters <inline-formula><alternatives><tex-math><![CDATA[\mathbf{\beta}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>𝛃</mml:mi></mml:math></alternatives></inline-formula>
        (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021-nb-article" ref-type="bibr">Fahrmeir
        et al., 2021</xref>): <disp-formula><alternatives><tex-math><![CDATA[
        g(E(Y|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u})) = \eta
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>𝐗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐱</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐮</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>η</mml:mi></mml:mrow></mml:math></alternatives></disp-formula>
        Equivalently, the conditional expected value is modeled as the
        linear combination <inline-formula><alternatives><tex-math><![CDATA[\eta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>η</mml:mi></mml:math></alternatives></inline-formula>,
        transformed by the inverse link function
        <inline-formula><alternatives><tex-math><![CDATA[g^{-1}()]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>:
        <disp-formula><alternatives><tex-math><![CDATA[
        E(Y|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u}) = g^{-1}(\eta)
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>𝐗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐱</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐮</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
        If the dependent variable (i.e., diagnostic decision)
        <inline-formula><alternatives><tex-math><![CDATA[Y]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>Y</mml:mi></mml:math></alternatives></inline-formula>
        is a binary variable with values <inline-formula><alternatives><tex-math><![CDATA[0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0</mml:mn></mml:math></alternatives></inline-formula>
        (i.e., inaccurate), or <inline-formula><alternatives><tex-math><![CDATA[1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>1</mml:mn></mml:math></alternatives></inline-formula>
        (i.e., accurate), the conditional expected value is equivalent
        to the probability: <disp-formula><alternatives><tex-math><![CDATA[
        P_{si} := P(Y = 1|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u})
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>:=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>𝐗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐱</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐮</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
        In our case study, <inline-formula><alternatives><tex-math><![CDATA[P_{si}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>
        is the conditional probability that subject
        <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
        gives the correct response to item (i.e., CT scan)
        <inline-formula><alternatives><tex-math><![CDATA[i]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula>.</p>
              <p>In such a setting, we model this probability as
        <disp-formula><alternatives><tex-math><![CDATA[
        P_{si} = \text{inverse\_logit}(\eta_{si})
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
        with the inverse-logit link <inline-formula><alternatives><tex-math><![CDATA[g^{-1}(\eta_{si}) = inverse\_logit(\eta_{si}) = \frac{exp(\eta_{si})}{1 + exp(\eta_{si})}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi>−</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>
        or equivalently <disp-formula><alternatives><tex-math><![CDATA[
        \text{logit}(P_{si}) = \eta_{si}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mrow><mml:mtext mathvariant="normal">logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></disp-formula>
        with the logit link <inline-formula><alternatives><tex-math><![CDATA[g(P_{si}) = \text{logit}(P_{si}) = \text{ln} (\frac{P_{si}}{1 - P_{si}})]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">ln</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mfrac><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
              <p>In our case study, the probability of making an accurate
        diagnostic decision is assumed to depend on the predictors:</p>
              <list list-type="bullet">
                <list-item>
                  <p><inline-formula><alternatives><tex-math><![CDATA[advice\_present_{si}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
            whether subject <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
            was presented with AI advice (1) or not (0) when asked to
            assess item <inline-formula><alternatives><tex-math><![CDATA[i]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula></p>
                </list-item>
                <list-item>
                  <p><inline-formula><alternatives><tex-math><![CDATA[advice\_correct_{si}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
            whether this advice was correct (1) or not (0)</p>
                </list-item>
                <list-item>
                  <p><inline-formula><alternatives><tex-math><![CDATA[expert_s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:
            whether subject <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
            was a task expert (1) or not (0)</p>
                </list-item>
              </list>
              <p>and the random effects:</p>
              <list list-type="bullet">
                <list-item>
                  <p><inline-formula><alternatives><tex-math><![CDATA[u_{0s}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>:
            the deviation of subject <inline-formula><alternatives><tex-math><![CDATA[s]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>s</mml:mi></mml:math></alternatives></inline-formula>
            from the average ability to solve an item (i.e., CT scan)
            with average difficulty; assumed to be distributed as
            <inline-formula><alternatives><tex-math><![CDATA[u_{0s} \sim N(0, \sigma_S^2)]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
                </list-item>
                <list-item>
                  <p><inline-formula><alternatives><tex-math><![CDATA[u_{0i}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>:
            the deviation of item (i.e., CT scan)
            <inline-formula><alternatives><tex-math><![CDATA[i]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>i</mml:mi></mml:math></alternatives></inline-formula>
            from the average difficulty to be solved by a person with
            average ability; assumed to be distributed as
            <inline-formula><alternatives><tex-math><![CDATA[u_{0i} \sim N(0, \sigma_I^2)]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
                </list-item>
              </list>
              <p>In total, we assume the model <disp-formula><alternatives><tex-math><![CDATA[
        \begin{aligned}
        \text{logit}[P_{si}] =\ (&\beta_0 + u_{0s} + u_{0i}) + \\
        &\beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s + \\
        &\beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}
        \end{aligned}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mtext mathvariant="normal">logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mspace width="0.222em"/><mml:mo stretchy="false" form="prefix">(</mml:mo></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">)</mml:mo><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
        or equivalently <disp-formula><alternatives><tex-math><![CDATA[
        \begin{aligned}
        P_{si} = \text{inverse\_logit}[&(\beta_0 + u_{0s} + u_{0i}) + \\
        &\beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s + \\
        &\beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}]
        \end{aligned}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mo stretchy="false" form="prefix">[</mml:mo></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
        with model parameters <inline-formula><alternatives><tex-math><![CDATA[\beta_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_e]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_a]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_c]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_{ea}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\beta_{ec}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
        and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>.</p>
              <p>In the GLMM literature, this would be called a binomial GLMM
        with two random intercepts (for subjects and items), two level-1
        predictors (<inline-formula><alternatives><tex-math><![CDATA[advice\_present]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[advice\_correct]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>),
        one level-2 predictor (<inline-formula><alternatives><tex-math><![CDATA[expert]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>)
        and two cross-level interactions (<inline-formula><alternatives><tex-math><![CDATA[expert \cdot advice\_present]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>,
        <inline-formula><alternatives><tex-math><![CDATA[expert \cdot advice\_correct]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>).
        To limit complexity, we do not consider random slopes,
        additional predictors or higher-level interactions.</p>
            </sec>
            <sec id="simulation-function-in-r-nb-article">
              <title>Simulation function in R</title>
              <p>The following R function simulates a full dataset structured
        according to the design of our case study.</p>
              <sec specific-use="notebook-content">
                <code language="r script">b_0 = 0.847
b_e = 1.350
b_a = -1.253
b_c = 2.603
b_ea = 0.790
b_ec = -1.393</code>
              </sec>
              <sec specific-use="notebook-content">
                <code language="r script">simulate &lt;- function(n_subjects = 100, n_items = 50,
  b_0 = 0.847, b_e = 1.350, b_a = -1.253, b_c = 2.603,
  b_ea = 0.790, b_ec = -1.393,
  sd_u0s = 0.5, sd_u0i = 0.5, ...){
  require(dplyr)
  require(faux)
  # simulate design
  dat &lt;- add_random(subject = n_subjects, item = n_items) |&gt;
    add_between("subject", expert = c(1, 0), .prob = c(0.25, 0.75)) |&gt;
    mutate(advice_present = rbinom(n(), 1, prob = 2/3)) |&gt;
    mutate(advice_correct = if_else(advice_present == 1L, 
                                    rbinom(n(), 1L, prob = 0.8), 0L)) |&gt;
    # add random effects
    add_ranef("subject", u0s = sd_u0s) |&gt;
    add_ranef("item", u0i = sd_u0i) |&gt;
    # compute dependent variable
    mutate(linpred = b_0 + u0i + u0s +
        b_e * expert + b_a * advice_present + b_c * advice_correct +
        b_ea * expert * advice_present + b_ec * expert * advice_correct) |&gt;
    mutate(y_prob = plogis(linpred)) |&gt;
    mutate(y_bin = rbinom(n = n(), size = 1, prob = y_prob))
  dat
}</code>
              </sec>
              <p>In the first four lines of the function definition, we set
        some default parameter values (which we will explain in the next
        section) and load the packages we use to manipulate and simulate
        data.<xref ref-type="fn" rid="fn2-nb-article">2</xref> In our case study,
        each subject (<monospace>n_subjects</monospace> in total) is
        assumed to respond to each item (i.e., CT scan;
        <monospace>n_items</monospace> in total). Thus, the
        <monospace>add_random</monospace> command creates a
        fully-crossed <monospace>data.frame</monospace> with
        <monospace>n_subjects</monospace> <inline-formula><alternatives><tex-math><![CDATA[\times]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>×</mml:mi></mml:math></alternatives></inline-formula>
        <monospace>n_items</monospace> rows. We add a between-subject
        effect with the <monospace>add_between</monospace> command,
        simulating that about <inline-formula><alternatives><tex-math><![CDATA[25\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>25</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
        of subjects are experts. The next two lines simulate that in
        <inline-formula><alternatives><tex-math><![CDATA[\frac{2}{3}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mfrac><mml:mn>2</mml:mn><mml:mn>3</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>
        of trials, subjects will be presented with AI advice, and if
        advice is presented, the advice will be correct in about
        <inline-formula><alternatives><tex-math><![CDATA[80\%]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>80</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
        of cases (the variable <monospace>advice_correct</monospace> is
        always 0 when no advice is presented). Next, we simulate one
        random effect for each subject (<monospace>u0s</monospace>) and
        for each item (<monospace>u0i</monospace>). As assumed by
        standard GLMMs, the <monospace>add_ranef</monospace> function
        draws the random effects from a normal distribution with a mean
        0 and a standard deviation specified by the user. With all
        design variables done, we are ready to simulate our model
        equation outlined in the last section. The linear predictor
        variable <monospace>linpred</monospace>
        (<inline-formula><alternatives><tex-math><![CDATA[\eta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>η</mml:mi></mml:math></alternatives></inline-formula>
        in the GLMM model equations) combines the predictor variables,
        random effects, and model parameters as assumed by our model. We
        then transform the linear predictor with the inverse-link
        function to compute <monospace>y_prob</monospace>, the
        probability that the subject correctly solved the item (in R,
        the inverse-logit link is computed with
        <monospace>plogis</monospace> and the logit link with
        <monospace>qlogis</monospace>). In the final step, we simulate
        the binary dependent variable <monospace>y_bin</monospace>
        (i.e., whether the subject makes an accurate diagnostic decision
        for the CT scan) by – for each trial – drawing from a Bernoulli
        distribution with success probability
        <monospace>y_prob</monospace>.</p>
            </sec>
          </sec>
        </sec>
        <sec id="step-3-specify-the-population-parameters-nb-article">
          <title>Step 3: Specify the population parameters</title>
          <sec id="theory-2-nb-article">
            <title>THEORY</title>
            <p>In the absence of previous studies with the same design or
      pilot data, researchers require strategies on how to specify the
      population parameters used in their data simulation. Population
      parameters are all model parameters estimated in a GLMM, in
      particular the regression coefficients of the fixed effects and
      the standard deviation of the random effects (and the correlation
      between random effects in more complicated models). In contrast to
      non-hierarchical linear regression, common heuristics based on
      standardized effect sizes are less useful or not even available
      for GLMMs. Our strategies to specify population parameters will
      require access to domain knowledge from domain experts. Because
      most domain knowledge can only be expressed in unstandardized
      measurement units of a specific application, we argue that
      unstandardized effect sizes are usually preferable over
      standardized effect sizes for tailored simulation-based sample
      size planning. The basic idea of all strategies is how the data
      generating process implied by certain values of population
      parameters can be quantified or visualized in an intuitive way
      that enables a calibration of population parameters based on the
      available knowledge of domain experts.</p>
            <p>Although we use frequentist model estimation in our tutorial,
      many strategies described in this chapter are inspired by research
      on how to monitor the plausibility of model assumptions in applied
      Bayesian statistics
      (<xref alt="Gelman et al., 2020" rid="ref-gelmanBayesianWorkflow2020-nb-article" ref-type="bibr">Gelman
      et al., 2020</xref>).</p>
          </sec>
          <sec id="practice-2-nb-article">
            <title>PRACTICE</title>
            <p>When introducing the simulation function for our case study, we
      have used theoretically plausible values as defaults for all model
      parameters (<inline-formula><alternatives><tex-math><![CDATA[\beta_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_e]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_a]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_c]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_{ea}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\beta_{ec}]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>,
      <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>),
      but have not talked about where these numbers came from.</p>
            <p>The starting point for all parameter values in our present case
      study were based on results from distantly related study designs
      in the literature. Additionally, we had repeated discussions with
      our affiliated domain experts in radiology to check whether our
      assumptions seem plausible.</p>
            <p>We now outline our main strategy to determine plausible
      parameter values for the fixed effects
      (<inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters): Unfortunately, the model parameters in a binomial
      GLMM are hard to interpret in isolation because 1) the
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters are connected to the modeled probability via the
      non-linear inverse-logit link, and 2) we also have to consider the
      random effects. The most simple interpretation, that allows us to
      ignore the random effects for now, works by imagining a subject
      with average ability (<inline-formula><alternatives><tex-math><![CDATA[u_{0s} = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>)
      responding to an item (i.e., CT scan) with average difficulty
      (<inline-formula><alternatives><tex-math><![CDATA[u_{0i} = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).
      Then the model implied probability that such a person solves such
      an item accurately is given by:</p>
            <p><disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      P(Y=1|\mathbf{X=x}, \mathbf{U} = \mathbf{0}) = \\
      = \text{inverse\_logit}[&\beta_0 + \beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s + \\
      &\beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}]
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mrow><mml:mi>𝐗</mml:mi><mml:mo mathvariant="bold">=</mml:mo><mml:mi>𝐱</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>𝐔</mml:mi><mml:mo>=</mml:mo><mml:mn>𝟎</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mo stretchy="false" form="prefix">[</mml:mo></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>⋅</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false" form="postfix">]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      In fact, we would only need the full equation if the subject is an
      expert and correct advice is presented. In all other experimental
      conditions, some terms drop from the equation because they are
      multiplied by <inline-formula><alternatives><tex-math><![CDATA[0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0</mml:mn></mml:math></alternatives></inline-formula>.
      For example, the probability that a non-expert with average
      ability solves an item with average difficulty when no advice is
      presented, only requires the intercept:
      <disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      P(Y=1| advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) = \\
      = \text{inverse\_logit}[\beta_0]
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mo>=</mml:mo><mml:mtext mathvariant="normal">inverse_logit</mml:mtext><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      We can revert this perspective by choosing plausible probability
      values based on domain knowledge and deriving the parameter values
      implied by these probabilities for each experimental
      condition.</p>
            <sec specific-use="notebook-content">
              <code language="r script">probtable &lt;- data.frame(
  col1 = 
    c("no advice, no expert", "no advice, expert", "false advice, no expert", 
      "false advice, expert", "correct advice, no expert", "correct advice, expert"),
  col2 =
    c("0.70", "0.90", "0.40", "0.85", "0.90", "0.95"),
  col3 = 
    c("$logit(0.70) = \\beta_0<!-- (F2ED4C6E)[nb-article]:/Users/florianpargent/Documents/Forschung/glmm_simulation_tutorial/manuscript.qmd -->quot;,
      "$logit(0.90) = \\beta_0 + \\beta_e<!-- (F2ED4C6E)[nb-article]:/Users/florianpargent/Documents/Forschung/glmm_simulation_tutorial/manuscript.qmd -->quot;, 
      "$logit(0.40) = \\beta_0 + \\beta_a<!-- (F2ED4C6E)[nb-article]:/Users/florianpargent/Documents/Forschung/glmm_simulation_tutorial/manuscript.qmd -->quot;,
      "$logit(0.85) = \\beta_0 + \\beta_e + \\beta_{a} + \\beta_{ea}<!-- (F2ED4C6E)[nb-article]:/Users/florianpargent/Documents/Forschung/glmm_simulation_tutorial/manuscript.qmd -->quot;,
      "$logit(0.90) = \\beta_0 + \\beta_a + \\beta_c<!-- (F2ED4C6E)[nb-article]:/Users/florianpargent/Documents/Forschung/glmm_simulation_tutorial/manuscript.qmd -->quot;,
      "$logit(0.95) = \\beta_0 + \\beta_e + \\beta_a + \\beta_c + \\beta_{ea} + \\beta_{ec}<!-- (F2ED4C6E)[nb-article]:/Users/florianpargent/Documents/Forschung/glmm_simulation_tutorial/manuscript.qmd -->quot;))
knitr::kable(probtable, col.names = c("Experimental condition",
    "$P(Y=1 \\mid \\mathbf{X=x}, \\mathbf{U} = \\mathbf{0})<!-- (F2ED4C6E)[nb-article]:/Users/florianpargent/Documents/Forschung/glmm_simulation_tutorial/manuscript.qmd -->quot;,
    "Implied equation"), escape = FALSE)</code>
              <fig id="tbl-probtable-nb-article">
                <caption>
                  <p>Table 1: Assumed probabilities that an average
        subject solves an average item in each experimental
        condition.</p>
                </caption>
                <table-wrap>
                  <table>
                    <colgroup>
                      <col width="16%"/>
                      <col width="33%"/>
                      <col width="51%"/>
                    </colgroup>
                    <thead>
                      <tr>
                        <th align="left">Experimental condition</th>
                        <th align="left">
                          <inline-formula>
                            <alternatives>
                              <tex-math><![CDATA[P(Y=1 \mid \mathbf{X=x}, \mathbf{U} = \mathbf{0})]]></tex-math>
                              <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                                <mml:mrow>
                                  <mml:mi>P</mml:mi>
                                  <mml:mrow>
                                    <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                    <mml:mi>Y</mml:mi>
                                    <mml:mo>=</mml:mo>
                                    <mml:mn>1</mml:mn>
                                    <mml:mo>∣</mml:mo>
                                    <mml:mrow>
                                      <mml:mi>𝐗</mml:mi>
                                      <mml:mo mathvariant="bold">=</mml:mo>
                                      <mml:mi>𝐱</mml:mi>
                                    </mml:mrow>
                                    <mml:mo>,</mml:mo>
                                    <mml:mi>𝐔</mml:mi>
                                    <mml:mo>=</mml:mo>
                                    <mml:mn>𝟎</mml:mn>
                                    <mml:mo stretchy="true" form="postfix">)</mml:mo>
                                  </mml:mrow>
                                </mml:mrow>
                              </mml:math>
                            </alternatives>
                          </inline-formula>
                        </th>
                        <th align="left">Implied equation</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td align="left">no advice, no expert</td>
                        <td align="left">0.70</td>
                        <td align="left">
                          <inline-formula>
                            <alternatives>
                              <tex-math><![CDATA[logit(0.70) = \beta_0]]></tex-math>
                              <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                                <mml:mrow>
                                  <mml:mi>l</mml:mi>
                                  <mml:mi>o</mml:mi>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                  <mml:mi>t</mml:mi>
                                  <mml:mrow>
                                    <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                    <mml:mn>0.70</mml:mn>
                                    <mml:mo stretchy="true" form="postfix">)</mml:mo>
                                  </mml:mrow>
                                  <mml:mo>=</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mn>0</mml:mn>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:math>
                            </alternatives>
                          </inline-formula>
                        </td>
                      </tr>
                      <tr>
                        <td align="left">no advice, expert</td>
                        <td align="left">0.90</td>
                        <td align="left">
                          <inline-formula>
                            <alternatives>
                              <tex-math><![CDATA[logit(0.90) = \beta_0 + \beta_e]]></tex-math>
                              <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                                <mml:mrow>
                                  <mml:mi>l</mml:mi>
                                  <mml:mi>o</mml:mi>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                  <mml:mi>t</mml:mi>
                                  <mml:mrow>
                                    <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                    <mml:mn>0.90</mml:mn>
                                    <mml:mo stretchy="true" form="postfix">)</mml:mo>
                                  </mml:mrow>
                                  <mml:mo>=</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mn>0</mml:mn>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>e</mml:mi>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:math>
                            </alternatives>
                          </inline-formula>
                        </td>
                      </tr>
                      <tr>
                        <td align="left">false advice, no expert</td>
                        <td align="left">0.40</td>
                        <td align="left">
                          <inline-formula>
                            <alternatives>
                              <tex-math><![CDATA[logit(0.40) = \beta_0 + \beta_a]]></tex-math>
                              <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                                <mml:mrow>
                                  <mml:mi>l</mml:mi>
                                  <mml:mi>o</mml:mi>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                  <mml:mi>t</mml:mi>
                                  <mml:mrow>
                                    <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                    <mml:mn>0.40</mml:mn>
                                    <mml:mo stretchy="true" form="postfix">)</mml:mo>
                                  </mml:mrow>
                                  <mml:mo>=</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mn>0</mml:mn>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>a</mml:mi>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:math>
                            </alternatives>
                          </inline-formula>
                        </td>
                      </tr>
                      <tr>
                        <td align="left">false advice, expert</td>
                        <td align="left">0.85</td>
                        <td align="left">
                          <inline-formula>
                            <alternatives>
                              <tex-math><![CDATA[logit(0.85) = \beta_0 + \beta_e + \beta_{a} + \beta_{ea}]]></tex-math>
                              <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                                <mml:mrow>
                                  <mml:mi>l</mml:mi>
                                  <mml:mi>o</mml:mi>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                  <mml:mi>t</mml:mi>
                                  <mml:mrow>
                                    <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                    <mml:mn>0.85</mml:mn>
                                    <mml:mo stretchy="true" form="postfix">)</mml:mo>
                                  </mml:mrow>
                                  <mml:mo>=</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mn>0</mml:mn>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>e</mml:mi>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>a</mml:mi>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mrow>
                                      <mml:mi>e</mml:mi>
                                      <mml:mi>a</mml:mi>
                                    </mml:mrow>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:math>
                            </alternatives>
                          </inline-formula>
                        </td>
                      </tr>
                      <tr>
                        <td align="left">correct advice, no expert</td>
                        <td align="left">0.90</td>
                        <td align="left">
                          <inline-formula>
                            <alternatives>
                              <tex-math><![CDATA[logit(0.90) = \beta_0 + \beta_a + \beta_c]]></tex-math>
                              <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                                <mml:mrow>
                                  <mml:mi>l</mml:mi>
                                  <mml:mi>o</mml:mi>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                  <mml:mi>t</mml:mi>
                                  <mml:mrow>
                                    <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                    <mml:mn>0.90</mml:mn>
                                    <mml:mo stretchy="true" form="postfix">)</mml:mo>
                                  </mml:mrow>
                                  <mml:mo>=</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mn>0</mml:mn>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>a</mml:mi>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>c</mml:mi>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:math>
                            </alternatives>
                          </inline-formula>
                        </td>
                      </tr>
                      <tr>
                        <td align="left">correct advice, expert</td>
                        <td align="left">0.95</td>
                        <td align="left">
                          <inline-formula>
                            <alternatives>
                              <tex-math><![CDATA[logit(0.95) = \beta_0 + \beta_e + \beta_a + \beta_c + \beta_{ea} + \beta_{ec}]]></tex-math>
                              <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline">
                                <mml:mrow>
                                  <mml:mi>l</mml:mi>
                                  <mml:mi>o</mml:mi>
                                  <mml:mi>g</mml:mi>
                                  <mml:mi>i</mml:mi>
                                  <mml:mi>t</mml:mi>
                                  <mml:mrow>
                                    <mml:mo stretchy="true" form="prefix">(</mml:mo>
                                    <mml:mn>0.95</mml:mn>
                                    <mml:mo stretchy="true" form="postfix">)</mml:mo>
                                  </mml:mrow>
                                  <mml:mo>=</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mn>0</mml:mn>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>e</mml:mi>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>a</mml:mi>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mi>c</mml:mi>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mrow>
                                      <mml:mi>e</mml:mi>
                                      <mml:mi>a</mml:mi>
                                    </mml:mrow>
                                  </mml:msub>
                                  <mml:mo>+</mml:mo>
                                  <mml:msub>
                                    <mml:mi>β</mml:mi>
                                    <mml:mrow>
                                      <mml:mi>e</mml:mi>
                                      <mml:mi>c</mml:mi>
                                    </mml:mrow>
                                  </mml:msub>
                                </mml:mrow>
                              </mml:math>
                            </alternatives>
                          </inline-formula>
                        </td>
                      </tr>
                    </tbody>
                  </table>
                </table-wrap>
              </fig>
            </sec>
            <p><xref alt="Table 1" rid="tbl-probtable-nb-article">Table 1</xref> shows
      our set of assumptions concerning the probability that an average
      subject solves an average item for each experimental condition, as
      well as the corresponding equations implied by the model. The
      table can be used to compute the implied values for the
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters, starting with the first equation and reinserting the
      computed <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      values in all following equations (<monospace>b_0</monospace>
      stands for the intercept <inline-formula><alternatives><tex-math><![CDATA[\beta_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>,
      <monospace>b_e</monospace> for the slope
      <inline-formula><alternatives><tex-math><![CDATA[\beta_e]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      and so on):</p>
            <sec specific-use="notebook-content">
              <code language="r script">b_0 &lt;- qlogis(0.7)
b_e &lt;- qlogis(0.9) - b_0
b_a &lt;- qlogis(0.4) - b_0
b_ea &lt;- qlogis(0.85) - b_0 - b_e - b_a
b_c &lt;- qlogis(0.9) - b_0 - b_a
b_ec &lt;- qlogis(0.95) - b_0 - b_e - b_a - b_c - b_ea
c(b_0 = b_0, b_e = b_e, b_a = b_a, b_c = b_c, b_ea = b_ea, b_ec = b_ec)</code>
              <boxed-text>
                <preformat>       b_0        b_e        b_a        b_c       b_ea       b_ec 
 0.8472979  1.3499267 -1.2527630  2.6026897  0.7901394 -1.3928518 </preformat>
              </boxed-text>
            </sec>
            <p>It is always possible to double-check these computations by
      transforming the parameter values back to probabilities, e.g. 
      <disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      P(Y=1|expert = 1, advice\_present = 1, advice\_correct = 1, u_{0s} = 0, u_{0i} = 0) = \\
      = inverse\_logit[\beta_0 + \beta_e + \beta_a + \beta_c + \beta_{ea} + \beta_{ec}]
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">[</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true" form="postfix">]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
            <p>which we compute in R as:</p>
            <sec specific-use="notebook-content">
              <code language="r script">plogis(b_0 + b_e + b_a + b_c + b_ea + b_ec)</code>
              <boxed-text>
                <preformat>[1] 0.95</preformat>
              </boxed-text>
            </sec>
            <p>This leaves us with the question on how to determine plausible
      values for the two remaining model parameters
      (<inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>,
      and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>)
      that are the standard deviations for the random intercepts. For
      this, we introduce two more strategies.</p>
          </sec>
          <sec id="insightful-descriptive-statistics-nb-article">
            <title>Insightful descriptive statistics</title>
            <sec id="theory-3-nb-article">
              <title>THEORY</title>
              <p>The mathematical structure of GLMMs determines which patterns
        in data would be produced by the model, if a specific set of
        values for the population parameters would be specified. The
        knowledge of how to simulate from a GLMM enables us to compute
        insightful descriptive statistics that can be compared to
        available domain knowledge much more easily than the opaque
        values of model parameters. For example, domain experts might
        not be able to directly choose plausible values for the
        coefficients in a logistic regression model (which are measured
        on the log-odds scale). However, they should be able to reason
        about the expected ratio of the binary dependent variable in
        different experimental conditions, i.e. which relative frequency
        they expect to observe (on average). The job of the analyst who
        is familiar with the mathematical structure of the GLMM is to
        produce the model implied value of the insightful descriptive
        statistic expected by the domain expert. Although insightful
        descriptive statistics usually depend on the model parameters in
        a non-linear way, it is not necessary to solve the exact
        relationship mathematically. Instead, one can simply adjust the
        population parameters by trial and error until the model implied
        quantities produce the desired result.</p>
            </sec>
            <sec id="practice-3-nb-article">
              <title>PRACTICE</title>
              <p>In the last section, we showed how we can derive the model
        implied probability that a subject with average ability solves
        an item with average difficulty for each experimental condition.
        Although these derivations are straightforward, it is important
        not to misinterpret their implications: In binomial GLMMs, the
        average probability to solve an item (averaged across persons of
        varying ability and items of varying difficulty) is
        <bold>not</bold> equal to the probability that a person with
        average ability solves an item with average difficulty
        (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021-nb-article" ref-type="bibr">Fahrmeir
        et al., 2021</xref>). The first perspective implies a so-called
        marginal interpretation, while the second one implies a
        conditional interpretation.</p>
              <p>For example, we determined the <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
        parameters in a way that corresponds to a desired conditional
        probability of <inline-formula><alternatives><tex-math><![CDATA[0.95]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0.95</mml:mn></mml:math></alternatives></inline-formula>,
        that an expert with average ability solves an item with average
        difficulty when presented with correct advice (the conditional
        perspective). However, even if the model were true, we would not
        observe that 95% of experts responding to items presented with
        correct advice from a big sample of subjects drawn from their
        natural distribution of ability, and items drawn from their
        natural distribution of difficulty (the marginal perspective).
        How much the two probabilities differ depends on the standard
        deviations of the random intercepts (the two probabilities are
        only equal if both standard deviations would be zero). We want
        to use the model implied observed proportion of correct
        diagnoses in each experimental condition as an insightful
        descriptive statistics to determine plausible values for the
        random effect standard deviations.</p>
              <p>We will simulate a large dataset (for which the observed
        values of the descriptive statistic will be close to their model
        implied true values) and simply compute the relative frequency
        of correct diagnoses for each experimental condition.</p>
              <sec specific-use="notebook-content">
                <code language="r script">library(tidyverse)
set.seed(1)
dat &lt;- simulate(n_subjects = 3000, n_items = 3000,
  sd_u0s = 0.5, sd_u0i = 0.5)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
 "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
 "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
 "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  group_by(condition) |&gt;
  summarize(relative_frequency = sum(y_bin) / n())</code>
                <boxed-text>
                  <preformat># A tibble: 6 × 2
  condition                 relative_frequency
  &lt;fct&gt;                                  &lt;dbl&gt;
1 no expert, no advice                   0.683
2 expert, no advice                      0.881
3 no expert, wrong advice                0.409
4 expert, wrong advice                   0.828
5 no expert, correct advice              0.883
6 expert, correct advice                 0.938</preformat>
                </boxed-text>
              </sec>
              <p>We tried using these descriptive statistics to judge together
        with domain experts whether our chosen values for the random
        effect standard deviations would produce data that align with
        out domain expertise. However, although the result was deemed
        plausible, these statistics were not informative enough to
        determine a final set of plausible parameter values. For this
        reason, we will additionally look at insightful model based
        quantities.</p>
            </sec>
          </sec>
          <sec id="insightful-model-based-quantities-nb-article">
            <title>Insightful model based quantities</title>
            <sec id="theory-4-nb-article">
              <title>THEORY</title>
              <p>Because GLMMs are complicated models, descriptive statistics
        alone are usually not enough to specify plausible values for all
        model parameters. This is especially true for the standard
        deviation of random effects that have non-linear (and often
        unexpected) effects on the model-implied results. An important
        advantage of data simulation (where one has full control over
        parameter values and sample sizes) is that one can produce
        insightful model based quantities that can never be directly
        observed in an actual empirical dataset. For example, in a
        logistic model with random intercepts for participants, one can
        produce a visualization of the implied distribution of the
        probability that a participant on average solves a cognitive
        task. Although domain knowledge will probably not suffice to
        specify this distribution completely, it should be possible to
        rule out implausible boundary conditions. For example, the
        domain expert might deem it implausible that the 5% most able
        participants have a probability of more than 0.99 to solve the
        difficult cognitive task.</p>
            </sec>
            <sec id="practice-4-nb-article">
              <title>PRACTICE</title>
              <p>The discussed inequality of conditional and marginal effects
        in GLMMs
        (<xref alt="Fahrmeir et al., 2021" rid="ref-fahrmeirRegressionModelsMethods2021-nb-article" ref-type="bibr">Fahrmeir
        et al., 2021</xref>) makes their interpretation more difficult.
        One must be careful when specifying parameter values based on
        previous studies or pilot data that use the marginal
        interpretation (e.g., a pilot study providing an estimate of how
        often radiologists make an accurate diagnosis based on brain
        scans). However, this does not mean that we cannot use the
        marginal interpretation (average probability across persons and
        items) to inform plausible parameter values: When parameter
        values have been selected, we can compute the implied marginal
        distributions and compare this information to our domain
        knowledge. Then, we can iteratively adjust the parameter values
        until we are satisfied with the implied distributions. In the
        last section, we simulated a large dataset and computed
        descriptive statistics, the relative frequencies of correct
        diagnoses, for each experimental condition. We will now use the
        model implied probability of each simulated data point (stored
        in the variable <monospace>y_prob</monospace>) to visualize the
        whole model implied marginal distribution of correct diagnoses
        for each experimental condition.</p>
              <sec id="cell-fig-margdist1-nb-article" specific-use="notebook-content">
                <code language="r script">library(ggdist)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
"no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
"no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
"no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))</code>
                <fig id="fig-margdist1-nb-article">
                  <caption>
                    <p>Figure 1: Marginal distributions including means,
          66% and 95% confidence intervals for all experimental
          conditions.</p>
                  </caption>
                  <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-margdist1-1.png"/>
                </fig>
              </sec>
              <p><xref alt="Figure 1" rid="fig-margdist1-nb-article">Figure 1</xref>
        shows the model implied marginal distributions, including the
        mean, 66% and 95% intervals. We can see that, indeed, the
        average probabilities (black dots) slightly differ from the
        probabilities of average subjects and items considered in the
        previous section. This difference increases with the variability
        of the random effects. We can use plots like the one above as a
        useful tool to decide whether the specified standard deviations
        of the subject and item random intercepts
        (<inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
        and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>)
        are reasonable by comparing the ranges and overlap between
        conditions to domain knowledge.</p>
              <sec id="cell-fig-margdist2-nb-article" specific-use="notebook-content">
                <code language="r script">set.seed(1)
dat &lt;- simulate(n_subjects = 3000, n_items = 3000, sd_u0i = 0.01)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
"no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
"no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
"no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))</code>
                <fig id="fig-margdist2-nb-article">
                  <caption>
                    <p>Figure 2: Marginal distributions including means,
          66% and 95% confidence intervals for all experimental
          conditions while setting the standard deviation of item random
          intercepts to 0.01.</p>
                  </caption>
                  <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-margdist2-1.png"/>
                </fig>
              </sec>
              <p>In the next plot, we have set the item standard deviation to
        almost zero (<inline-formula><alternatives><tex-math><![CDATA[\sigma_I = 0.01]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).
        This gives us a better way to see the variability between
        persons. As an example,
        <xref alt="Figure 2" rid="fig-margdist2-nb-article">Figure 2</xref> reveals
        a number of implicit assumptions about the comparison between
        experts and non-experts: With wrong advice, virtually all
        experts have a higher probability of making a correct diagnosis
        compared to non-experts when considering only items with average
        difficulty. In contrast, there is considerable overlap in
        probability between experts and non-experts with no advice and
        even higher overlap with correct advice. Patterns like these
        should be considered carefully and discussed with the domain
        experts. Parameter values (<inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
        parameters, and <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>)
        should be adjusted if the implications do not seem reasonable.
        We could also have a closer look at variability between items by
        setting the subject standard deviation to almost zero
        (<inline-formula><alternatives><tex-math><![CDATA[\sigma_S = 0.01]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).</p>
              <sec specific-use="notebook-content">
                <code language="r script">set.seed(1)
dat &lt;- simulate(n_subjects = 3000, n_items = 3000, sd_u0s = 0.01)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
"no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
"no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
"no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))</code>
                <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/unnamed-chunk-10-1.png"/>
              </sec>
              <p>The final plot demonstrates that these plots are also useful
        for spotting standard deviations that are specified too high.
        For <xref alt="Figure 3" rid="fig-margdist3-nb-article">Figure 3</xref> we
        have set <inline-formula><alternatives><tex-math><![CDATA[\sigma_S = 3]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
        and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I = 3]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.
        This implies that in each experimental condition, the
        probabilities that a subject solves an item are usually close to
        either 0 or 1, which is not a plausible assumption. These high
        standard deviations do not account for the inherent variability
        and complexity of human performance. For example, we would
        expect that a participant with low ability compared to other
        task experts to solve a difficult item with a probability
        substantially larger than zero even when presented with wrong
        advice.</p>
              <sec id="cell-fig-margdist3-nb-article" specific-use="notebook-content">
                <code language="r script">set.seed(1)
dat &lt;- simulate(n_subjects = 3000, n_items = 3000, sd_u0s = 3, sd_u0i = 3)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
    "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
    "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
    "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))</code>
                <fig id="fig-margdist3-nb-article">
                  <caption>
                    <p>Figure 3: Marginal distributions including means,
          66% and 95% confidence intervals for all experimental
          conditions while setting the standard deviation of subject and
          item random intercepts to 3.</p>
                  </caption>
                  <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-margdist3-1.png"/>
                </fig>
              </sec>
            </sec>
          </sec>
          <sec id="iterative-process-with-domain-experts-nb-article">
            <title>Iterative process with domain experts</title>
            <sec id="theory-5-nb-article">
              <title>THEORY</title>
              <p>In our experience, the gathering of domain knowledge by
        domain experts and the consecutive specification of population
        parameter values used in data simulation is not a one-time event
        but rather an iterative process. In a first step, domain experts
        can be interviewed to “elicit” their domain knowledge about how
        the future data of the planned study is expected to look like.
        As most domain experts are no experts in statistical modeling
        and GLMMs, they often struggle without further guidance to
        communicate their knowledge in a way that is useful when
        specifying the parameters for data simulation. For this reason,
        we suggest that after an initial unstructured interview of
        domain experts, the analyst who is familiar with the structure
        of the GLMM under study selects an initial set of insightful
        descriptive statistics and model based quantities. Then they
        reenter into an iterative discussion where some set of
        population values are selected and the plausibility of resulting
        implied quantities are discussed with the domain experts. Then,
        the population parameters are updated based on this discussion
        until the domain experts are satisfied with the final result.
        During this process, the monitored model based quantities and
        descriptive statistics can be updated or extended to capture as
        much available domain knowledge as possible.</p>
              <sec id="practice-5-nb-article">
                <title>PRACTICE</title>
                <p>All parameter values in our present case study have been
          determined based on repeated discussions with our affiliated
          domain experts in Radiology to validate our assumptions.
          Initially, we reviewed the literature to establish a
          reasonable baseline performance rate for examining head CT
          scans for intracranial hemorrhage. Existing studies indicate
          that radiologists typically demonstrate high accuracies, often
          exceeding or hovering around 90%, while interns have been
          shown to perform below 80%, and medical students fall even
          shorter. For simplicity, we assumed plausible probability
          values of .90 for experts and .70 for non-experts,
          respectively. Our experts confirmed that these values are
          realistic baselines for reviewing diverse head CT images
          without AI assistance. Subsequently, we consulted several
          published papers investigating the effect of correct and
          incorrect advice on decision-making performance in other
          settings. From their findings, we inferred that both experts
          and non-experts should benefit from correct and suffer losses
          from incorrect advice. However, the magnitude of these effects
          should be substantially greater for non-experts, given their
          demonstrated reliance on advice compared to experts. We
          further validated the plausibility of our estimated gains and
          losses with the collaborating radiologists. For our
          simulation, we used the probabilities of average participants
          to solve an average case, as shown in Table 1.</p>
              </sec>
            </sec>
          </sec>
        </sec>
        <sec id="step-4-estimate-the-statistical-model-nb-article">
          <title>Step 4: Estimate the statistical model</title>
          <sec id="theory-6-nb-article">
            <title>THEORY</title>
            <p>At this point, the researcher is capable of producing a
      simulated dataset similar to the actual dataset that will later be
      collected in the planned study. The next step is to specify how
      the statistical model shall be estimated in the actual study
      collected later. This usually includes the selection of 1) a
      statistical framework (e.g., frequentist statistics), 2) a
      software package that is capable of estimating the model class of
      interest (e.g., the lme4 R package), 3) an estimation algorithm
      (e.g., the default optimizer “bobyqa”), and 4) the specific model
      structure including all fixed effects, random effects, and the
      model family of the dependent variable.
      Note that this does not always mean that one will specify the same
      GLMM that was used when specifying the data generating process. On
      the one hand, using a simpler model for data simulation than for
      model estimation can be a useful strategy in scenarios where
      making plausible assumptions for complicated random effect
      structures and interactions is not feasible. On the other hand,
      using a more complex model for data simulation than for model
      estimation can be a useful strategy in scenarios where one has
      specific domain knowledge about aspects of the data generating
      process that are still difficult to estimate with the current
      state-of-the-art in multilevel modeling.</p>
          </sec>
          <sec id="practice-6-nb-article">
            <title>PRACTICE</title>
            <p>In our case study, we use the lme4 R package
      (<xref alt="Bates et al., 2015" rid="ref-batesFittingLinearMixedEffects2015-nb-article" ref-type="bibr">Bates
      et al., 2015</xref>), which is a state-of-the-art tool for fitting
      frequentist GLMMs.<xref ref-type="fn" rid="fn3-nb-article">3</xref> For the
      current example, we simulate data according to our model, in which
      100 subjects respond to 50 items (we use
      <monospace>set.seed</monospace> to make the simulation
      reproducible). However, for the sake of the exercise, we can
      imagine that this would be real data resulting from our future
      experiment and think about how we would analyze this data.</p>
            <sec specific-use="notebook-content">
              <code language="r script">library(tidyverse)
set.seed(1)
dat &lt;- simulate(n_subjects = 100, n_items = 50)</code>
            </sec>
            <p>The lme4 package uses a special syntax for model specification.
      Our specific GLMM is represented by the formula:</p>
            <sec specific-use="notebook-content">
              <code language="r script">library(lme4)
f &lt;- y_bin ~ 1 + expert + advice_present + advice_correct + 
  expert:advice_present + expert:advice_correct +
  (1|subject) + (1|item)</code>
            </sec>
            <p>The first two lines look similar to any linear model in R
      (general intercept indicated by <monospace>1</monospace>; main
      effects indicated by variable names in the dataset; interactions
      indicated by <monospace>variable1:variable2</monospace>). The
      third line specifies a random intercept for each subject
      <monospace>(1|subject)</monospace> and for each item
      <monospace>(1|item)</monospace>. The complete set of rules for the
      syntax is outlined in Bates et al.
      (<xref alt="2015" rid="ref-batesFittingLinearMixedEffects2015-nb-article" ref-type="bibr">2015</xref>)
      and in the documentation of the lme4 package.</p>
            <p>In lme4, a GLMM is fitted with the <monospace>glmer</monospace>
      function. By setting
      <monospace>family =  "binomial"</monospace>, we request
      a binomial GLMM appropriate for our binary dependent variable
      <monospace>y_bin</monospace> (the binomial GLMM uses the canonical
      logit link by default), which is defined as an accurate (1)
      vs. inaccurate (0) diagnosis.</p>
            <sec specific-use="notebook-content">
              <code language="r script">fit &lt;- glmer(f, data = dat, family = "binomial")</code>
            </sec>
            <p>We can inspect the estimates for all model parameters with the
      <monospace>summary</monospace> command:</p>
            <sec specific-use="notebook-content">
              <code language="r script">summary(fit)</code>
              <boxed-text>
                <preformat>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: 
y_bin ~ 1 + expert + advice_present + advice_correct + expert:advice_present +  
    expert:advice_correct + (1 | subject) + (1 | item)
   Data: dat

     AIC      BIC   logLik deviance df.resid 
  4149.4   4201.6  -2066.7   4133.4     4992 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-5.7669  0.2125  0.3046  0.4317  2.1056 

Random effects:
 Groups  Name        Variance Std.Dev.
 subject (Intercept) 0.3148   0.5611  
 item    (Intercept) 0.1624   0.4029  
Number of obs: 5000, groups:  subject, 100; item, 50

Fixed effects:
                      Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)             1.0339     0.1103   9.374  &lt; 2e-16 ***
expert                  1.1849     0.2096   5.654 1.56e-08 ***
advice_present         -1.3436     0.1206 -11.143  &lt; 2e-16 ***
advice_correct          2.6154     0.1273  20.540  &lt; 2e-16 ***
expert:advice_present   1.0589     0.2940   3.601 0.000317 ***
expert:advice_correct  -1.8104     0.2915  -6.210 5.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) expert advc_p advc_c exprt:dvc_p
expert      -0.377                                 
advic_prsnt -0.349  0.176                          
advic_crrct  0.023  0.001 -0.668                   
exprt:dvc_p  0.143 -0.448 -0.412  0.276            
exprt:dvc_c -0.008  0.004  0.292 -0.435 -0.686     </preformat>
              </boxed-text>
            </sec>
            <p>In the lme4 output, the <monospace>Estimate</monospace> column
      in the <monospace>Fixed effects</monospace> table contains the
      estimates for the <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters, while the <monospace>Std.Dev.</monospace> column in
      the <monospace>Random effects</monospace> table contains the
      estimates for <inline-formula><alternatives><tex-math><![CDATA[\sigma_S]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></alternatives></inline-formula>
      and <inline-formula><alternatives><tex-math><![CDATA[\sigma_I]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>σ</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:math></alternatives></inline-formula>.</p>
          </sec>
        </sec>
        <sec id="step-5-compute-the-estimate-nb-article">
          <title>Step 5: Compute the estimate</title>
          <sec id="theory-7-nb-article">
            <title>THEORY</title>
            <p>In previous steps, we have defined the theoretical estimand,
      written a data simulation function and specified how to estimate a
      GLMM using simulated data. The next step is to specify how to
      compute a concrete point estimate of the theoretical estimand
      within the framework of the fitted GLMM. For some research
      question, the estimate corresponds with a single regression
      coefficient. In more complicated scenarios, the estimate is
      computed from a combination of coefficients. Beyond computing the
      point estimate, we have already discussed that both hypothesis
      testing and interval estimation can be used to answer the research
      question. The decision on testing or estimating is then followed
      by selecting the specific statistical method that shall be applied
      to compute the HT(s) or CI(s) (e.g., compute HTs and CIs with the
      marginaleffects R package using the delta method).</p>
          </sec>
          <sec id="practice-7-nb-article">
            <title>PRACTICE</title>
            <p>In the estimand section, we have translated a verbal
      description of our research question into four probability
      statements that are specified outside of any specific statistical
      model. For a concrete estimate within the context of our specified
      GLMM, we must compute the following probability contrasts:</p>
            <p>
              <disp-formula>
                <alternatives>
                  <tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                    <mml:mtable>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mi>Y</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>s</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>n</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>o</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>e</mml:mi>
                            <mml:mi>x</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>s</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mspace width="1.0em"/>
                          <mml:mo>−</mml:mo>
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mi>Y</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>s</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>n</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>o</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>e</mml:mi>
                            <mml:mi>x</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>s</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:math>
                </alternatives>
              </disp-formula>
              <disp-formula>
                <alternatives>
                  <tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                    <mml:mtable>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mi>Y</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>s</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>n</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>o</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>e</mml:mi>
                            <mml:mi>x</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>s</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mspace width="1.0em"/>
                          <mml:mo>−</mml:mo>
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mi>Y</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>s</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>n</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>o</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>e</mml:mi>
                            <mml:mi>x</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>s</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:math>
                </alternatives>
              </disp-formula>
            </p>
            <p>
              <disp-formula>
                <alternatives>
                  <tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block">
                    <mml:mtable>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mi>Y</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>s</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>n</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>o</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>e</mml:mi>
                            <mml:mi>x</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>s</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd columnalign="right" style="text-align: right"/>
                        <mml:mtd columnalign="left" style="text-align: left">
                          <mml:mspace width="1.0em"/>
                          <mml:mo>−</mml:mo>
                          <mml:mi>P</mml:mi>
                          <mml:mrow>
                            <mml:mo stretchy="true" form="prefix">(</mml:mo>
                            <mml:mi>Y</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>1</mml:mn>
                            <mml:mo stretchy="false" form="prefix">|</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>s</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>n</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>a</mml:mi>
                            <mml:mi>d</mml:mi>
                            <mml:mi>v</mml:mi>
                            <mml:mi>i</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>_</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>o</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>c</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:mi>e</mml:mi>
                            <mml:mi>x</mml:mi>
                            <mml:mi>p</mml:mi>
                            <mml:mi>e</mml:mi>
                            <mml:mi>r</mml:mi>
                            <mml:mi>t</mml:mi>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>s</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo>,</mml:mo>
                            <mml:msub>
                              <mml:mi>u</mml:mi>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>=</mml:mo>
                            <mml:mn>0</mml:mn>
                            <mml:mo stretchy="true" form="postfix">)</mml:mo>
                          </mml:mrow>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:math>
                </alternatives>
              </disp-formula>
            </p>
            <p><disp-formula><alternatives><tex-math><![CDATA[
      \begin{aligned}
      & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
      & \quad - P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
      \end{aligned}
      ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mspace width="1.0em"/><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
      We have already discussed how to compute the involved
      probabilities in the section on specifying population parameters.
      Plugging in the model equation of the GLMM produces an equation on
      how to compute each contrast if all model parameters were known.
      When we want to estimate the above contrasts based on
      <italic>observed</italic> data, the only difference is that model
      parameters are not known and we instead use the corresponding
      parameter <italic>estimates</italic>.</p>
            <p>We could use our knowledge of the structure of the GLMM to
      determine the exact formula needed to compute the contrasts of
      interest and then plug in the parameter estimates manually from
      the <monospace>summary(fit)</monospace> output. However, this
      would be tedious and we can use R to compute this contrast without
      doing the math. Using the first contrast <italic>(correct advice,
      expert) - (no advice, expert)</italic> as our example, we could
      apply the <monospace>predict</monospace> function of the lme4
      package to compute the predicted probability for a correct
      diagnosis based on our fitted model, plug in the two sets of
      predictor values, and compute the difference between the two
      estimated probabilities.</p>
            <sec specific-use="notebook-content">
              <code language="r script">grid1 &lt;- data.frame(advice_present = c(1, 0), advice_correct = c(1, 0), 
  expert = c(1, 1))
grid1</code>
              <boxed-text>
                <preformat>  advice_present advice_correct expert
1              1              1      1
2              0              0      1</preformat>
              </boxed-text>
              <code language="r script">pred &lt;- predict(fit, newdata = grid1, type = "response", re.form = NA)
pred</code>
              <boxed-text>
                <preformat>       1        2 
0.939292 0.901923 </preformat>
              </boxed-text>
              <code language="r script">pred[1] - pred[2]</code>
              <boxed-text>
                <preformat>         1 
0.03736901 </preformat>
              </boxed-text>
            </sec>
            <p>The argument <monospace>type = "response"</monospace>
      specifies that predictions are made on the probability scale
      (instead of the log-odds scale of the
      <inline-formula><alternatives><tex-math><![CDATA[\beta]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>β</mml:mi></mml:math></alternatives></inline-formula>
      parameters), while <monospace>re.form = NA</monospace> sets all
      random effects to 0. We could use this method to compute point
      estimates for all four contrasts that are part of our estimand.
      However, depending on whether we are interested in hypothesis
      testing or parameter estimation, we also need a method to compute
      HTs or CI. The marginaleffects package
      (<xref alt="Arel-Bundock, 2024" rid="ref-R-marginaleffects-nb-article" ref-type="bibr">Arel-Bundock,
      2024</xref>) is a very flexible, increasingly popular package to
      compute HTs and CIs for contrasts with a variety of statistical
      models, including GLMMs estimated with lme4. First, we specify a
      grid of all combinations of predictor variable and then compute
      estimated probabilities for all experimental conditions in our
      experiment with the <monospace>predictions</monospace>
      function:</p>
            <sec specific-use="notebook-content">
              <code language="r script">library(tidyverse)
library(marginaleffects)
library(tinytable)
grid2 &lt;- expand_grid(advice_present = 0:1, 
  advice_correct = 0:1, expert = 0:1)
grid2</code>
              <boxed-text>
                <preformat># A tibble: 8 × 3
  advice_present advice_correct expert
           &lt;int&gt;          &lt;int&gt;  &lt;int&gt;
1              0              0      0
2              0              0      1
3              0              1      0
4              0              1      1
5              1              0      0
6              1              0      1
7              1              1      0
8              1              1      1</preformat>
              </boxed-text>
              <code language="r script">preds &lt;- predictions(fit, newdata = grid2, 
  type = "response", re.form = NA)
print(preds, style = "tinytable") |&gt; theme_tt(theme = "resize")</code>
              <table-wrap>
                <table>
                  <colgroup>
                    <col width="9%"/>
                    <col width="11%"/>
                    <col width="7%"/>
                    <col width="9%"/>
                    <col width="7%"/>
                    <col width="7%"/>
                    <col width="8%"/>
                    <col width="14%"/>
                    <col width="14%"/>
                    <col width="8%"/>
                  </colgroup>
                  <thead>
                    <tr>
                      <th>Estimate</th>
                      <th>Std. Error</th>
                      <th>z</th>
                      <th>Pr(&gt;|z|)</th>
                      <th>S</th>
                      <th>2.5 %</th>
                      <th>97.5 %</th>
                      <th>advice_present</th>
                      <th>advice_correct</th>
                      <th>expert</th>
                    </tr>
                  </thead>
                  <tfoot>
                    <tr>
                      <td colspan="10">Columns: rowid, estimate, std.error,
              statistic, p.value, s.value, conf.low, conf.high,
              advice_present, advice_correct, expert, y_bin</td>
                    </tr>
                  </tfoot>
                  <tbody>
                    <tr>
                      <td>0.738</td>
                      <td>0.02134</td>
                      <td>34.6</td>
                      <td>&lt;0.001</td>
                      <td>867.2</td>
                      <td>0.696</td>
                      <td>0.779</td>
                      <td>0</td>
                      <td>0</td>
                      <td>0</td>
                    </tr>
                    <tr>
                      <td>0.902</td>
                      <td>0.01739</td>
                      <td>51.9</td>
                      <td>&lt;0.001</td>
                      <td>Inf</td>
                      <td>0.868</td>
                      <td>0.936</td>
                      <td>0</td>
                      <td>0</td>
                      <td>1</td>
                    </tr>
                    <tr>
                      <td>0.975</td>
                      <td>0.00421</td>
                      <td>231.6</td>
                      <td>&lt;0.001</td>
                      <td>Inf</td>
                      <td>0.966</td>
                      <td>0.983</td>
                      <td>0</td>
                      <td>1</td>
                      <td>0</td>
                    </tr>
                    <tr>
                      <td>0.954</td>
                      <td>0.01454</td>
                      <td>65.6</td>
                      <td>&lt;0.001</td>
                      <td>Inf</td>
                      <td>0.925</td>
                      <td>0.982</td>
                      <td>0</td>
                      <td>1</td>
                      <td>1</td>
                    </tr>
                    <tr>
                      <td>0.423</td>
                      <td>0.03221</td>
                      <td>13.1</td>
                      <td>&lt;0.001</td>
                      <td>128.6</td>
                      <td>0.360</td>
                      <td>0.486</td>
                      <td>1</td>
                      <td>0</td>
                      <td>0</td>
                    </tr>
                    <tr>
                      <td>0.874</td>
                      <td>0.02793</td>
                      <td>31.3</td>
                      <td>&lt;0.001</td>
                      <td>711.4</td>
                      <td>0.819</td>
                      <td>0.928</td>
                      <td>1</td>
                      <td>0</td>
                      <td>1</td>
                    </tr>
                    <tr>
                      <td>0.909</td>
                      <td>0.00967</td>
                      <td>94.1</td>
                      <td>&lt;0.001</td>
                      <td>Inf</td>
                      <td>0.890</td>
                      <td>0.928</td>
                      <td>1</td>
                      <td>1</td>
                      <td>0</td>
                    </tr>
                    <tr>
                      <td>0.939</td>
                      <td>0.01091</td>
                      <td>86.1</td>
                      <td>&lt;0.001</td>
                      <td>Inf</td>
                      <td>0.918</td>
                      <td>0.961</td>
                      <td>1</td>
                      <td>1</td>
                      <td>1</td>
                    </tr>
                    <tr>
                      <td colspan="10">Type: response</td>
                    </tr>
                  </tbody>
                </table>
              </table-wrap>
            </sec>
            <p>The point estimates for all experimental conditions are
      reported in the <monospace>Estimate</monospace> column. Note that
      the output also contains the two missing by design conditions that
      will never be observed in the actual study
      (<inline-formula><alternatives><tex-math><![CDATA[advice\_present = 0, advice\_correct = 1, expert = 1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
      and <inline-formula><alternatives><tex-math><![CDATA[advice\_present = 0, advice\_correct = 1, expert = 0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).
      This is no problem as long as we never interpret those estimates.
      Next, we use the estimated probabilities to compute the four
      specific contrasts that are part of our estimand. For this we must
      specify which rows in <monospace>probs</monospace> have to be
      subtracted from each other. We will use the
      <monospace>hypotheses</monospace> function to compute our four
      contrasts of interest together with HTs and CIs. We use the
      default inference options of the marginaleffects package that
      compute HTs and CIs based on the approximate delta method.</p>
            <sec specific-use="notebook-content">
              <code language="r script">contrasts &lt;- preds |&gt; 
  hypotheses(hypothesis = c(
    "b8 = b2",  # (correct advice, expert) - (no advice, expert)
    "b2 = b6",  # (no advice, expert) - (wrong advice, expert) 
    "b7 = b1",  # (correct advice, no expert) - (no advice, no expert)
    "b1 = b5"), # (no advice, no expert) - (wrong advice, no expert)
    equivalence = c(0, 0))
print(contrasts, style = "tinytable") |&gt; theme_tt(theme = "resize")</code>
              <table-wrap>
                <table>
                  <colgroup>
                    <col width="6%"/>
                    <col width="9%"/>
                    <col width="10%"/>
                    <col width="6%"/>
                    <col width="9%"/>
                    <col width="6%"/>
                    <col width="9%"/>
                    <col width="7%"/>
                    <col width="10%"/>
                    <col width="10%"/>
                    <col width="10%"/>
                  </colgroup>
                  <thead>
                    <tr>
                      <th>Term</th>
                      <th>Estimate</th>
                      <th>Std. Error</th>
                      <th>z</th>
                      <th>Pr(&gt;|z|)</th>
                      <th>S</th>
                      <th>2.5 %</th>
                      <th>97.5 %</th>
                      <th>p (NonSup)</th>
                      <th>p (NonInf)</th>
                      <th>p (Equiv)</th>
                    </tr>
                  </thead>
                  <tfoot>
                    <tr>
                      <td colspan="11">Columns: term, estimate, std.error,
              statistic, p.value, s.value, conf.low, conf.high,
              statistic.noninf, statistic.nonsup, p.value.noninf,
              p.value.nonsup, p.value.equiv</td>
                    </tr>
                  </tfoot>
                  <tbody>
                    <tr>
                      <td>b8=b2</td>
                      <td>0.0374</td>
                      <td>0.0162</td>
                      <td>2.31</td>
                      <td>0.021</td>
                      <td>5.6</td>
                      <td>0.00563</td>
                      <td>0.0691</td>
                      <td>0.989</td>
                      <td>0.0105</td>
                      <td>0.989</td>
                    </tr>
                    <tr>
                      <td>b2=b6</td>
                      <td>0.0282</td>
                      <td>0.0279</td>
                      <td>1.01</td>
                      <td>0.312</td>
                      <td>1.7</td>
                      <td>-0.02653</td>
                      <td>0.0830</td>
                      <td>0.844</td>
                      <td>0.1562</td>
                      <td>0.844</td>
                    </tr>
                    <tr>
                      <td>b7=b1</td>
                      <td>0.1717</td>
                      <td>0.0173</td>
                      <td>9.93</td>
                      <td>&lt;0.001</td>
                      <td>74.8</td>
                      <td>0.13780</td>
                      <td>0.2056</td>
                      <td>1.000</td>
                      <td>&lt;0.001</td>
                      <td>1.000</td>
                    </tr>
                    <tr>
                      <td>b1=b5</td>
                      <td>0.3145</td>
                      <td>0.0280</td>
                      <td>11.24</td>
                      <td>&lt;0.001</td>
                      <td>95.0</td>
                      <td>0.25965</td>
                      <td>0.3693</td>
                      <td>1.000</td>
                      <td>&lt;0.001</td>
                      <td>1.000</td>
                    </tr>
                    <tr>
                      <td colspan="11">Type: response</td>
                    </tr>
                  </tbody>
                </table>
              </table-wrap>
            </sec>
            <p>The expression <monospace>"b8 = b2"</monospace> is
      special syntax to subtract the estimate in row number 8 from the
      estimate in row number 2 in the
      <monospace>probs</monospace>-output. The argument
      <monospace>equivalence = c(0, 0)</monospace> can be used to
      compute one-sided p-values, testing whether the contrast in the
      population is smaller than 0 (<monospace>p (NonSub)</monospace>
      column) or greater than 0 (<monospace>p (NonInf)</monospace>
      column). The point estimates for four contrasts are reported in
      the <monospace>Estimate</monospace> column. Note that to
      facilitate interpretation, we arranged the contrasts in a way that
      we theoretically expect positive values for all four of them.</p>
            <sec id="hypothesis-testing-nb-article">
              <title>Hypothesis testing</title>
              <p>If we chose hypothesis testing for our case study, we would
        test a combined null hypothesis <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
        that consists of four separate null hypotheses:
        <disp-formula><alternatives><tex-math><![CDATA[
        \begin{aligned}
        H_{01}:\ & P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 1, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
        H_{02}:\ &P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
        H_{03}:\ &P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 0, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
        H_{04}:\ & P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \leq \\
        & P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
        \end{aligned}
        ]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>01</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>02</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>03</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"><mml:msub><mml:mi>H</mml:mi><mml:mn>04</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mspace width="0.222em"/></mml:mtd><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right" style="text-align: right"/><mml:mtd columnalign="left" style="text-align: left"><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false" form="prefix">|</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>_</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
        The combined null hypothesis <inline-formula><alternatives><tex-math><![CDATA[H_0]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
        should only be rejected if <bold>all</bold> individual null
        hypotheses are rejected (i.e., intersection-union setting;
        <xref alt="Dmitrienko &amp; D’Agostino, 2013" rid="ref-dmitrienkoTraditionalMultiplicityAdjustment2013-nb-article" ref-type="bibr">Dmitrienko
        &amp; D’Agostino, 2013</xref>). In such cases, the error
        probabilities do not accumulate, and we would waste power when
        correcting for multiple tests.</p>
              <p>With a standard significance level of
        <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
        we would not reject all four null hypotheses (the p-value in the
        <monospace>p (NonInf)</monospace> column for the second
        hypothesis is not significant) and therefore also not reject the
        combined null hypothesis for this particular (simulated)
        dataset. Note that this decision would be wrong because we have
        simulated the data such that the combined alternative hypothesis
        <inline-formula><alternatives><tex-math><![CDATA[H_1]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:msub><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></alternatives></inline-formula>
        is actually true in the population.</p>
            </sec>
            <sec id="interval-estimation-nb-article">
              <title>Interval estimation</title>
              <p>If we chose parameter estimation for our case study, we would
        focus on the two-sided CIs of the four contrasts of interest.
        With a standard confidence level of
        <inline-formula><alternatives><tex-math><![CDATA[1 - \alpha = 0.95]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>,
        plausible values are clearly in the positive range for the
        first, third and fourth contrast, while both negative and
        positive values seem plausible for the second contrast. Note
        that due to the constrained range of the probability scale, the
        width of the CI differs between the four contrasts (which is the
        expected behavior for binomial GLMMs). The smallest width is
        observed for the first contrast (expert with correct advice
        vs. expert without advice) where both underlying probabilities
        are close to 1. The largest width is observed for the fourth
        contrast (non-expert with wrong advice vs. non-expert without
        advice), where both underlying probabilities are closer to
        0.5.</p>
            </sec>
          </sec>
        </sec>
        <sec id="step-6-perform-repeated-simulations-nb-article">
          <title>Step 6: Perform repeated simulations</title>
          <sec id="theory-8-nb-article">
            <title>THEORY</title>
            <p>Conducting all previous steps enables the analyst to 1)
      simulate a dataset, 2) estimate a GLMM, and 3) compute HTs or CIs
      for estimands of interest, mirroring the analysis that will later
      be performed for the actual dataset of the planned study. The last
      missing piece is to write code to perform the above steps
      repeatedly and allow for a setting using different sample sizes.
      On a conceptual level, we first require a function that takes as
      input the sample size and the full set of population parameter
      values. When planning for power, the function should return the
      p-value(s) of the HT(s) of interest when conducted on the
      simulated dataset. When planning for precision, the function
      should return the width of the CI(s) of interest. Secondly, we
      must run this function repeatedly with the same sample size and
      population parameters. Because even fitting GLMMs with frequentist
      methods can quickly become time-consuming, it is recommended to
      use parallel computing, that is running simulations on multiple
      cores of the computer at the same time to reduce total run time.
      Thirdly, the results of the repeated simulation must be collected
      and aggregated. When planning for power, we compute the relative
      frequency of (a) significant p-value(s) across repeated
      simulations. When planning for precision, we compute the average
      width of the CI(s). Lastly, we have to repeat the complete
      simulation for different sample sizes, to determine how big the
      sample must be in order to achieve the targeted power or
      precision.</p>
          </sec>
          <sec id="practice-8-nb-article">
            <title>PRACTICE</title>
            <p>We are finally ready to run our simulation-based sample size
      planning analyses to plan for power and for precision. Wrapping
      the <monospace>simulate</monospace> function already constructed
      earlier, the helper function
      <monospace>sim_and_analyse</monospace> performs all previous steps
      (simulate a dataset, fit a GLMM, compute p-values and CIs) in a
      single command.</p>
            <sec specific-use="notebook-content">
              <code language="r script">sim_and_analyse &lt;- function(
  formula_chr = "y_bin ~ 1 + expert + advice_present + advice_correct + 
    expert:advice_present + expert:advice_correct + (1|subject) + (1|item)",
  contrasts = c("b8 = b2", "b2 = b6", "b7 = b1", "b1 = b5"), ...){
  require(lme4)
  require(marginaleffects)
  require(tidyr)
  # simulate data
  dat &lt;- simulate(...)
  # fit model
  model &lt;- glmer(as.formula(formula_chr), data = dat, family = "binomial")
  # compute contrasts
  contr_df &lt;- expand_grid(advice_present = 0:1, advice_correct = 0:1,
    expert = 0:1)
  predictions(model, newdata = contr_df, type = "response", re.form = NA) |&gt;
    hypotheses(hypothesis = contrasts, equivalence = c(0, 0)) |&gt;
    data.frame()
}</code>
            </sec>
            <p>Simulation-based sample size planning can quickly become
      computationally intensive when we repeatedly simulate data and fit
      models for different parameter combinations or sample sizes. Thus,
      we use the future
      (<xref alt="Bengtsson, 2021" rid="ref-R-RJ-2021-048-nb-article" ref-type="bibr">Bengtsson,
      2021</xref>) and furrr
      (<xref alt="Vaughan &amp; Dancho, 2022" rid="ref-R-furrr-nb-article" ref-type="bibr">Vaughan
      &amp; Dancho, 2022</xref>) packages to perform computations in
      parallel. First, we enable parallelization with the
      <monospace>plan</monospace> function and specify how many parallel
      cores (“workers”) of our computer to use (users can find out the
      maximum number of cores on their computer with the command
      <monospace>parallel::detectCores()</monospace>), and set a seed to
      make the simulation reproducible.</p>
            <sec specific-use="notebook-content">
              <code language="r script">library(future)
plan("multisession", workers = 6)
set.seed(2)</code>
            </sec>
            <p>The next code chunk specifies a simulation grid with different
      settings for both the number of subjects
      (<monospace>n_subjects</monospace>) and the number of items
      (<monospace>n_items</monospace>), each combination being repeated
      <monospace>rep</monospace> times. We chose 300 repetitions for the
      data simulation at hand as it strikes a balance between achieving
      a robust statistical estimate and remaining computationally
      feasible. With the current settings, this simulation takes about
      one hour on a MacBook Pro from 2020 with M1 chip and 16 GB working
      memory. If you want to quickly experiment with the code yourself,
      a setting with <monospace>workers = 4</monospace> and
      <monospace>rep = 5</monospace> should finish in less than 5
      minutes, even on smaller machines.</p>
            <sec specific-use="notebook-content">
              <code language="r script">library(furrr)
sim_result &lt;- crossing(
  rep = 1:300,
  n_subjects = c(100, 150, 200, 250),
  n_items = c(10, 30, 50, 70)
) |&gt;
  mutate(res = future_pmap(., sim_and_analyse, 
    .options = furrr_options(seed = TRUE))) |&gt;
  unnest(col = res)</code>
            </sec>
            <p>The result of this computation is a data frame that contains
      the p-values and CIs of all specified contrasts for each simulated
      dataset. In some iterations (predominantly in conditions with
      small sample sizes), model estimation did not converge with the
      lme4 package. When the model fails to converge, it means that the
      statistical model being fitted to the data failed to reach a
      stable or valid solution during the estimation process. We do not
      remove these results because non-convergence can also happen when
      analyzing the real data we plan to collect, thus, we want to
      factor in this possibility to keep our simulation more
      realistic.</p>
            <sec id="power-results-nb-article">
              <title>Power results</title>
              <p>For our exemplary combined hypothesis, power is defined as
        the (long-run) percentage of simulations in which all four
        p-values of our individual hypotheses are significant at the
        <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>
        level. Based on our simulation outcomes, we compute a power
        estimate for each combination of
        <monospace>n_subjects</monospace> <inline-formula><alternatives><tex-math><![CDATA[\times]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>×</mml:mi></mml:math></alternatives></inline-formula>
        <monospace>n_items</monospace> (including 95% CIs) and visualize
        the results with the following
        code.<xref ref-type="fn" rid="fn4-nb-article">4</xref></p>
              <sec specific-use="notebook-content">
                <code language="r script"># The simulation results were computed in the full_simulation.qmd notebook
sim_result &lt;- readRDS(file = "results.rds")</code>
              </sec>
              <sec id="cell-fig-finalpwr-nb-article" specific-use="notebook-content">
                <code language="r script">library(binom)
alpha &lt;- 0.05
power &lt;- sim_result |&gt;
  pivot_wider(names_from = term, names_sep = "_", 
    values_from = estimate:p.value.equiv) |&gt;
  group_by(n_subjects, n_items) |&gt; 
  summarise(
    power = mean(`p.value.noninf_b1=b5` &lt; alpha &amp; 
        `p.value.noninf_b8=b2` &lt; alpha &amp; `p.value.noninf_b2=b6` &lt; alpha &amp; 
        `p.value.noninf_b7=b1` &lt; alpha), 
    n_sig = sum(`p.value.noninf_b1=b5` &lt; alpha &amp; 
        `p.value.noninf_b8=b2` &lt; alpha &amp; `p.value.noninf_b2=b6` &lt; alpha &amp; 
        `p.value.noninf_b7=b1` &lt; alpha),
    n = n(),
    ci.lwr = binom.confint(n_sig, n, method = "wilson")$lower,
    ci.upr = binom.confint(n_sig, n, method = "wilson")$upper, 
    .groups = "drop")
power |&gt;
  mutate(across(c(n_subjects, n_items), factor)) |&gt;
  ggplot(aes(n_subjects, n_items, fill = power)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.2f \n [%.2f; %.2f]", 
                                power, ci.lwr, ci.upr)), 
    color = "white", size = 4) +
  scale_fill_viridis_c(limits = c(0, 1)) +
  xlab("number of subjects") + ylab("number of items")</code>
                <fig id="fig-finalpwr-nb-article">
                  <caption>
                    <p>Figure 4: Simulation-based power estimates
          including 95% confidence interval of the case study for
          different numbers of subjects and items, based on a
          significance level of 0.05.</p>
                  </caption>
                  <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-finalpwr-1.png"/>
                </fig>
              </sec>
              <p>As should be the case, power estimates in
        <xref alt="Figure 4" rid="fig-finalpwr-nb-article">Figure 4</xref> increase
        with both the number of subjects and the number of items. The
        CIs reported here indicate how precisely power was estimated by
        our simulation. Higher precision (which would be reflected in
        narrower CIs) could be obtained by increasing the number of
        repetitions (<monospace>rep</monospace>) in the simulation. In
        practice, data simulations are often run multiple times with
        adjusted combinations of sample sizes. When running for the
        first time, it might be revealed that power is way too low (or
        much higher than required) for some combinations of
        <monospace>n_subjects</monospace> and
        <monospace>n_items</monospace>. When narrowing down the best
        combination that achieves sufficient power while at the same
        time striking a good balance of how many subjects and items are
        practically feasible, later rounds of data simulation will
        typically include a smaller grid of sample sizes combined with a
        higher number of repetitions. This will assure high precision
        for the final power estimates, which are then used for the
        sample size justification of the future study.</p>
              <p>Much has been written on the optimal amount of power to
        target in empirical research. The most prominent heuristic is to
        target a power of 0.8 (when combined with a type I error rate of
        <inline-formula><alternatives><tex-math><![CDATA[\alpha = 0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>),
        but depending on the research goals of the study, there are
        often good reasons to move away from this standard depending on
        the research goals and resource constraints
        (<xref alt="Lakens, Adolfi, et al., 2018" rid="ref-lakensJustifyYourAlpha2018-nb-article" ref-type="bibr">Lakens,
        Adolfi, et al., 2018</xref>;
        <xref alt="Lakens, 2022a" rid="ref-lakensSampleSizeJustification2022-nb-article" ref-type="bibr">Lakens,
        2022a</xref>). When target power has been specified, the number
        of subjects and the number of items in our study design can be
        traded against each other based on practical considerations. For
        the sake of the example, let the targeted power be indeed about
        0.8, using an <inline-formula><alternatives><tex-math><![CDATA[\alpha]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>α</mml:mi></mml:math></alternatives></inline-formula>
        of 0.05 to detect an effect of the expected size implied by our
        data simulation. This could be achieved by collecting data from
        200 subjects (about 25% of which will be experts), each
        completing the same 50 items (with advice present in about 67%
        of cases, which is correct in about 80% of cases with present
        advice). If collecting data from 200 subjects is not feasible,
        an alternative would be to recruit 150 subjects but increase the
        length of the experiment to over 70 items. However, 70 items
        might take too long to complete for the radiologists
        participating in the study, who have a busy schedule. The
        simulation suggests that it might also be possible to plan a
        shorter experiment with only 30 items if it is feasible to
        recruit an even higher number of subjects (&gt; 250, to be
        determined by additional rounds of power analysis). Design
        parameters that also affect power, and which could be
        investigated in the simulation to find a more optimal trade-off,
        are the ratio of experts, the frequency of whether advice is
        presented and whether it is correct.</p>
            </sec>
            <sec id="precision-results-nb-article">
              <title>Precision results</title>
              <p>When planning for precision, one could monitor the width of
        all four CIs at the same time. However, because the CIs of the
        four contrasts strongly differ in width, it is not trivial to
        decide which width one should target when deciding on the
        appropriate sample size. In contrast to planning for power,
        there are no common standards on how to specify the targeted
        precision. For our example, we use a simple heuristic but we
        strongly encourage readers to think about better alternatives
        that are appropriate in their own applications. Our simulations
        show that the smallest CI can be expected for the first contrast
        (expert with correct advice vs. expert without advice). The true
        contrast in probability for an average expert and an average
        item in this condition is
        <monospace>plogis(b_0 + b_e + b_a + b_c + b_ea + b_ec) - plogis(b_0 + b_e) =</monospace>
        <inline-formula><alternatives><tex-math><![CDATA[0.05]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mn>0.05</mml:mn></mml:math></alternatives></inline-formula>.
        We want the width of this CI to be smaller than 0.1. This would
        mean that if the point estimate happens to be close to the true
        value, the plausible values inside of a 95% CI would all be
        positive.</p>
              <p>Thus in our example, precision is defined as the (long-run)
        average width of a 95% CI for the probability contrast between
        experts with correct advice and experts without advice. Of
        course, lower width implies better precision. Based on our
        simulation outcomes, we compute the precision estimate for each
        combination of <monospace>n_subjects</monospace>
        <inline-formula><alternatives><tex-math><![CDATA[\times]]></tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="inline"><mml:mi>×</mml:mi></mml:math></alternatives></inline-formula>
        <monospace>n_items</monospace> (including 95% CIs) and visualize
        the results with the following code.</p>
              <sec id="cell-fig-finalprecision-nb-article" specific-use="notebook-content">
                <code language="r script">precision &lt;- sim_result |&gt;
  pivot_wider(names_from = term, names_sep = "_", 
    values_from = estimate:p.value.equiv) |&gt;
  group_by(n_subjects, n_items) |&gt;
  mutate(width = `conf.high_b8=b2` - `conf.low_b8=b2`) |&gt;
  summarise(precision = mean(width),
    ci.lwr = t.test(width)$conf.int[1],
    ci.upr = t.test(width)$conf.int[2], 
    .groups = "drop")
precision |&gt;
  mutate(across(c(n_subjects, n_items), factor)) |&gt;
  ggplot(aes(n_subjects, n_items, fill = precision)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.2f \n [%.2f; %.2f]", 
                                precision, ci.lwr, ci.upr)), 
    color = "white", size = 4) +
  scale_fill_viridis_c(limits = c(0, 0.3), direction = -1) +
  guides(fill = guide_legend(reverse=FALSE))</code>
                <fig id="fig-finalprecision-nb-article">
                  <caption>
                    <p>Figure 5: Simulation-based precision estimates
          (expected width of confidence intervals) including 95%
          confidence interval of the case study for different numbers of
          subjects and items, based on a confidence level of
          0.95.</p>
                  </caption>
                  <graphic mimetype="image" mime-subtype="png" xlink:href="manuscript_files/figure-jats/fig-finalprecision-1.png"/>
                </fig>
              </sec>
              <p>As should be the case, precision estimates in
        <xref alt="Figure 5" rid="fig-finalprecision-nb-article">Figure 5</xref>
        increase (i.e., average width of CI decreases) with both the
        number of subjects and the number of items. The CIs reported
        here indicate how precisely the expected width of the CI for our
        focal contrast was estimated by our simulation. Applying our
        simple heuristic of targeting an expected width smaller than
        0.1, we see the same trade-off between the number of subjects
        and the number of items as with planning for power. We could
        either choose 100 subjects and 30 items or 200 subjects and 10
        items. Note that our simple heuristic for determining sample
        size in the planning for precision scenario was quite liberal.
        This is reflected by the result that we would need a smaller
        sample size than in the planning for power scenario. With a more
        conservative precision target, the result is generally the
        opposite: As a rule, precise parameter estimates usually require
        bigger samples than null hypothesis testing.</p>
            </sec>
          </sec>
        </sec>
        <sec id="sensitivity-analysis-nb-article">
          <title>Sensitivity analysis</title>
          <p>In our case study, we have performed simulation-based sample size
    planning from a single set of parameter values that reflect our
    assumptions of an expected effect size. Instead of extracting this
    expected effect size from meta-analyses or pilot data, which has
    been the main focus of previous tutorials (e.g.,
    <xref alt="Kumle et al., 2021" rid="ref-kumleEstimatingPowerGeneralized2021-nb-article" ref-type="bibr">Kumle
    et al., 2021</xref>), we have demonstrated some strategies to
    determine plausible parameter values in GLMMs based on domain
    knowledge. Domain knowledge can be considered a vague theoretical
    model about the data-generating process that is less formal and can
    only be accessed by a back-and-forth exchange in which domain
    experts assess the plausibility of simulated data. When sample sizes
    are chosen based on the results of our simulation-based power
    analysis, a future study will be informative to reject the null
    hypothesis if an effect of our <italic>expected size</italic> is
    present (or estimate the effect with satisfying precision). However,
    if the true effect is indeed smaller, power (or precision) will be
    lower, and the study might not be sufficiently informative. A
    common, more conservative strategy for sample size justification is
    to perform sample size planning for the smallest effect size of
    interest (SESOI). An effect smaller than the SESOI would be
    considered too small to be interesting or practically meaningful,
    even if the effect is not actually zero
    (<xref alt="King, 2011" rid="ref-kingPointMinimalImportant2011-nb-article" ref-type="bibr">King,
    2011</xref>;
    <xref alt="Lakens, Scheel, et al., 2018" rid="ref-lakensEquivalenceTestingPsychological2018-nb-article" ref-type="bibr">Lakens,
    Scheel, et al., 2018</xref>). For strategies on the even more
    difficult task of specifying a plausible SESOI, as well as a
    thorough discussion of various topics concerning power analysis, see
    (<xref alt="Lakens, 2022b" rid="ref-lakensImprovingYourStatistical2022-nb-article" ref-type="bibr">Lakens,
    2022b</xref>). When domain knowledge or formal theories about the
    research topic of interest are too vague to specify a meaningful
    SESOI, it is still recommended to demonstrate power or precision for
    different effect sizes in what is called <italic>sensitivity power
    analysis</italic>. By simulating power (or precision) for different
    effect sizes (in addition to the different number of subjects and
    items), one can make sure that power (or precision) would still be
    sufficient to detect smaller effect sizes than our expected effect
    or at least get an impression of how strongly power (or precision)
    depends on the size of the true effect. For our case study that
    investigates combined hypotheses in a GLMM modeling framework,
    sensitivity analysis would require manually specifying additional
    sets of plausible parameter values that reflect scenarios with
    smaller or larger differences between groups with respect to our
    specific research question. Power (or precision) could then be
    simulated for several of these scenarios (across different numbers
    of subjects and items, as considered earlier).</p>
        </sec>
      </sec>
      <sec id="conclusion-and-outlook-nb-article">
        <title>Conclusion and outlook</title>
        <p>The goal of this tutorial was to teach researchers how to perform
  tailored simulation-based sample size planning for GLMMs. Beyond the
  specifics of our concrete case study, we want to outline six
  developments regarding the future role of simulation-based sample size
  planning in experimental research:</p>
        <p>In light of the ongoing replication crisis and an existing
  literature full of underpowered studies, there is a growing need for
  simulation-based sample size planning in experimental research: In
  order to conduct informative research, GLMMs offer a flexible
  statistical framework to analyze complex experimental study designs.
  However, existing formula-based heuristics and user-friendly software
  tools for a priori power analysis are often not sufficient. Therefore,
  simulation-based power analysis is becoming increasingly needed since
  it provides experimental researchers with a tailored approach to
  estimating required sample sizes before data collection.</p>
        <p>Managing data simulations more easily with discrete predictor
  variables: Simulation-based sample size planning becomes more
  manageable when all predictor variables are discrete (like in the
  presented case study) and fixed by the study design. This allows
  researchers to focus on simulating outcome variables while avoiding
  the need for complex simulations of predictor values, which would
  introduce additional assumptions. By simplifying the simulation
  process, researchers can obtain reliable estimates for power or
  precision without compromising realistic assumptions about the
  data-generating process implied by the study design.</p>
        <p>Teaching data simulation skills: The ability to conduct
  simulation-based sample size planning is a valuable skill that should
  be taught to experimental researchers. By incorporating such training
  into research methods courses and workshops, researchers can gain a
  deeper understanding of statistical power or precision, and improve
  the quality of their experimental designs. Equipping researchers with
  the knowledge and tools to perform simulation-based sample size
  planning enables them to make informed decisions and enhance the rigor
  of their studies. The need to reason about how to simulate plausible
  data that is in line with the research hypothesis, while not violating
  domain expertise on how plausible data should look, might also
  contribute to planning more insightful studies that can answer more
  precise research questions
  (<xref alt="Yarkoni, 2022" rid="ref-yarkoniGeneralizabilityCrisis2022-nb-article" ref-type="bibr">Yarkoni,
  2022</xref>).</p>
        <p>Addressing the mismatch in effort perception: There is often a
  significant disconnect between the amount of effort required to
  perform tailored simulation-based sample size planning and the
  perceived effort estimated by researchers and collaborators in
  experimental research. Many researchers request simulation-based power
  analyses from statisticians or methodological experts without fully
  comprehending the complexity and time-consuming nature of these
  tailored simulations. It is crucial to raise awareness about the
  effort involved to ensure realistic expectations and effective
  collaboration between researchers and methodological experts.</p>
        <p>Recognizing the value of simulation-based design analysis: Tailored
  data simulations and power analyses are not mere technicalities; they
  are valuable research contributions that deserve recognition in
  experimental research. They offer insights into the robustness and
  sensitivity of experimental designs, helping researchers make informed
  decisions about sample sizes, effect sizes, and statistical power or
  precision. Their importance can be reflected by allocating them a
  separate publication or incorporating them as a significant component
  of stage 1 preregistered reports
  (<xref alt="Chambers &amp; Tzavella, 2022" rid="ref-chambersPresentFutureRegistered2022-nb-article" ref-type="bibr">Chambers
  &amp; Tzavella, 2022</xref>).</p>
        <p>Integration with Open Science and preregistration practices:
  Simulation-based sample size planning aligns well with the principles
  of Open Science and preregistration in experimental research. When
  researchers have access to simulated data based on their pre-specified
  model, analyzing the collected dataset becomes straightforward and
  unambiguous. By preregistering their simulation-based sample size
  plan, researchers enhance the transparency and accountability of their
  experimental procedures, contributing to the credibility and
  reproducibility of research.</p>
      </sec>
    </body>
    <back>
      <ref-list>
        <title>References</title>
        <ref id="ref-albersWhenPowerAnalyses2018a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Albers</surname>
                <given-names>Casper</given-names>
              </name>
              <name>
                <surname>Lakens</surname>
                <given-names>Daniël</given-names>
              </name>
            </person-group>
            <article-title>When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias</article-title>
            <source>Journal of Experimental Social Psychology</source>
            <year iso-8601-date="2018-01">2018</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-05">2024</year>
              <month>06</month>
              <day>05</day>
            </date-in-citation>
            <volume>74</volume>
            <issn>00221031</issn>
            <pub-id pub-id-type="doi">10.1016/j.jesp.2017.09.004</pub-id>
            <fpage>187</fpage>
            <lpage>195</lpage>
          </element-citation>
        </ref>
        <ref id="ref-arendStatisticalPowerTwolevel2019-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Arend</surname>
                <given-names>Matthias G.</given-names>
              </name>
              <name>
                <surname>Schäfer</surname>
                <given-names>Thomas</given-names>
              </name>
            </person-group>
            <article-title>Statistical power in two-level models: A tutorial based on Monte Carlo simulation.</article-title>
            <source>Psychological Methods</source>
            <year iso-8601-date="2019-02">2019</year>
            <month>02</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-08">2023</year>
              <month>08</month>
              <day>08</day>
            </date-in-citation>
            <volume>24</volume>
            <issue>1</issue>
            <issn>1939-1463, 1082-989X</issn>
            <pub-id pub-id-type="doi">10.1037/met0000195</pub-id>
            <fpage>1</fpage>
            <lpage>19</lpage>
          </element-citation>
        </ref>
        <ref id="ref-batesFittingLinearMixedEffects2015-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Bates</surname>
                <given-names>Douglas</given-names>
              </name>
              <name>
                <surname>Mächler</surname>
                <given-names>Martin</given-names>
              </name>
              <name>
                <surname>Bolker</surname>
                <given-names>Ben</given-names>
              </name>
              <name>
                <surname>Walker</surname>
                <given-names>Steve</given-names>
              </name>
            </person-group>
            <article-title>Fitting Linear Mixed-Effects Models Using Lme4</article-title>
            <source>Journal of Statistical Software</source>
            <year iso-8601-date="2015">2015</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2022-07-14">2022</year>
              <month>07</month>
              <day>14</day>
            </date-in-citation>
            <volume>67</volume>
            <issue>1</issue>
            <issn>1548-7660</issn>
            <pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-brooksGlmmTMBBalancesSpeed2017-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Brooks</surname>
                <given-names>Mollie</given-names>
                <suffix>E.</suffix>
              </name>
              <name>
                <surname>Kristensen</surname>
                <given-names>Kasper</given-names>
              </name>
              <name>
                <surname>Benthem</surname>
                <given-names>van</given-names>
                <suffix>J.</suffix>
              </name>
              <name>
                <surname>Magnusson</surname>
                <given-names>Arni</given-names>
              </name>
              <name>
                <surname>Berg</surname>
                <given-names>Casper</given-names>
                <suffix>W.</suffix>
              </name>
              <name>
                <surname>Nielsen</surname>
                <given-names>Anders</given-names>
              </name>
              <name>
                <surname>Skaug</surname>
                <given-names>Hans</given-names>
                <suffix>J.</suffix>
              </name>
              <name>
                <surname>Mächler</surname>
                <given-names>Martin</given-names>
              </name>
              <name>
                <surname>Bolker</surname>
                <given-names>Benjamin</given-names>
                <suffix>M.</suffix>
              </name>
            </person-group>
            <article-title>glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling</article-title>
            <source>The R Journal</source>
            <year iso-8601-date="2017">2017</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-05-24">2024</year>
              <month>05</month>
              <day>24</day>
            </date-in-citation>
            <volume>9</volume>
            <issue>2</issue>
            <issn>2073-4859</issn>
            <pub-id pub-id-type="doi">10.32614/RJ-2017-066</pub-id>
            <fpage>378</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-brysbaertPowerAnalysisEffect2018-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Brysbaert</surname>
                <given-names>Marc</given-names>
              </name>
              <name>
                <surname>Stevens</surname>
                <given-names>Michaël</given-names>
              </name>
            </person-group>
            <article-title>Power Analysis and Effect Size in Mixed Effects Models: A Tutorial</article-title>
            <source>Journal of Cognition</source>
            <year iso-8601-date="2018-01">2018</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2022-07-14">2022</year>
              <month>07</month>
              <day>14</day>
            </date-in-citation>
            <volume>1</volume>
            <issue>1</issue>
            <issn>2514-4820</issn>
            <pub-id pub-id-type="doi">10.5334/joc.10</pub-id>
            <fpage>9</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-burknerAdvancedBayesianMultilevel2018-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Bürkner</surname>
                <given-names>Paul-Christian</given-names>
              </name>
            </person-group>
            <article-title>Advanced Bayesian Multilevel Modeling with the R Package brms</article-title>
            <source>The R Journal</source>
            <year iso-8601-date="2018">2018</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-05-24">2024</year>
              <month>05</month>
              <day>24</day>
            </date-in-citation>
            <volume>10</volume>
            <issue>1</issue>
            <issn>2073-4859</issn>
            <pub-id pub-id-type="doi">10.32614/RJ-2018-017</pub-id>
            <fpage>395</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-burknerBrmsPackageBayesian2017-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Bürkner</surname>
                <given-names>Paul-Christian</given-names>
              </name>
            </person-group>
            <article-title>Brms: An R Package for Bayesian Multilevel Models Using Stan</article-title>
            <source>Journal of Statistical Software</source>
            <year iso-8601-date="2017-08">2017</year>
            <month>08</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-11">2023</year>
              <month>08</month>
              <day>11</day>
            </date-in-citation>
            <volume>80</volume>
            <issn>1548-7660</issn>
            <pub-id pub-id-type="doi">10.18637/jss.v080.i01</pub-id>
            <fpage>1</fpage>
            <lpage>28</lpage>
          </element-citation>
        </ref>
        <ref id="ref-chambersPresentFutureRegistered2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Chambers</surname>
                <given-names>Christopher D.</given-names>
              </name>
              <name>
                <surname>Tzavella</surname>
                <given-names>Loukia</given-names>
              </name>
            </person-group>
            <article-title>The past, present and future of Registered Reports</article-title>
            <source>Nature Human Behaviour</source>
            <publisher-name>Nature Publishing Group</publisher-name>
            <year iso-8601-date="2022-01">2022</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-09-11">2023</year>
              <month>09</month>
              <day>11</day>
            </date-in-citation>
            <volume>6</volume>
            <issue>1</issue>
            <issn>2397-3374</issn>
            <pub-id pub-id-type="doi">10.1038/s41562-021-01193-7</pub-id>
            <fpage>29</fpage>
            <lpage>42</lpage>
          </element-citation>
        </ref>
        <ref id="ref-cohenPowerPrimer1992-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Cohen</surname>
                <given-names>Jacob</given-names>
              </name>
            </person-group>
            <article-title>A power primer.</article-title>
            <source>Psychological Bulletin</source>
            <year iso-8601-date="1992">1992</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-04">2024</year>
              <month>06</month>
              <day>04</day>
            </date-in-citation>
            <volume>112</volume>
            <issue>1</issue>
            <issn>1939-1455, 0033-2909</issn>
            <pub-id pub-id-type="doi">10.1037/0033-2909.112.1.155</pub-id>
            <fpage>155</fpage>
            <lpage>159</lpage>
          </element-citation>
        </ref>
        <ref id="ref-cummingNewStatisticsWhy2014-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Cumming</surname>
                <given-names>Geoff</given-names>
              </name>
            </person-group>
            <article-title>The New Statistics: Why and How</article-title>
            <source>Psychological Science</source>
            <year iso-8601-date="2014-01">2014</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-04">2024</year>
              <month>06</month>
              <day>04</day>
            </date-in-citation>
            <volume>25</volume>
            <issue>1</issue>
            <issn>0956-7976, 1467-9280</issn>
            <pub-id pub-id-type="doi">10.1177/0956797613504966</pub-id>
            <fpage>7</fpage>
            <lpage>29</lpage>
          </element-citation>
        </ref>
        <ref id="ref-debruineUnderstandingMixedEffectsModels2021-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>DeBruine</surname>
                <given-names>Lisa</given-names>
              </name>
              <name>
                <surname>Barr</surname>
                <given-names>Dale J.</given-names>
              </name>
            </person-group>
            <article-title>Understanding Mixed-Effects Models Through Data Simulation</article-title>
            <source>Advances in Methods and Practices in Psychological Science</source>
            <publisher-name>SAGE Publications Inc</publisher-name>
            <year iso-8601-date="2021-01">2021</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2022-07-14">2022</year>
              <month>07</month>
              <day>14</day>
            </date-in-citation>
            <volume>4</volume>
            <issue>1</issue>
            <issn>2515-2459</issn>
            <pub-id pub-id-type="doi">10.1177/2515245920965119</pub-id>
            <fpage>2515245920965119</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-deffnerCausalFrameworkCrossCultural2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Deffner</surname>
                <given-names>Dominik</given-names>
              </name>
              <name>
                <surname>Rohrer</surname>
                <given-names>Julia M.</given-names>
              </name>
              <name>
                <surname>McElreath</surname>
                <given-names>Richard</given-names>
              </name>
            </person-group>
            <article-title>A Causal Framework for Cross-Cultural Generalizability</article-title>
            <source>Advances in Methods and Practices in Psychological Science</source>
            <year iso-8601-date="2022-07">2022</year>
            <month>07</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2022-12-01">2022</year>
              <month>12</month>
              <day>01</day>
            </date-in-citation>
            <volume>5</volume>
            <issue>3</issue>
            <issn>2515-2459, 2515-2467</issn>
            <pub-id pub-id-type="doi">10.1177/25152459221106366</pub-id>
            <fpage>251524592211063</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-dmitrienkoTraditionalMultiplicityAdjustment2013-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Dmitrienko</surname>
                <given-names>Alex</given-names>
              </name>
              <name>
                <surname>D’Agostino</surname>
                <given-names>Ralph</given-names>
              </name>
            </person-group>
            <article-title>Traditional multiplicity adjustment methods in clinical trials</article-title>
            <source>Statistics in Medicine</source>
            <year iso-8601-date="2013-12">2013</year>
            <month>12</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-18">2023</year>
              <month>08</month>
              <day>18</day>
            </date-in-citation>
            <volume>32</volume>
            <issue>29</issue>
            <issn>02776715</issn>
            <pub-id pub-id-type="doi">10.1002/sim.5990</pub-id>
            <fpage>5172</fpage>
            <lpage>5218</lpage>
          </element-citation>
        </ref>
        <ref id="ref-fahrmeirRegressionModelsMethods2021-nb-article">
          <element-citation publication-type="book">
            <person-group person-group-type="author">
              <name>
                <surname>Fahrmeir</surname>
                <given-names>Ludwig</given-names>
              </name>
              <name>
                <surname>Kneib</surname>
                <given-names>Thomas</given-names>
              </name>
              <name>
                <surname>Lang</surname>
                <given-names>Stefan</given-names>
              </name>
              <name>
                <surname>Marx</surname>
                <given-names>Brian D.</given-names>
              </name>
            </person-group>
            <source>Regression: Models, Methods and Applications</source>
            <publisher-name>Springer Berlin Heidelberg</publisher-name>
            <publisher-loc>Berlin, Heidelberg</publisher-loc>
            <year iso-8601-date="2021">2021</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-18">2023</year>
              <month>08</month>
              <day>18</day>
            </date-in-citation>
            <isbn>978-3-662-63881-1 978-3-662-63882-8</isbn>
            <pub-id pub-id-type="doi">10.1007/978-3-662-63882-8</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-gelmanBayesianWorkflow2020-nb-article">
          <element-citation>
            <person-group person-group-type="author">
              <name>
                <surname>Gelman</surname>
                <given-names>Andrew</given-names>
              </name>
              <name>
                <surname>Vehtari</surname>
                <given-names>Aki</given-names>
              </name>
              <name>
                <surname>Simpson</surname>
                <given-names>Daniel</given-names>
              </name>
              <name>
                <surname>Margossian</surname>
                <given-names>Charles C.</given-names>
              </name>
              <name>
                <surname>Carpenter</surname>
                <given-names>Bob</given-names>
              </name>
              <name>
                <surname>Yao</surname>
                <given-names>Yuling</given-names>
              </name>
              <name>
                <surname>Kennedy</surname>
                <given-names>Lauren</given-names>
              </name>
              <name>
                <surname>Gabry</surname>
                <given-names>Jonah</given-names>
              </name>
              <name>
                <surname>Bürkner</surname>
                <given-names>Paul-Christian</given-names>
              </name>
              <name>
                <surname>Modrák</surname>
                <given-names>Martin</given-names>
              </name>
            </person-group>
            <article-title>Bayesian Workflow</article-title>
            <publisher-name>arXiv</publisher-name>
            <year iso-8601-date="2020-11">2020</year>
            <month>11</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-04-09">2024</year>
              <month>04</month>
              <day>09</day>
            </date-in-citation>
            <uri>https://arxiv.org/abs/2011.01808</uri>
          </element-citation>
        </ref>
        <ref id="ref-gomilaMissingDataExperiments2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Gomila</surname>
                <given-names>Robin</given-names>
              </name>
              <name>
                <surname>Clark</surname>
                <given-names>Chelsey S.</given-names>
              </name>
            </person-group>
            <article-title>Missing data in experiments: Challenges and solutions.</article-title>
            <source>Psychological Methods</source>
            <year iso-8601-date="2022-04">2022</year>
            <month>04</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-05">2024</year>
              <month>06</month>
              <day>05</day>
            </date-in-citation>
            <volume>27</volume>
            <issue>2</issue>
            <issn>1939-1463, 1082-989X</issn>
            <pub-id pub-id-type="doi">10.1037/met0000361</pub-id>
            <fpage>143</fpage>
            <lpage>155</lpage>
          </element-citation>
        </ref>
        <ref id="ref-greenSIMRPackagePower2016a-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Green</surname>
                <given-names>Peter</given-names>
              </name>
              <name>
                <surname>MacLeod</surname>
                <given-names>Catriona J.</given-names>
              </name>
            </person-group>
            <article-title>SIMR : An R package for power analysis of generalized linear mixed models by simulation</article-title>
            <source>Methods in Ecology and Evolution</source>
            <person-group person-group-type="editor">
              <name>
                <surname>Nakagawa</surname>
                <given-names>Shinichi</given-names>
              </name>
            </person-group>
            <year iso-8601-date="2016-04">2016</year>
            <month>04</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-08">2024</year>
              <month>06</month>
              <day>08</day>
            </date-in-citation>
            <volume>7</volume>
            <issue>4</issue>
            <issn>2041-210X, 2041-210X</issn>
            <pub-id pub-id-type="doi">10.1111/2041-210X.12504</pub-id>
            <fpage>493</fpage>
            <lpage>498</lpage>
          </element-citation>
        </ref>
        <ref id="ref-kainPracticalGuidePower2015-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Kain</surname>
                <given-names>Morgan P.</given-names>
              </name>
              <name>
                <surname>Bolker</surname>
                <given-names>Ben M.</given-names>
              </name>
              <name>
                <surname>McCoy</surname>
                <given-names>Michael W.</given-names>
              </name>
            </person-group>
            <article-title>A practical guide and power analysis for GLMMs: Detecting among treatment variation in random effects</article-title>
            <source>PeerJ</source>
            <year iso-8601-date="2015-09">2015</year>
            <month>09</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-08">2024</year>
              <month>06</month>
              <day>08</day>
            </date-in-citation>
            <volume>3</volume>
            <issn>2167-8359</issn>
            <pub-id pub-id-type="doi">10.7717/peerj.1226</pub-id>
            <fpage>e1226</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-kelleySampleSizePlanning2006-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Kelley</surname>
                <given-names>Ken</given-names>
              </name>
              <name>
                <surname>Rausch</surname>
                <given-names>Joseph R.</given-names>
              </name>
            </person-group>
            <article-title>Sample size planning for the standardized mean difference: Accuracy in parameter estimation via narrow confidence intervals.</article-title>
            <source>Psychological Methods</source>
            <year iso-8601-date="2006">2006</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-03-13">2024</year>
              <month>03</month>
              <day>13</day>
            </date-in-citation>
            <volume>11</volume>
            <issue>4</issue>
            <issn>1939-1463, 1082-989X</issn>
            <pub-id pub-id-type="doi">10.1037/1082-989X.11.4.363</pub-id>
            <fpage>363</fpage>
            <lpage>385</lpage>
          </element-citation>
        </ref>
        <ref id="ref-kingPointMinimalImportant2011-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>King</surname>
                <given-names>Madeleine T</given-names>
              </name>
            </person-group>
            <article-title>A point of minimal important difference (MID): A critique of terminology and methods</article-title>
            <source>Expert Review of Pharmacoeconomics &amp; Outcomes Research</source>
            <year iso-8601-date="2011-04">2011</year>
            <month>04</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-18">2023</year>
              <month>08</month>
              <day>18</day>
            </date-in-citation>
            <volume>11</volume>
            <issue>2</issue>
            <issn>1473-7167, 1744-8379</issn>
            <pub-id pub-id-type="doi">10.1586/erp.11.9</pub-id>
            <fpage>171</fpage>
            <lpage>184</lpage>
          </element-citation>
        </ref>
        <ref id="ref-kruschkeBayesianNewStatistics2018-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Kruschke</surname>
                <given-names>John K.</given-names>
              </name>
              <name>
                <surname>Liddell</surname>
                <given-names>Torrin M.</given-names>
              </name>
            </person-group>
            <article-title>The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective</article-title>
            <source>Psychonomic Bulletin &amp; Review</source>
            <year iso-8601-date="2018-02">2018</year>
            <month>02</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-04">2024</year>
              <month>06</month>
              <day>04</day>
            </date-in-citation>
            <volume>25</volume>
            <issue>1</issue>
            <issn>1069-9384, 1531-5320</issn>
            <pub-id pub-id-type="doi">10.3758/s13423-016-1221-4</pub-id>
            <fpage>178</fpage>
            <lpage>206</lpage>
          </element-citation>
        </ref>
        <ref id="ref-kumleEstimatingPowerGeneralized2021-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Kumle</surname>
                <given-names>Levi</given-names>
              </name>
              <name>
                <surname>Võ</surname>
                <given-names>Melissa L.-H.</given-names>
              </name>
              <name>
                <surname>Draschkow</surname>
                <given-names>Dejan</given-names>
              </name>
            </person-group>
            <article-title>Estimating power in (generalized) linear mixed models: An open introduction and tutorial in R</article-title>
            <source>Behavior Research Methods</source>
            <year iso-8601-date="2021-12">2021</year>
            <month>12</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2022-07-07">2022</year>
              <month>07</month>
              <day>07</day>
            </date-in-citation>
            <volume>53</volume>
            <issue>6</issue>
            <issn>1554-3528</issn>
            <pub-id pub-id-type="doi">10.3758/s13428-021-01546-0</pub-id>
            <fpage>2528</fpage>
            <lpage>2543</lpage>
          </element-citation>
        </ref>
        <ref id="ref-lafitSelectionNumberParticipants2021-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lafit</surname>
                <given-names>Ginette</given-names>
              </name>
              <name>
                <surname>Adolf</surname>
                <given-names>Janne K.</given-names>
              </name>
              <name>
                <surname>Dejonckheere</surname>
                <given-names>Egon</given-names>
              </name>
              <name>
                <surname>Myin-Germeys</surname>
                <given-names>Inez</given-names>
              </name>
              <name>
                <surname>Viechtbauer</surname>
                <given-names>Wolfgang</given-names>
              </name>
              <name>
                <surname>Ceulemans</surname>
                <given-names>Eva</given-names>
              </name>
            </person-group>
            <article-title>Selection of the Number of Participants in Intensive Longitudinal Studies: A User-Friendly Shiny App and Tutorial for Performing Power Analysis in Multilevel Regression Models That Account for Temporal Dependencies</article-title>
            <source>Advances in Methods and Practices in Psychological Science</source>
            <year iso-8601-date="2021-01">2021</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-08">2023</year>
              <month>08</month>
              <day>08</day>
            </date-in-citation>
            <volume>4</volume>
            <issue>1</issue>
            <issn>2515-2459, 2515-2467</issn>
            <pub-id pub-id-type="doi">10.1177/2515245920978738</pub-id>
            <fpage>251524592097873</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-lakensEquivalenceTestingPsychological2018-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lakens</surname>
                <given-names>Daniël</given-names>
              </name>
              <name>
                <surname>Scheel</surname>
                <given-names>Anne M.</given-names>
              </name>
              <name>
                <surname>Isager</surname>
                <given-names>Peder M.</given-names>
              </name>
            </person-group>
            <article-title>Equivalence Testing for Psychological Research: A Tutorial</article-title>
            <source>Advances in Methods and Practices in Psychological Science</source>
            <year iso-8601-date="2018-06">2018</year>
            <month>06</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-05">2024</year>
              <month>06</month>
              <day>05</day>
            </date-in-citation>
            <volume>1</volume>
            <issue>2</issue>
            <issn>2515-2459, 2515-2467</issn>
            <pub-id pub-id-type="doi">10.1177/2515245918770963</pub-id>
            <fpage>259</fpage>
            <lpage>269</lpage>
          </element-citation>
        </ref>
        <ref id="ref-lakensImprovingYourStatistical2022-nb-article">
          <element-citation>
            <person-group person-group-type="author">
              <name>
                <surname>Lakens</surname>
                <given-names>Daniël</given-names>
              </name>
            </person-group>
            <article-title>Improving Your Statistical Inferences</article-title>
            <publisher-name>Zenodo</publisher-name>
            <year iso-8601-date="2022-04">2022</year>
            <month>04</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-09">2023</year>
              <month>08</month>
              <day>09</day>
            </date-in-citation>
            <pub-id pub-id-type="doi">10.5281/ZENODO.6409077</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-lakensJustifyYourAlpha2018-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lakens</surname>
                <given-names>Daniël</given-names>
              </name>
              <name>
                <surname>Adolfi</surname>
                <given-names>Federico G.</given-names>
              </name>
              <name>
                <surname>Albers</surname>
                <given-names>Casper J.</given-names>
              </name>
              <name>
                <surname>Anvari</surname>
                <given-names>Farid</given-names>
              </name>
              <name>
                <surname>Apps</surname>
                <given-names>Matthew A. J.</given-names>
              </name>
              <name>
                <surname>Argamon</surname>
                <given-names>Shlomo E.</given-names>
              </name>
              <name>
                <surname>Baguley</surname>
                <given-names>Thom</given-names>
              </name>
              <name>
                <surname>Becker</surname>
                <given-names>Raymond B.</given-names>
              </name>
              <name>
                <surname>Benning</surname>
                <given-names>Stephen D.</given-names>
              </name>
              <name>
                <surname>Bradford</surname>
                <given-names>Daniel E.</given-names>
              </name>
              <name>
                <surname>Buchanan</surname>
                <given-names>Erin M.</given-names>
              </name>
              <name>
                <surname>Caldwell</surname>
                <given-names>Aaron R.</given-names>
              </name>
              <name>
                <surname>Van Calster</surname>
                <given-names>Ben</given-names>
              </name>
              <name>
                <surname>Carlsson</surname>
                <given-names>Rickard</given-names>
              </name>
              <name>
                <surname>Chen</surname>
                <given-names>Sau-Chin</given-names>
              </name>
              <name>
                <surname>Chung</surname>
                <given-names>Bryan</given-names>
              </name>
              <name>
                <surname>Colling</surname>
                <given-names>Lincoln J.</given-names>
              </name>
              <name>
                <surname>Collins</surname>
                <given-names>Gary S.</given-names>
              </name>
              <name>
                <surname>Crook</surname>
                <given-names>Zander</given-names>
              </name>
              <name>
                <surname>Cross</surname>
                <given-names>Emily S.</given-names>
              </name>
              <name>
                <surname>Daniels</surname>
                <given-names>Sameera</given-names>
              </name>
              <name>
                <surname>Danielsson</surname>
                <given-names>Henrik</given-names>
              </name>
              <name>
                <surname>DeBruine</surname>
                <given-names>Lisa</given-names>
              </name>
              <name>
                <surname>Dunleavy</surname>
                <given-names>Daniel J.</given-names>
              </name>
              <name>
                <surname>Earp</surname>
                <given-names>Brian D.</given-names>
              </name>
              <name>
                <surname>Feist</surname>
                <given-names>Michele I.</given-names>
              </name>
              <name>
                <surname>Ferrell</surname>
                <given-names>Jason D.</given-names>
              </name>
              <name>
                <surname>Field</surname>
                <given-names>James G.</given-names>
              </name>
              <name>
                <surname>Fox</surname>
                <given-names>Nicholas W.</given-names>
              </name>
              <name>
                <surname>Friesen</surname>
                <given-names>Amanda</given-names>
              </name>
              <name>
                <surname>Gomes</surname>
                <given-names>Caio</given-names>
              </name>
              <name>
                <surname>Gonzalez-Marquez</surname>
                <given-names>Monica</given-names>
              </name>
              <name>
                <surname>Grange</surname>
                <given-names>James A.</given-names>
              </name>
              <name>
                <surname>Grieve</surname>
                <given-names>Andrew P.</given-names>
              </name>
              <name>
                <surname>Guggenberger</surname>
                <given-names>Robert</given-names>
              </name>
              <name>
                <surname>Grist</surname>
                <given-names>James</given-names>
              </name>
              <name>
                <surname>van Harmelen</surname>
                <given-names>Anne-Laura</given-names>
              </name>
              <name>
                <surname>Hasselman</surname>
                <given-names>Fred</given-names>
              </name>
              <name>
                <surname>Hochard</surname>
                <given-names>Kevin D.</given-names>
              </name>
              <name>
                <surname>Hoffarth</surname>
                <given-names>Mark R.</given-names>
              </name>
              <name>
                <surname>Holmes</surname>
                <given-names>Nicholas P.</given-names>
              </name>
              <name>
                <surname>Ingre</surname>
                <given-names>Michael</given-names>
              </name>
              <name>
                <surname>Isager</surname>
                <given-names>Peder M.</given-names>
              </name>
              <name>
                <surname>Isotalus</surname>
                <given-names>Hanna K.</given-names>
              </name>
              <name>
                <surname>Johansson</surname>
                <given-names>Christer</given-names>
              </name>
              <name>
                <surname>Juszczyk</surname>
                <given-names>Konrad</given-names>
              </name>
              <name>
                <surname>Kenny</surname>
                <given-names>David A.</given-names>
              </name>
              <name>
                <surname>Khalil</surname>
                <given-names>Ahmed A.</given-names>
              </name>
              <name>
                <surname>Konat</surname>
                <given-names>Barbara</given-names>
              </name>
              <name>
                <surname>Lao</surname>
                <given-names>Junpeng</given-names>
              </name>
              <name>
                <surname>Larsen</surname>
                <given-names>Erik Gahner</given-names>
              </name>
              <name>
                <surname>Lodder</surname>
                <given-names>Gerine M. A.</given-names>
              </name>
              <name>
                <surname>Lukavský</surname>
                <given-names>Jiří</given-names>
              </name>
              <name>
                <surname>Madan</surname>
                <given-names>Christopher R.</given-names>
              </name>
              <name>
                <surname>Manheim</surname>
                <given-names>David</given-names>
              </name>
              <name>
                <surname>Martin</surname>
                <given-names>Stephen R.</given-names>
              </name>
              <name>
                <surname>Martin</surname>
                <given-names>Andrea E.</given-names>
              </name>
              <name>
                <surname>Mayo</surname>
                <given-names>Deborah G.</given-names>
              </name>
              <name>
                <surname>McCarthy</surname>
                <given-names>Randy J.</given-names>
              </name>
              <name>
                <surname>McConway</surname>
                <given-names>Kevin</given-names>
              </name>
              <name>
                <surname>McFarland</surname>
                <given-names>Colin</given-names>
              </name>
              <name>
                <surname>Nio</surname>
                <given-names>Amanda Q. X.</given-names>
              </name>
              <name>
                <surname>Nilsonne</surname>
                <given-names>Gustav</given-names>
              </name>
              <name>
                <surname>de Oliveira</surname>
                <given-names>Cilene Lino</given-names>
              </name>
              <name>
                <surname>de Xivry</surname>
                <given-names>Jean-Jacques Orban</given-names>
              </name>
              <name>
                <surname>Parsons</surname>
                <given-names>Sam</given-names>
              </name>
              <name>
                <surname>Pfuhl</surname>
                <given-names>Gerit</given-names>
              </name>
              <name>
                <surname>Quinn</surname>
                <given-names>Kimberly A.</given-names>
              </name>
              <name>
                <surname>Sakon</surname>
                <given-names>John J.</given-names>
              </name>
              <name>
                <surname>Saribay</surname>
                <given-names>S. Adil</given-names>
              </name>
              <name>
                <surname>Schneider</surname>
                <given-names>Iris K.</given-names>
              </name>
              <name>
                <surname>Selvaraju</surname>
                <given-names>Manojkumar</given-names>
              </name>
              <name>
                <surname>Sjoerds</surname>
                <given-names>Zsuzsika</given-names>
              </name>
              <name>
                <surname>Smith</surname>
                <given-names>Samuel G.</given-names>
              </name>
              <name>
                <surname>Smits</surname>
                <given-names>Tim</given-names>
              </name>
              <name>
                <surname>Spies</surname>
                <given-names>Jeffrey R.</given-names>
              </name>
              <name>
                <surname>Sreekumar</surname>
                <given-names>Vishnu</given-names>
              </name>
              <name>
                <surname>Steltenpohl</surname>
                <given-names>Crystal N.</given-names>
              </name>
              <name>
                <surname>Stenhouse</surname>
                <given-names>Neil</given-names>
              </name>
              <name>
                <surname>Świątkowski</surname>
                <given-names>Wojciech</given-names>
              </name>
              <name>
                <surname>Vadillo</surname>
                <given-names>Miguel A.</given-names>
              </name>
              <name>
                <surname>Van Assen</surname>
                <given-names>Marcel A. L. M.</given-names>
              </name>
              <name>
                <surname>Williams</surname>
                <given-names>Matt N.</given-names>
              </name>
              <name>
                <surname>Williams</surname>
                <given-names>Samantha E.</given-names>
              </name>
              <name>
                <surname>Williams</surname>
                <given-names>Donald R.</given-names>
              </name>
              <name>
                <surname>Yarkoni</surname>
                <given-names>Tal</given-names>
              </name>
              <name>
                <surname>Ziano</surname>
                <given-names>Ignazio</given-names>
              </name>
              <name>
                <surname>Zwaan</surname>
                <given-names>Rolf A.</given-names>
              </name>
            </person-group>
            <article-title>Justify your alpha</article-title>
            <source>Nature Human Behaviour</source>
            <year iso-8601-date="2018-03">2018</year>
            <month>03</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2022-03-17">2022</year>
              <month>03</month>
              <day>17</day>
            </date-in-citation>
            <volume>2</volume>
            <issue>3</issue>
            <issn>2397-3374</issn>
            <pub-id pub-id-type="doi">10.1038/s41562-018-0311-x</pub-id>
            <fpage>168</fpage>
            <lpage>171</lpage>
          </element-citation>
        </ref>
        <ref id="ref-lakensSampleSizeJustification2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lakens</surname>
                <given-names>Daniël</given-names>
              </name>
            </person-group>
            <article-title>Sample Size Justification</article-title>
            <source>Collabra: Psychology</source>
            <year iso-8601-date="2022-03">2022</year>
            <month>03</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-04-24">2023</year>
              <month>04</month>
              <day>24</day>
            </date-in-citation>
            <volume>8</volume>
            <issue>1</issue>
            <issn>2474-7394</issn>
            <pub-id pub-id-type="doi">10.1525/collabra.33267</pub-id>
            <fpage>33267</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-lanePowerStrugglesEstimating2018-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lane</surname>
                <given-names>Sean P.</given-names>
              </name>
              <name>
                <surname>Hennes</surname>
                <given-names>Erin P.</given-names>
              </name>
            </person-group>
            <article-title>Power struggles: Estimating sample size for multilevel relationships research</article-title>
            <source>Journal of Social and Personal Relationships</source>
            <year iso-8601-date="2018-01">2018</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-08">2023</year>
              <month>08</month>
              <day>08</day>
            </date-in-citation>
            <volume>35</volume>
            <issue>1</issue>
            <issn>0265-4075, 1460-3608</issn>
            <pub-id pub-id-type="doi">10.1177/0265407517710342</pub-id>
            <fpage>7</fpage>
            <lpage>31</lpage>
          </element-citation>
        </ref>
        <ref id="ref-littleStatisticalAnalysisMissing2014-nb-article">
          <element-citation publication-type="book">
            <person-group person-group-type="author">
              <name>
                <surname>Little</surname>
                <given-names>Roderick J. A.</given-names>
              </name>
              <name>
                <surname>Rubin</surname>
                <given-names>Donald B.</given-names>
              </name>
            </person-group>
            <source>Statistical Analysis with Missing Data</source>
            <publisher-name>Wiley</publisher-name>
            <publisher-loc>Somerset</publisher-loc>
            <year iso-8601-date="2014">2014</year>
            <edition>2nd ed</edition>
            <isbn>978-1-118-62588-0</isbn>
          </element-citation>
        </ref>
        <ref id="ref-lundbergWhatYourEstimand2021-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Lundberg</surname>
                <given-names>Ian</given-names>
              </name>
              <name>
                <surname>Johnson</surname>
                <given-names>Rebecca</given-names>
              </name>
              <name>
                <surname>Stewart</surname>
                <given-names>Brandon M.</given-names>
              </name>
            </person-group>
            <article-title>What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory</article-title>
            <source>American Sociological Review</source>
            <year iso-8601-date="2021-06">2021</year>
            <month>06</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-03-13">2024</year>
              <month>03</month>
              <day>13</day>
            </date-in-citation>
            <volume>86</volume>
            <issue>3</issue>
            <issn>0003-1224, 1939-8271</issn>
            <pub-id pub-id-type="doi">10.1177/00031224211004187</pub-id>
            <fpage>532</fpage>
            <lpage>565</lpage>
          </element-citation>
        </ref>
        <ref id="ref-maxwellSampleSizePlanning2008-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Maxwell</surname>
                <given-names>Scott E.</given-names>
              </name>
              <name>
                <surname>Kelley</surname>
                <given-names>Ken</given-names>
              </name>
              <name>
                <surname>Rausch</surname>
                <given-names>Joseph R.</given-names>
              </name>
            </person-group>
            <article-title>Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation</article-title>
            <source>Annual Review of Psychology</source>
            <year iso-8601-date="2008-01">2008</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-08">2023</year>
              <month>08</month>
              <day>08</day>
            </date-in-citation>
            <volume>59</volume>
            <issue>1</issue>
            <issn>0066-4308, 1545-2085</issn>
            <pub-id pub-id-type="doi">10.1146/annurev.psych.59.103006.093735</pub-id>
            <fpage>537</fpage>
            <lpage>563</lpage>
          </element-citation>
        </ref>
        <ref id="ref-mcelreathStatisticalRethinkingBayesian2020-nb-article">
          <element-citation publication-type="book">
            <person-group person-group-type="author">
              <name>
                <surname>McElreath</surname>
                <given-names>Richard</given-names>
              </name>
            </person-group>
            <source>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</source>
            <publisher-name>Chapman and Hall/CRC</publisher-name>
            <year iso-8601-date="2020-03">2020</year>
            <month>03</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-04">2024</year>
              <month>06</month>
              <day>04</day>
            </date-in-citation>
            <edition>2</edition>
            <isbn>978-0-429-02960-8</isbn>
            <pub-id pub-id-type="doi">10.1201/9780429029608</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-murayamaSummarystatisticsbasedPowerAnalysis2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Murayama</surname>
                <given-names>Kou</given-names>
              </name>
              <name>
                <surname>Usami</surname>
                <given-names>Satoshi</given-names>
              </name>
              <name>
                <surname>Sakaki</surname>
                <given-names>Michiko</given-names>
              </name>
            </person-group>
            <article-title>Summary-statistics-based power analysis: A new and practical method to determine sample size for mixed-effects modeling.</article-title>
            <source>Psychological Methods</source>
            <year iso-8601-date="2022-01">2022</year>
            <month>01</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-08-07">2023</year>
              <month>08</month>
              <day>07</day>
            </date-in-citation>
            <issn>1939-1463, 1082-989X</issn>
            <pub-id pub-id-type="doi">10.1037/met0000330</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-preacherComputationalToolsProbing2006-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Preacher</surname>
                <given-names>Kristopher J.</given-names>
              </name>
              <name>
                <surname>Curran</surname>
                <given-names>Patrick J.</given-names>
              </name>
              <name>
                <surname>Bauer</surname>
                <given-names>Daniel J.</given-names>
              </name>
            </person-group>
            <article-title>Computational Tools for Probing Interactions in Multiple Linear Regression, Multilevel Modeling, and Latent Curve Analysis</article-title>
            <source>Journal of Educational and Behavioral Statistics</source>
            <year iso-8601-date="2006-12">2006</year>
            <month>12</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-05">2024</year>
              <month>06</month>
              <day>05</day>
            </date-in-citation>
            <volume>31</volume>
            <issue>4</issue>
            <issn>1076-9986, 1935-1054</issn>
            <pub-id pub-id-type="doi">10.3102/10769986031004437</pub-id>
            <fpage>437</fpage>
            <lpage>448</lpage>
          </element-citation>
        </ref>
        <ref id="ref-riesthuisSimulationBasedPowerAnalyses2024-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Riesthuis</surname>
                <given-names>Paul</given-names>
              </name>
            </person-group>
            <article-title>Simulation-Based Power Analyses for the Smallest Effect Size of Interest: A Confidence-Interval Approach for Minimum-Effect and Equivalence Testing</article-title>
            <source>Advances in Methods and Practices in Psychological Science</source>
            <publisher-name>SAGE Publications Inc</publisher-name>
            <year iso-8601-date="2024-04">2024</year>
            <month>04</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-04-23">2024</year>
              <month>04</month>
              <day>23</day>
            </date-in-citation>
            <volume>7</volume>
            <issue>2</issue>
            <issn>2515-2459</issn>
            <pub-id pub-id-type="doi">10.1177/25152459241240722</pub-id>
            <fpage>25152459241240722</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-schadHowCapitalizePriori2020-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Schad</surname>
                <given-names>Daniel J.</given-names>
              </name>
              <name>
                <surname>Vasishth</surname>
                <given-names>Shravan</given-names>
              </name>
              <name>
                <surname>Hohenstein</surname>
                <given-names>Sven</given-names>
              </name>
              <name>
                <surname>Kliegl</surname>
                <given-names>Reinhold</given-names>
              </name>
            </person-group>
            <article-title>How to capitalize on a priori contrasts in linear (mixed) models: A tutorial</article-title>
            <source>Journal of Memory and Language</source>
            <year iso-8601-date="2020-02">2020</year>
            <month>02</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-05">2024</year>
              <month>06</month>
              <day>05</day>
            </date-in-citation>
            <volume>110</volume>
            <issn>0749596X</issn>
            <pub-id pub-id-type="doi">10.1016/j.jml.2019.104038</pub-id>
            <fpage>104038</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-uyguntuncEpistemicPragmaticFunction2023-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Uygun Tunç</surname>
                <given-names>Duygu</given-names>
              </name>
              <name>
                <surname>Tunç</surname>
                <given-names>Mehmet Necip</given-names>
              </name>
              <name>
                <surname>Lakens</surname>
                <given-names>Daniël</given-names>
              </name>
            </person-group>
            <article-title>The epistemic and pragmatic function of dichotomous claims based on statistical hypothesis tests</article-title>
            <source>Theory &amp; Psychology</source>
            <year iso-8601-date="2023-06">2023</year>
            <month>06</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-06-04">2024</year>
              <month>06</month>
              <day>04</day>
            </date-in-citation>
            <volume>33</volume>
            <issue>3</issue>
            <issn>0959-3543, 1461-7447</issn>
            <pub-id pub-id-type="doi">10.1177/09593543231160112</pub-id>
            <fpage>403</fpage>
            <lpage>423</lpage>
          </element-citation>
        </ref>
        <ref id="ref-westfallStatisticalPowerOptimal2014-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Westfall</surname>
                <given-names>Jacob</given-names>
              </name>
              <name>
                <surname>Kenny</surname>
                <given-names>David A.</given-names>
              </name>
              <name>
                <surname>Judd</surname>
                <given-names>Charles M.</given-names>
              </name>
            </person-group>
            <article-title>Statistical power and optimal design in experiments in which samples of participants respond to samples of stimuli</article-title>
            <source>Journal of Experimental Psychology: General</source>
            <publisher-name>American Psychological Association</publisher-name>
            <publisher-loc>US</publisher-loc>
            <year iso-8601-date="2014">2014</year>
            <volume>143</volume>
            <issn>1939-2222</issn>
            <pub-id pub-id-type="doi">10.1037/xge0000014</pub-id>
            <fpage>2020</fpage>
            <lpage>2045</lpage>
          </element-citation>
        </ref>
        <ref id="ref-wickhamDataScienceImport2023-nb-article">
          <element-citation publication-type="book">
            <person-group person-group-type="author">
              <name>
                <surname>Wickham</surname>
                <given-names>Hadley</given-names>
              </name>
              <name>
                <surname>Çetinkaya-Rundel</surname>
                <given-names>Mine</given-names>
              </name>
              <name>
                <surname>Grolemund</surname>
                <given-names>Garrett</given-names>
              </name>
            </person-group>
            <source>R for data science: Import, tidy, transform, visualize, and model data</source>
            <publisher-name>O’Reilly</publisher-name>
            <publisher-loc>Beijing Boston Farnham Sebastopol Tokyo</publisher-loc>
            <year iso-8601-date="2023">2023</year>
            <edition>2nd edition</edition>
            <isbn>978-1-4920-9740-2</isbn>
          </element-citation>
        </ref>
        <ref id="ref-wickhamWelcomeTidyverse2019-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Wickham</surname>
                <given-names>Hadley</given-names>
              </name>
              <name>
                <surname>Averick</surname>
                <given-names>Mara</given-names>
              </name>
              <name>
                <surname>Bryan</surname>
                <given-names>Jennifer</given-names>
              </name>
              <name>
                <surname>Chang</surname>
                <given-names>Winston</given-names>
              </name>
              <name>
                <surname>McGowan</surname>
                <given-names>Lucy</given-names>
              </name>
              <name>
                <surname>François</surname>
                <given-names>Romain</given-names>
              </name>
              <name>
                <surname>Grolemund</surname>
                <given-names>Garrett</given-names>
              </name>
              <name>
                <surname>Hayes</surname>
                <given-names>Alex</given-names>
              </name>
              <name>
                <surname>Henry</surname>
                <given-names>Lionel</given-names>
              </name>
              <name>
                <surname>Hester</surname>
                <given-names>Jim</given-names>
              </name>
              <name>
                <surname>Kuhn</surname>
                <given-names>Max</given-names>
              </name>
              <name>
                <surname>Pedersen</surname>
                <given-names>Thomas</given-names>
              </name>
              <name>
                <surname>Miller</surname>
                <given-names>Evan</given-names>
              </name>
              <name>
                <surname>Bache</surname>
                <given-names>Stephan</given-names>
              </name>
              <name>
                <surname>Müller</surname>
                <given-names>Kirill</given-names>
              </name>
              <name>
                <surname>Ooms</surname>
                <given-names>Jeroen</given-names>
              </name>
              <name>
                <surname>Robinson</surname>
                <given-names>David</given-names>
              </name>
              <name>
                <surname>Seidel</surname>
                <given-names>Dana</given-names>
              </name>
              <name>
                <surname>Spinu</surname>
                <given-names>Vitalie</given-names>
              </name>
              <name>
                <surname>Takahashi</surname>
                <given-names>Kohske</given-names>
              </name>
              <name>
                <surname>Vaughan</surname>
                <given-names>Davis</given-names>
              </name>
              <name>
                <surname>Wilke</surname>
                <given-names>Claus</given-names>
              </name>
              <name>
                <surname>Woo</surname>
                <given-names>Kara</given-names>
              </name>
              <name>
                <surname>Yutani</surname>
                <given-names>Hiroaki</given-names>
              </name>
            </person-group>
            <article-title>Welcome to the Tidyverse</article-title>
            <source>Journal of Open Source Software</source>
            <year iso-8601-date="2019-11">2019</year>
            <month>11</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2024-05-21">2024</year>
              <month>05</month>
              <day>21</day>
            </date-in-citation>
            <volume>4</volume>
            <issue>43</issue>
            <issn>2475-9066</issn>
            <pub-id pub-id-type="doi">10.21105/joss.01686</pub-id>
            <fpage>1686</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-yarkoniGeneralizabilityCrisis2022-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Yarkoni</surname>
                <given-names>Tal</given-names>
              </name>
            </person-group>
            <article-title>The generalizability crisis</article-title>
            <source>Behavioral and Brain Sciences</source>
            <year iso-8601-date="2022">2022</year>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2022-11-30">2022</year>
              <month>11</month>
              <day>30</day>
            </date-in-citation>
            <volume>45</volume>
            <issn>0140-525X, 1469-1825</issn>
            <pub-id pub-id-type="doi">10.1017/S0140525X20001685</pub-id>
            <fpage>e1</fpage>
            <lpage/>
          </element-citation>
        </ref>
        <ref id="ref-zimmerSampleSizePlanning2022-nb-article">
          <element-citation>
            <person-group person-group-type="author">
              <name>
                <surname>Zimmer</surname>
                <given-names>Felix</given-names>
              </name>
              <name>
                <surname>Henninger</surname>
                <given-names>Mirka</given-names>
              </name>
              <name>
                <surname>Debelak</surname>
                <given-names>Rudolf</given-names>
              </name>
            </person-group>
            <article-title>Sample Size Planning for Complex Study Designs: A Tutorial for the mlpwr Package</article-title>
            <publisher-name>PsyArXiv</publisher-name>
            <year iso-8601-date="2022-10">2022</year>
            <month>10</month>
            <date-in-citation content-type="access-date">
              <year iso-8601-date="2023-04-24">2023</year>
              <month>04</month>
              <day>24</day>
            </date-in-citation>
            <pub-id pub-id-type="doi">10.31234/osf.io/r9w6t</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-R-faux-nb-article">
          <element-citation publication-type="book">
            <person-group person-group-type="author">
              <name>
                <surname>DeBruine</surname>
                <given-names>Lisa</given-names>
              </name>
            </person-group>
            <source>Faux: Simulation for factorial designs</source>
            <publisher-name>Zenodo</publisher-name>
            <year iso-8601-date="2023">2023</year>
            <uri>https://debruine.github.io/faux/</uri>
            <pub-id pub-id-type="doi">10.5281/zenodo.2669586</pub-id>
          </element-citation>
        </ref>
        <ref id="ref-R-furrr-nb-article">
          <element-citation publication-type="book">
            <person-group person-group-type="author">
              <name>
                <surname>Vaughan</surname>
                <given-names>Davis</given-names>
              </name>
              <name>
                <surname>Dancho</surname>
                <given-names>Matt</given-names>
              </name>
            </person-group>
            <source>Furrr: Apply mapping functions in parallel using futures</source>
            <year iso-8601-date="2022">2022</year>
            <uri>https://github.com/DavisVaughan/furrr</uri>
          </element-citation>
        </ref>
        <ref id="ref-R-RJ-2021-048-nb-article">
          <element-citation publication-type="article-journal">
            <person-group person-group-type="author">
              <name>
                <surname>Bengtsson</surname>
                <given-names>Henrik</given-names>
              </name>
            </person-group>
            <article-title>A unifying framework for parallel and distributed processing in r using futures</article-title>
            <source>The R Journal</source>
            <year iso-8601-date="2021">2021</year>
            <volume>13</volume>
            <issue>2</issue>
            <uri>https://doi.org/10.32614/RJ-2021-048</uri>
            <pub-id pub-id-type="doi">10.32614/RJ-2021-048</pub-id>
            <fpage>208</fpage>
            <lpage>227</lpage>
          </element-citation>
        </ref>
        <ref id="ref-R-marginaleffects-nb-article">
          <element-citation publication-type="book">
            <person-group person-group-type="author">
              <name>
                <surname>Arel-Bundock</surname>
                <given-names>Vincent</given-names>
              </name>
            </person-group>
            <source>Marginaleffects: Predictions, comparisons, slopes, marginal means, and hypothesis tests</source>
            <year iso-8601-date="2024">2024</year>
            <uri>https://marginaleffects.com/</uri>
          </element-citation>
        </ref>
      </ref-list>
      <fn-group>
        <fn id="fn1-nb-article">
          <label>1</label>
          <p>Note that a different estimand would be the
    so-called average treatment effect (ATE). For the ATE, the
    probability contrast is defined for each combination of expert and
    scan, and then these contrasts are averaged across all experts and
    scans from the target population
    (<xref alt="Lundberg et al., 2021" rid="ref-lundbergWhatYourEstimand2021-nb-article" ref-type="bibr">Lundberg
    et al., 2021</xref>).</p>
        </fn>
        <fn id="fn2-nb-article">
          <label>2</label>
          <p>The faux package
    (<xref alt="DeBruine, 2023" rid="ref-R-faux-nb-article" ref-type="bibr">DeBruine,
    2023</xref>) contains useful functions when simulating factorial
    designs, including random effects.</p>
        </fn>
        <fn id="fn3-nb-article">
          <label>3</label>
          <p>For Bayesian GLMMs, the brms R package is
    currently the most prominent option
    (<xref alt="Bürkner, 2017" rid="ref-burknerBrmsPackageBayesian2017-nb-article" ref-type="bibr">Bürkner,
    2017</xref>).</p>
        </fn>
        <fn id="fn4-nb-article">
          <label>4</label>
          <p>This code was inspired by the “Mixed Design
    Simulation” vignette of the faux package at
    <ext-link ext-link-type="uri" xlink:href="https://debruine.github.io/faux/articles/sim_mixed.html">https://debruine.github.io/faux/articles/sim_mixed.html</ext-link>.</p>
        </fn>
      </fn-group>
    </back>
  </sub-article>
  <sub-article article-type="notebook" id="nb-2-nb-1">
    <front-stub>
      <title-group>
        <article-title>R code from PRACTICE sections</article-title>
      </title-group>
    </front-stub>
    <body>
      <boxed-text>
        <disp-quote>
          <p>
            <bold>Note</bold>
          </p>
          <p>This Notebook contains only the R code from the PRACTICE sections
    of the manuscript. The number of samples and repetitions for all
    simulations have been greatly reduced to ensure that the code runs
    quickly and with limited computational resources.</p>
        </disp-quote>
      </boxed-text>
      <sec id="simulate-the-data-generating-process-nb-1">
        <title>Simulate the data generating process</title>
        <sec specific-use="notebook-content">
          <code language="r script">simulate &lt;- function(n_subjects = 100, n_items = 50,
  b_0 = 0.847, b_e = 1.350, b_a = -1.253, b_c = 2.603,
  b_ea = 0.790, b_ec = -1.393,
  sd_u0s = 0.5, sd_u0i = 0.5, ...){
  require(dplyr)
  require(faux)
  # simulate design
  dat &lt;- add_random(subject = n_subjects, item = n_items) |&gt;
    add_between("subject", expert = c(1, 0), .prob = c(0.25, 0.75)) |&gt;
    mutate(advice_present = rbinom(n(), 1, prob = 2/3)) |&gt;
    mutate(advice_correct = if_else(advice_present == 1L, 
                                    rbinom(n(), 1L, prob = 0.8), 0L)) |&gt;
    # add random effects
    add_ranef("subject", u0s = sd_u0s) |&gt;
    add_ranef("item", u0i = sd_u0i) |&gt;
    # compute dependent variable
    mutate(linpred = b_0 + u0i + u0s +
        b_e * expert + b_a * advice_present + b_c * advice_correct +
        b_ea * expert * advice_present + b_ec * expert * advice_correct) |&gt;
    mutate(y_prob = plogis(linpred)) |&gt;
    mutate(y_bin = rbinom(n = n(), size = 1, prob = y_prob))
  dat
}
  </code>
        </sec>
      </sec>
      <sec id="specify-the-population-parameters-nb-1">
        <title>Specify the population parameters</title>
        <sec specific-use="notebook-content">
          <code language="r script">b_0 &lt;- qlogis(0.7)
b_e &lt;- qlogis(0.9) - b_0
b_a &lt;- qlogis(0.4) - b_0
b_ea &lt;- qlogis(0.85) - b_0 - b_e - b_a
b_c &lt;- qlogis(0.9) - b_0 - b_a
b_ec &lt;- qlogis(0.95) - b_0 - b_e - b_a - b_c - b_ea
c(b_0 = b_0, b_e = b_e, b_a = b_a, b_c = b_c, b_ea = b_ea, b_ec = b_ec)
  </code>
        </sec>
        <sec specific-use="notebook-content">
          <code language="r script">plogis(b_0 + b_e + b_a + b_c + b_ea + b_ec)
  </code>
        </sec>
        <sec id="insightful-descriptive-statistics-nb-1">
          <title>Insightful descriptive statistics</title>
          <sec specific-use="notebook-content">
            <code language="r script">library(tidyverse)
set.seed(1)
dat &lt;- simulate(n_subjects = 500, n_items = 500,
  sd_u0s = 0.5, sd_u0i = 0.5)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
 "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
 "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
 "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  group_by(condition) |&gt;
  summarize(relative_frequency = sum(y_bin) / n())
    </code>
          </sec>
        </sec>
        <sec id="insightful-model-based-quantities-nb-1">
          <title>Insightful model based quantities</title>
          <sec id="cell-fig-margdist1-nb-1" specific-use="notebook-content">
            <code language="r script">
library(ggdist)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
 "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
 "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
 "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))
    </code>
          </sec>
          <sec id="cell-fig-margdist2-nb-1" specific-use="notebook-content">
            <code language="r script">set.seed(1)
dat &lt;- simulate(n_subjects = 500, n_items = 500, sd_u0i = 0.01)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
    "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
    "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
    "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">set.seed(1)
dat &lt;- simulate(n_subjects = 500, n_items = 500, sd_u0s = 0.01)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
    "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
    "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
    "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))
    </code>
          </sec>
          <sec id="cell-fig-margdist3-nb-1" specific-use="notebook-content">
            <code language="r script">set.seed(1)
dat &lt;- simulate(n_subjects = 500, n_items = 500, sd_u0s = 3, sd_u0i = 3)
dat |&gt; 
  mutate(condition = fct_cross(
    factor(expert), factor(advice_present), factor(advice_correct))) |&gt;
  mutate(condition = fct_recode(condition,
    "no expert, no advice" = "0:0:0", "expert, no advice" = "1:0:0", 
    "no expert, wrong advice" = "0:1:0", "expert, wrong advice" = "1:1:0",
    "no expert, correct advice" = "0:1:1", "expert, correct advice" = "1:1:1")) |&gt; 
  ggplot(aes(x = y_prob, y = condition)) +
  stat_histinterval(point_interval = "mean_qi", slab_color = "gray45",
    breaks = "Sturges") +
  scale_x_continuous(breaks = seq(0, 1, 0.1), limits = c(0, 1))
    </code>
          </sec>
        </sec>
      </sec>
      <sec id="estimate-the-statistical-model-nb-1">
        <title>Estimate the statistical model</title>
        <sec specific-use="notebook-content">
          <code language="r script">library(tidyverse)
library(lme4)
set.seed(1)
dat &lt;- simulate(n_subjects = 100, n_items = 50)
f &lt;- y_bin ~ 1 + expert + advice_present + advice_correct + 
  expert:advice_present + expert:advice_correct +
  (1|subject) + (1|item)
fit &lt;- glmer(f, data = dat, family = "binomial")
summary(fit)
  </code>
        </sec>
      </sec>
      <sec id="compute-the-estimate-nb-1">
        <title>Compute the estimate</title>
        <sec specific-use="notebook-content">
          <code language="r script">grid1 &lt;- data.frame(advice_present = c(1, 0), advice_correct = c(1, 0), 
  expert = c(1, 1))
grid1
pred &lt;- predict(fit, newdata = grid1, type = "response", re.form = NA)
pred
pred[1] - pred[2]
  </code>
        </sec>
        <sec specific-use="notebook-content">
          <code language="r script">grid2 &lt;- expand_grid(advice_present = 0:1, 
  advice_correct = 0:1, expert = 0:1)
grid2
preds &lt;- predictions(fit, newdata = grid2, 
  type = "response", re.form = NA)
as.data.frame(preds)[,c(2,7:11)]
  </code>
        </sec>
        <sec specific-use="notebook-content">
          <code language="r script">contrasts &lt;- preds |&gt; 
  hypotheses(hypothesis = c(
    "b8 = b2",  # (correct advice, expert) - (no advice, expert)
    "b2 = b6",  # (no advice, expert) - (wrong advice, expert) 
    "b7 = b1",  # (correct advice, no expert) - (no advice, no expert)
    "b1 = b5"), # (no advice, no expert) - (wrong advice, no expert)
    equivalence = c(0, 0))
contrasts
  </code>
        </sec>
      </sec>
      <sec id="perform-repeated-simulations-nb-1">
        <title>Perform repeated simulations</title>
        <sec specific-use="notebook-content">
          <code language="r script">sim_and_analyse &lt;- function(
  formula_chr = "y_bin ~ 1 + expert + advice_present + advice_correct + 
    expert:advice_present + expert:advice_correct + (1|subject) + (1|item)",
  contrasts = c("b8 = b2", "b2 = b6", "b7 = b1", "b1 = b5"), ...){
  require(lme4)
  require(marginaleffects)
  require(tidyr)
  # simulate data
  dat &lt;- simulate(...)
  # fit model
  model &lt;- glmer(as.formula(formula_chr), data = dat, family = "binomial")
  # compute contrasts
  contr_df &lt;- expand_grid(advice_present = 0:1, advice_correct = 0:1,
    expert = 0:1)
  predictions(model, newdata = contr_df, type = "response", re.form = NA) |&gt;
    hypotheses(hypothesis = contrasts, equivalence = c(0, 0)) |&gt;
    data.frame()
}
  </code>
        </sec>
        <sec specific-use="notebook-content">
          <code language="r script">library(future)
plan("multisession", workers = 4)
set.seed(2)
  </code>
        </sec>
        <sec specific-use="notebook-content">
          <code language="r script">library(furrr)
sim_result &lt;- crossing(
  rep = 1:5,
  n_subjects = c(100, 150, 200, 250),
  n_items = c(10, 30, 50, 70)
) |&gt;
  mutate(res = future_pmap(., sim_and_analyse, 
    .options = furrr_options(seed = TRUE))) |&gt;
  unnest(col = res)
  </code>
        </sec>
        <sec id="power-results-nb-1">
          <title>Power results</title>
          <sec id="cell-fig-finalpwr-nb-1" specific-use="notebook-content">
            <code language="r script">library(binom)
alpha &lt;- 0.05
power &lt;- sim_result |&gt;
  pivot_wider(names_from = term, names_sep = "_", 
    values_from = estimate:p.value.equiv) |&gt;
  group_by(n_subjects, n_items) |&gt; 
  summarise(
    power = mean(`p.value.noninf_b1=b5` &lt; alpha &amp; 
        `p.value.noninf_b8=b2` &lt; alpha &amp; `p.value.noninf_b2=b6` &lt; alpha &amp; 
        `p.value.noninf_b7=b1` &lt; alpha), 
    n_sig = sum(`p.value.noninf_b1=b5` &lt; alpha &amp; 
        `p.value.noninf_b8=b2` &lt; alpha &amp; `p.value.noninf_b2=b6` &lt; alpha &amp; 
        `p.value.noninf_b7=b1` &lt; alpha),
    n = n(),
    ci.lwr = binom.confint(n_sig, n, method = "wilson")$lower,
    ci.upr = binom.confint(n_sig, n, method = "wilson")$upper, 
    .groups = "drop")
power |&gt;
  mutate(across(c(n_subjects, n_items), factor)) |&gt;
  ggplot(aes(n_subjects, n_items, fill = power)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.2f \n [%.2f; %.2f]", 
                                power, ci.lwr, ci.upr)), 
    color = "white", size = 4) +
  scale_fill_viridis_c(limits = c(0, 1)) +
  xlab("number of subjects") + ylab("number of items")
    </code>
          </sec>
        </sec>
        <sec id="precision-results-nb-1">
          <title>Precision results</title>
          <sec id="cell-fig-finalprecision-nb-1" specific-use="notebook-content">
            <code language="r script">precision &lt;- sim_result |&gt;
  pivot_wider(names_from = term, names_sep = "_", 
    values_from = estimate:p.value.equiv) |&gt;
  group_by(n_subjects, n_items) |&gt;
  mutate(width = `conf.high_b8=b2` - `conf.low_b8=b2`) |&gt;
  summarise(precision = mean(width),
    ci.lwr = t.test(width)$conf.int[1],
    ci.upr = t.test(width)$conf.int[2], 
    .groups = "drop")
precision |&gt;
  mutate(across(c(n_subjects, n_items), factor)) |&gt;
  ggplot(aes(n_subjects, n_items, fill = precision)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%.2f \n [%.2f; %.2f]", 
                                precision, ci.lwr, ci.upr)), 
    color = "white", size = 4) +
  scale_fill_viridis_c(limits = c(0, 0.3), direction = -1) +
  guides(fill = guide_legend(reverse=FALSE))
    </code>
          </sec>
        </sec>
      </sec>
    </body>
    <back>
</back>
  </sub-article>
  <sub-article article-type="notebook" id="nb-4-nb-2">
    <front-stub>
      <title-group>
        <article-title>Run the full simulation for the case study
example</article-title>
      </title-group>
    </front-stub>
    <body>
      <boxed-text>
        <disp-quote>
          <p>
            <bold>Note</bold>
          </p>
          <p>This Notebook was used to run the full simulation for the case
    study discussed in the manuscript. The simulation takes more than 1
    hour to run on a Mac Book Pro (13-inch, M1, 2020) with 16 GB
    memory.</p>
        </disp-quote>
      </boxed-text>
      <sec id="simulation-functions-nb-2">
        <title>Simulation functions</title>
        <sec specific-use="notebook-content">
          <code language="r script">simulate &lt;- function(n_subjects = 100, n_items = 50,
  b_0 = 0.847, b_e = 1.350, b_a = -1.253, b_c = 2.603,
  b_ea = 0.790, b_ec = -1.393,
  sd_u0s = 0.5, sd_u0i = 0.5, ...){
  require(dplyr)
  require(faux)
  # simulate design
  dat &lt;- add_random(subject = n_subjects, item = n_items) |&gt;
    add_between("subject", expert = c(1, 0), .prob = c(0.25, 0.75)) |&gt;
    mutate(advice_present = rbinom(n(), 1, prob = 2/3)) |&gt;
    mutate(advice_correct = if_else(advice_present == 1L, 
                                    rbinom(n(), 1L, prob = 0.8), 0L)) |&gt;
    # add random effects
    add_ranef("subject", u0s = sd_u0s) |&gt;
    add_ranef("item", u0i = sd_u0i) |&gt;
    # compute dependent variable
    mutate(linpred = b_0 + u0i + u0s +
        b_e * expert + b_a * advice_present + b_c * advice_correct +
        b_ea * expert * advice_present + b_ec * expert * advice_correct) |&gt;
    mutate(y_prob = plogis(linpred)) |&gt;
    mutate(y_bin = rbinom(n = n(), size = 1, prob = y_prob))
  dat
}
  </code>
        </sec>
        <sec specific-use="notebook-content">
          <code language="r script">sim_and_analyse &lt;- function(
  formula_chr = "y_bin ~ 1 + expert + advice_present + advice_correct + 
    expert:advice_present + expert:advice_correct + (1|subject) + (1|item)",
  contrasts = c("b8 = b2", "b2 = b6", "b7 = b1", "b1 = b5"), ...){
  require(lme4)
  require(marginaleffects)
  require(tidyr)
  # simulate data
  dat &lt;- simulate(...)
  # fit model
  model &lt;- glmer(as.formula(formula_chr), data = dat, family = "binomial")
  # compute contrasts
  contr_df &lt;- expand_grid(advice_present = 0:1, advice_correct = 0:1,
    expert = 0:1)
  predictions(model, newdata = contr_df, type = "response", re.form = NA) |&gt;
    hypotheses(hypothesis = contrasts, equivalence = c(0, 0)) |&gt;
    data.frame()
}
  </code>
        </sec>
      </sec>
      <sec id="run-simulation-nb-2">
        <title>Run simulation</title>
        <sec specific-use="notebook-content">
          <code language="r script">library(tidyverse)
library(future)
library(furrr)
  
plan("multisession", workers = 6)
set.seed(2)
  
sim_result &lt;- crossing(
  rep = 1:300,
  n_subjects = c(100, 150, 200, 250),
  n_items = c(10, 30, 50, 70)
) |&gt;
  mutate(res = future_pmap(., sim_and_analyse, 
    .options = furrr_options(seed = TRUE))) |&gt;
  unnest(col = res)
  </code>
        </sec>
      </sec>
      <sec id="save-results-file-to-be-used-in-the-manuscript-nb-2">
        <title>Save results file to be used in the manuscript</title>
        <sec specific-use="notebook-content">
          <code language="r script">saveRDS(sim_result, file = "results.rds")
  </code>
        </sec>
      </sec>
    </body>
    <back>
</back>
  </sub-article>
</article>
