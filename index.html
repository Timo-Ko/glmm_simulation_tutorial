<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Florian Pargent">
<meta name="author" content="Timo K. Koch">
<meta name="author" content="Anne-Kathrin Kleine">
<meta name="author" content="Eva Lermer">
<meta name="author" content="Susanne Gaube">
<meta name="dcterms.date" content="2024-07-01">
<meta name="keywords" content="tutorial, sample size planning, generalized linear mixed model, power analysis, precision, data simulation">

<title>A Tutorial on Tailored Simulation-Based Sample-Size Planning for Experimental Designs with Generalized Linear Mixed Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<link href="site_libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="site_libs/tabwid-1.1.3/tabwid.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="A Tutorial on Tailored Simulation-Based Sample-Size Planning for Experimental Designs with Generalized Linear Mixed Models">
<meta name="citation_abstract" content="When planning experimental research, determining an appropriate sample size and using suitable statistical models are crucial for robust and informative results. The recent replication crisis underlines the need for more rigorous statistical methodology and adequately powered designs. Generalized linear mixed models (GLMMs) offer a flexible statistical framework to analyze experimental data with complex (e.g., dependent and hierarchical) data structures. However, available methods and software for a priori sample size planning for GLMMs are often limited to specific designs. Tailored data simulation approaches offer a more flexible alternative. Based on a practical case study where we focus on a binomial GLMM with two random intercepts and discrete predictor variables, the current tutorial equips researchers with a step-by-step guide and corresponding code for conducting tailored a priori sample size planning with GLMMs. We not only focus on power analysis but also explain how to use the precision of parameter estimates to determine appropriate sample sizes. We conclude with an outlook on the increasing importance of simulation-based sample size planning.">
<meta name="citation_keywords" content="tutorial,sample size planning,generalized linear mixed model,power analysis,precision,data simulation">
<meta name="citation_author" content="Florian Pargent">
<meta name="citation_author" content="Timo K. Koch">
<meta name="citation_author" content="Anne-Kathrin Kleine">
<meta name="citation_author" content="Eva Lermer">
<meta name="citation_author" content="Susanne Gaube">
<meta name="citation_publication_date" content="2024">
<meta name="citation_cover_date" content="2024">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-07-01">
<meta name="citation_issue" content="4">
<meta name="citation_doi" content="10.1177/25152459241287132">
<meta name="citation_volume" content="7">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Advances in Methods and Practices in Psychological Science">
<meta name="citation_reference" content="citation_title=When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias;,citation_author=Casper Albers;,citation_author=Daniël Lakens;,citation_publication_date=2018-01;,citation_cover_date=2018-01;,citation_year=2018;,citation_doi=10.1016/j.jesp.2017.09.004;,citation_issn=00221031;,citation_volume=74;,citation_language=en-US;,citation_journal_title=Journal of Experimental Social Psychology;">
<meta name="citation_reference" content="citation_title=When power analyses based on pilot data are biased: Inaccurate effect size estimators and follow-up bias;,citation_author=Casper Albers;,citation_author=Daniël Lakens;,citation_publication_date=2018-01;,citation_cover_date=2018-01;,citation_year=2018;,citation_doi=10.1016/j.jesp.2017.09.004;,citation_issn=00221031;,citation_volume=74;,citation_language=en-US;,citation_journal_title=Journal of Experimental Social Psychology;">
<meta name="citation_reference" content="citation_title=Statistical power in two-level models: A tutorial based on Monte Carlo simulation.;,citation_author=Matthias G. Arend;,citation_author=Thomas Schäfer;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_issue=1;,citation_doi=10.1037/met0000195;,citation_issn=1939-1463, 1082-989X;,citation_volume=24;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=Tutorial: Power Analyses for Interaction Effects in Cross-Sectional Regressions;,citation_abstract=Interaction analyses (also termed “moderation” analyses or “moderated multiple regression”) are a form of linear regression analysis designed to test whether the association between two variables changes when conditioned on a third variable. It can be challenging to perform a power analysis for interactions with existing software, particularly when variables are correlated and continuous. Moreover, although power is affected by main effects, their correlation, and variable reliability, it can be unclear how to incorporate these effects into a power analysis. The R package InteractionPoweR and associated Shiny apps allow researchers with minimal or no programming experience to perform analytic and simulation-based power analyses for interactions. At minimum, these analyses require the Pearson’s correlation between variables and sample size, and additional parameters, including reliability and the number of discrete levels that a variable takes (e.g., binary or Likert scale), can optionally be specified. In this tutorial, we demonstrate how to perform power analyses using our package and give examples of how power can be affected by main effects, correlations between main effects, reliability, and variable distributions. We also include a brief discussion of how researchers may select an appropriate interaction effect size when performing a power analysis.;,citation_author=David A. A. Baranger;,citation_author=Megan C. Finsaas;,citation_author=Brandon L. Goldstein;,citation_author=Colin E. Vize;,citation_author=Donald R. Lynam;,citation_author=Thomas M. Olino;,citation_publication_date=2023-07;,citation_cover_date=2023-07;,citation_year=2023;,citation_issue=3;,citation_doi=10.1177/25152459231187531;,citation_issn=2515-2459;,citation_volume=6;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;,citation_publisher=SAGE Publications Inc;">
<meta name="citation_reference" content="citation_title=Fitting Linear Mixed-Effects Models Using &amp;amp;amp;lt;b&amp;gt;Lme4&amp;lt;/b&amp;gt;;,citation_author=Douglas Bates;,citation_author=Martin Mächler;,citation_author=Ben Bolker;,citation_author=Steve Walker;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=1;,citation_doi=10.18637/jss.v067.i01;,citation_issn=1548-7660;,citation_volume=67;,citation_language=en-US;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Redefine statistical significance;,citation_author=Daniel J. Benjamin;,citation_author=James O. Berger;,citation_author=Magnus Johannesson;,citation_author=Brian A. Nosek;,citation_author=E.-J. Wagenmakers;,citation_author=Richard Berk;,citation_author=Kenneth A. Bollen;,citation_author=Björn Brembs;,citation_author=Lawrence Brown;,citation_author=Colin Camerer;,citation_author=David Cesarini;,citation_author=Christopher D. Chambers;,citation_author=Merlise Clyde;,citation_author=Thomas D. Cook;,citation_author=Paul De Boeck;,citation_author=Zoltan Dienes;,citation_author=Anna Dreber;,citation_author=Kenny Easwaran;,citation_author=Charles Efferson;,citation_author=Ernst Fehr;,citation_author=Fiona Fidler;,citation_author=Andy P. Field;,citation_author=Malcolm Forster;,citation_author=Edward I. George;,citation_author=Richard Gonzalez;,citation_author=Steven Goodman;,citation_author=Edwin Green;,citation_author=Donald P. Green;,citation_author=Anthony G. Greenwald;,citation_author=Jarrod D. Hadfield;,citation_author=Larry V. Hedges;,citation_author=Leonhard Held;,citation_author=Teck Hua Ho;,citation_author=Herbert Hoijtink;,citation_author=Daniel J. Hruschka;,citation_author=Kosuke Imai;,citation_author=Guido Imbens;,citation_author=John P. A. Ioannidis;,citation_author=Minjeong Jeon;,citation_author=James Holland Jones;,citation_author=Michael Kirchler;,citation_author=David Laibson;,citation_author=John List;,citation_author=Roderick Little;,citation_author=Arthur Lupia;,citation_author=Edouard Machery;,citation_author=Scott E. Maxwell;,citation_author=Michael McCarthy;,citation_author=Don A. Moore;,citation_author=Stephen L. Morgan;,citation_author=Marcus Munafó;,citation_author=Shinichi Nakagawa;,citation_author=Brendan Nyhan;,citation_author=Timothy H. Parker;,citation_author=Luis Pericchi;,citation_author=Marco Perugini;,citation_author=Jeff Rouder;,citation_author=Judith Rousseau;,citation_author=Victoria Savalei;,citation_author=Felix D. Schönbrodt;,citation_author=Thomas Sellke;,citation_author=Betsy Sinclair;,citation_author=Dustin Tingley;,citation_author=Trisha Van Zandt;,citation_author=Simine Vazire;,citation_author=Duncan J. Watts;,citation_author=Christopher Winship;,citation_author=Robert L. Wolpert;,citation_author=Yu Xie;,citation_author=Cristobal Young;,citation_author=Jonathan Zinman;,citation_author=Valen E. Johnson;,citation_publication_date=2017-09;,citation_cover_date=2017-09;,citation_year=2017;,citation_issue=1;,citation_doi=10.1038/s41562-017-0189-z;,citation_issn=2397-3374;,citation_volume=2;,citation_language=en-US;,citation_journal_title=Nature Human Behaviour;">
<meta name="citation_reference" content="citation_title=Simulation-based prior knowledge elicitation for parametric Bayesian models;,citation_abstract=Abstract A central characteristic of Bayesian statistics is the ability to consistently incorporate prior knowledge into various modeling processes. In this paper, we focus on translating domain expert knowledge into corresponding prior distributions over model parameters, a process known as prior elicitation. Expert knowledge can manifest itself in diverse formats, including information about raw data, summary statistics, or model parameters. A major challenge for existing elicitation methods is how to effectively utilize all of these different formats in order to formulate prior distributions that align with the expert’s expectations, regardless of the model structure. To address these challenges, we develop a simulation-based elicitation method that can learn the hyperparameters of potentially any parametric prior distribution from a wide spectrum of expert knowledge using stochastic gradient descent. We validate the effectiveness and robustness of our elicitation method in four representative simulation studies covering linear models, generalized linear models, and hierarchical models. Our results support the claim that our method is largely independent of the underlying model structure and adaptable to various elicitation techniques, including quantile-based, moment-based, and histogram-based methods.;,citation_author=Florence Bockting;,citation_author=Stefan T. Radev;,citation_author=Paul-Christian Bürkner;,citation_publication_date=2024-07;,citation_cover_date=2024-07;,citation_year=2024;,citation_issue=1;,citation_doi=10.1038/s41598-024-68090-7;,citation_issn=2045-2322;,citation_volume=14;,citation_language=en-US;,citation_journal_title=Scientific Reports;">
<meta name="citation_reference" content="citation_title=Linear and generalized linear mixed models;,citation_abstract=Abstract Generalized linear mixed models (GLMMs) are a powerful class of statistical models that combine the characteristics of generalized linear models and mixed models (models with both fixed and random predictor variables). This chapter: reviews the conceptual and theoretical background of GLMMs, focusing on the definition and meaning of random effects; gives basic guidelines and syntax for setting up a mixed model; and discusses the theoretical and practical details of estimating parameters, diagnosing problems with a model, and making statistical inferences (finding confidence intervals, estimating p values, and doing model selection) for GLMMs.;,citation_author=Benjamin M. Bolker;,citation_editor=Gordon A. Fox;,citation_editor=Simoneta Negrete-Yankelevich;,citation_editor=Vinicio J. Sosa;,citation_publication_date=2015-01;,citation_cover_date=2015-01;,citation_year=2015;,citation_doi=10.1093/acprof:oso/9780199672547.003.0014;,citation_isbn=978-0-19-967255-4 978-0-19-967254-7 978-0-19-179648-7;,citation_language=en-US;,citation_inbook_title=Ecological Statistics;">
<meta name="citation_reference" content="citation_title=Linear mixed-effects models and the analysis of nonindependent data: A unified framework to analyze categorical and continuous independent variables that vary within-subjects and/or within-items.;,citation_abstract=In this article we address a number of important issues that arise in the analysis of nonindependent data. Such data are common in studies in which predictors vary within “units” (e.g., within-subjects, within-classrooms). Most researchers analyze categorical within-unit predictors with repeated-measures ANOVAs, but continuous within-unit predictors with linear mixed-effects models (LMEMs). We show that both types of predictor variables can be analyzed within the LMEM framework. We discuss designs with multiple sources of nonindependence, for example, studies in which the same subjects rate the same set of items or in which students nested in classrooms provide multiple answers. We provide clear guidelines about the types of random effects that should be included in the analysis of such designs. We also present a number of corrective steps that researchers can take when convergence fails in LMEM models with too many parameters. We end with a brief discussion on the trade-off between power and generalizability in designs with “within-unit” predictors.;,citation_author=Markus Brauer;,citation_author=John J. Curtin;,citation_publication_date=2018-09;,citation_cover_date=2018-09;,citation_year=2018;,citation_issue=3;,citation_doi=10.1037/met0000159;,citation_issn=1939-1463, 1082-989X;,citation_volume=23;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling;,citation_author=Mollie Brooks;,citation_author=Kasper Kristensen;,citation_author=van Benthem;,citation_author=Arni Magnusson;,citation_author=Casper Berg;,citation_author=Anders Nielsen;,citation_author=Hans Skaug;,citation_author=Martin Mächler;,citation_author=Benjamin Bolker;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=2;,citation_doi=10.32614/RJ-2017-066;,citation_issn=2073-4859;,citation_volume=9;,citation_language=en-US;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=An Introduction to Linear Mixed-Effects Modeling in R;,citation_abstract=This Tutorial serves as both an approachable theoretical introduction to mixed-effects modeling and a practical introduction to how to implement mixed-effects models in R. The intended audience is researchers who have some basic statistical knowledge, but little or no experience implementing mixed-effects models in R using their own data. In an attempt to increase the accessibility of this Tutorial, I deliberately avoid using mathematical terminology beyond what a student would learn in a standard graduate-level statistics course, but I reference articles and textbooks that provide more detail for interested readers. This Tutorial includes snippets of R code throughout; the data and R script used to build the models described in the text are available via OSF at https://osf.io/v6qag/, so readers can follow along if they wish. The goal of this practical introduction is to provide researchers with the tools they need to begin implementing mixed-effects models in their own research.;,citation_author=Violet A. Brown;,citation_publication_date=2021-01;,citation_cover_date=2021-01;,citation_year=2021;,citation_issue=1;,citation_doi=10.1177/2515245920960351;,citation_issn=2515-2459;,citation_volume=4;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;,citation_publisher=SAGE Publications Inc;">
<meta name="citation_reference" content="citation_title=Power Analysis and Effect Size in Mixed Effects Models: A Tutorial;,citation_author=Marc Brysbaert;,citation_author=Michaël Stevens;,citation_publication_date=2018-01;,citation_cover_date=2018-01;,citation_year=2018;,citation_issue=1;,citation_doi=10.5334/joc.10;,citation_issn=2514-4820;,citation_volume=1;,citation_language=en-US;,citation_journal_title=Journal of Cognition;">
<meta name="citation_reference" content="citation_title=Advanced Bayesian Multilevel Modeling with the R Package brms;,citation_author=Paul-Christian Bürkner;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_doi=10.32614/RJ-2018-017;,citation_issn=2073-4859;,citation_volume=10;,citation_language=en-US;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=Brms: An R Package for Bayesian Multilevel Models Using Stan;,citation_abstract=The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit - among others - linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.;,citation_author=Paul-Christian Bürkner;,citation_publication_date=2017-08;,citation_cover_date=2017-08;,citation_year=2017;,citation_doi=10.18637/jss.v080.i01;,citation_issn=1548-7660;,citation_volume=80;,citation_language=en-US;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Power failure: Why small sample size undermines the reliability of neuroscience;,citation_author=Katherine S. Button;,citation_author=John P. A. Ioannidis;,citation_author=Claire Mokrysz;,citation_author=Brian A. Nosek;,citation_author=Jonathan Flint;,citation_author=Emma S. J. Robinson;,citation_author=Marcus R. Munafò;,citation_publication_date=2013-05;,citation_cover_date=2013-05;,citation_year=2013;,citation_issue=5;,citation_doi=10.1038/nrn3475;,citation_issn=1471-003X, 1471-0048;,citation_volume=14;,citation_language=en-US;,citation_journal_title=Nature Reviews Neuroscience;">
<meta name="citation_reference" content="citation_title=Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015;,citation_author=Colin F. Camerer;,citation_author=Anna Dreber;,citation_author=Felix Holzmeister;,citation_author=Teck-Hua Ho;,citation_author=Jürgen Huber;,citation_author=Magnus Johannesson;,citation_author=Michael Kirchler;,citation_author=Gideon Nave;,citation_author=Brian A. Nosek;,citation_author=Thomas Pfeiffer;,citation_author=Adam Altmejd;,citation_author=Nick Buttrick;,citation_author=Taizan Chan;,citation_author=Yiling Chen;,citation_author=Eskil Forsell;,citation_author=Anup Gampa;,citation_author=Emma Heikensten;,citation_author=Lily Hummer;,citation_author=Taisuke Imai;,citation_author=Siri Isaksson;,citation_author=Dylan Manfredi;,citation_author=Julia Rose;,citation_author=Eric-Jan Wagenmakers;,citation_author=Hang Wu;,citation_publication_date=2018-08;,citation_cover_date=2018-08;,citation_year=2018;,citation_issue=9;,citation_doi=10.1038/s41562-018-0399-z;,citation_issn=2397-3374;,citation_volume=2;,citation_language=en-US;,citation_journal_title=Nature Human Behaviour;">
<meta name="citation_reference" content="citation_title=The past, present and future of Registered Reports;,citation_abstract=Registered Reports are a form of empirical publication in which study proposals are peer reviewed and pre-accepted before research is undertaken. By deciding which articles are published based on the question, theory and methods, Registered Reports offer a remedy for a range of reporting and publication biases. Here, we reflect on the history, progress and future prospects of the Registered Reports initiative and offer practical guidance for authors, reviewers and editors. We review early evidence that Registered Reports are working as intended, while at the same time acknowledging that they are not a universal solution for irreproducibility. We also consider how the policies and practices surrounding Registered Reports are changing, or must change in the future, to address limitations and adapt to new challenges. We conclude that Registered Reports are promoting reproducibility, transparency and self-correction across disciplines and may help reshape how society evaluates research and researchers.;,citation_author=Christopher D. Chambers;,citation_author=Loukia Tzavella;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=1;,citation_doi=10.1038/s41562-021-01193-7;,citation_issn=2397-3374;,citation_volume=6;,citation_language=en-US;,citation_journal_title=Nature Human Behaviour;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=Package “pwr”;,citation_author=Stephane Champely;,citation_author=Claus Ekstrom;,citation_author=Peter Dalgaard;,citation_author=Jeffrey Gill;,citation_author=Stephan Weibelzahl;,citation_author=Aditya Anandkumar;,citation_author=Clay Ford;,citation_author=Robert Volcic;,citation_author=Helios De Rosario;,citation_author=Maintainer Helios De Rosario;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=2;,citation_volume=1;,citation_journal_title=R package version;">
<meta name="citation_reference" content="citation_title=Is two-tailed testing for directional research hypotheses tests legitimate?;,citation_author=Hyun-Chul Cho;,citation_author=Shuzo Abe;,citation_publication_date=2013-09;,citation_cover_date=2013-09;,citation_year=2013;,citation_issue=9;,citation_doi=10.1016/j.jbusres.2012.02.023;,citation_issn=01482963;,citation_volume=66;,citation_language=en-US;,citation_journal_title=Journal of Business Research;">
<meta name="citation_reference" content="citation_title=Threats of a replication crisis in empirical computer science;,citation_abstract=Research replication only works if there is confidence built into the results.;,citation_author=Andy Cockburn;,citation_author=Pierre Dragicevic;,citation_author=Lonni Besançon;,citation_author=Carl Gutwin;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_issue=8;,citation_doi=10.1145/3360311;,citation_issn=0001-0782, 1557-7317;,citation_volume=63;,citation_language=en-US;,citation_journal_title=Communications of the ACM;">
<meta name="citation_reference" content="citation_title=A power primer.;,citation_author=Jacob Cohen;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=1;,citation_doi=10.1037/0033-2909.112.1.155;,citation_issn=1939-1455, 0033-2909;,citation_volume=112;,citation_language=en-US;,citation_journal_title=Psychological Bulletin;">
<meta name="citation_reference" content="citation_title=The New Statistics: Why and How;,citation_abstract=We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate data-analytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing (NHST), we need to shift from reliance on NHST to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for NHST, and is aimed at building a cumulative quantitative discipline.;,citation_author=Geoff Cumming;,citation_publication_date=2014-01;,citation_cover_date=2014-01;,citation_year=2014;,citation_issue=1;,citation_doi=10.1177/0956797613504966;,citation_issn=0956-7976, 1467-9280;,citation_volume=25;,citation_language=en-US;,citation_journal_title=Psychological Science;">
<meta name="citation_reference" content="citation_title=Faux: Simulation for Factorial Designs;,citation_abstract=Create datasets with factorial structure through simulation by specifying variable parameters.;,citation_author=Lisa DeBruine;,citation_publication_date=2023-02;,citation_cover_date=2023-02;,citation_year=2023;,citation_doi=10.5281/ZENODO.2669586;,citation_language=en-US;,citation_publisher=Zenodo;">
<meta name="citation_reference" content="citation_title=Faux: Simulation for Factorial Designs;,citation_abstract=Create datasets with factorial structure through simulation by specifying variable parameters.;,citation_author=Lisa DeBruine;,citation_publication_date=2023-02;,citation_cover_date=2023-02;,citation_year=2023;,citation_doi=10.5281/ZENODO.2669586;,citation_language=en-US;,citation_publisher=Zenodo;">
<meta name="citation_reference" content="citation_title=Understanding Mixed-Effects Models Through Data Simulation;,citation_abstract=Experimental designs that sample both subjects and stimuli from a larger population need to account for random effects of both subjects and stimuli using mixed-effects models. However, much of this research is analyzed using analysis of variance on aggregated responses because researchers are not confident specifying and interpreting mixed-effects models. This Tutorial explains how to simulate data with random-effects structure and analyze the data using linear mixed-effects regression (with the lme4 R package), with a focus on interpreting the output in light of the simulated parameters. Data simulation not only can enhance understanding of how these models work, but also enables researchers to perform power calculations for complex designs. All materials associated with this article can be accessed at https://osf.io/3cz2e/.;,citation_author=Lisa DeBruine;,citation_author=Dale J. Barr;,citation_publication_date=2021-01;,citation_cover_date=2021-01;,citation_year=2021;,citation_issue=1;,citation_doi=10.1177/2515245920965119;,citation_issn=2515-2459;,citation_volume=4;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;,citation_publisher=SAGE Publications Inc;">
<meta name="citation_reference" content="citation_title=A Causal Framework for Cross-Cultural Generalizability;,citation_abstract=Behavioral researchers increasingly recognize the need for more diverse samples that capture the breadth of human experience. Current attempts to establish generalizability across populations focus on threats to validity, constraints on generalization, and the accumulation of large, cross-cultural data sets. But for continued progress, we also require a framework that lets us determine which inferences can be drawn and how to make informative cross-cultural comparisons. We describe a generative causal-modeling framework and outline simple graphical criteria to derive analytic strategies and implied generalizations. Using both simulated and real data, we demonstrate how to project and compare estimates across populations and further show how to formally represent measurement equivalence or inequivalence across societies. We conclude with a discussion of how a formal framework for generalizability can assist researchers in designing more informative cross-cultural studies and thus provides a more solid foundation for cumulative and generalizable behavioral research.;,citation_author=Dominik Deffner;,citation_author=Julia M. Rohrer;,citation_author=Richard McElreath;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_issue=3;,citation_doi=10.1177/25152459221106366;,citation_issn=2515-2459, 2515-2467;,citation_volume=5;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;">
<meta name="citation_reference" content="citation_title=Traditional multiplicity adjustment methods in clinical trials;,citation_author=Alex Dmitrienko;,citation_author=Ralph D’Agostino;,citation_publication_date=2013-12;,citation_cover_date=2013-12;,citation_year=2013;,citation_issue=29;,citation_doi=10.1002/sim.5990;,citation_issn=02776715;,citation_volume=32;,citation_language=en-US;,citation_journal_title=Statistics in Medicine;">
<meta name="citation_reference" content="citation_title=Many Labs 5: Testing Pre-Data-Collection Peer Review as an Intervention to Increase Replicability;,citation_abstract=Replication studies in psychological science sometimes fail to reproduce prior findings. If these studies use methods that are unfaithful to the original study or ineffective in eliciting the phenomenon of interest, then a failure to replicate may be a failure of the protocol rather than a challenge to the original finding. Formal pre-data-collection peer review by experts may address shortcomings and increase replicability rates. We selected 10 replication studies from the Reproducibility Project: Psychology (RP:P; Open Science Collaboration, 2015) for which the original authors had expressed concerns about the replication designs before data collection; only one of these studies had yielded a statistically significant effect ( p $&amp;amp;amp;lt;$ .05). Commenters suggested that lack of adherence to expert review and low-powered tests were the reasons that most of these RP:P studies failed to replicate the original effects. We revised the replication protocols and received formal peer review prior to conducting new replication studies. We administered the RP:P and revised protocols in multiple laboratories (median number of laboratories per original study = 6.5, range = 3–9; median total sample = 1,279.5, range = 276–3,512) for high-powered tests of each original finding with both protocols. Overall, following the preregistered analysis plan, we found that the revised protocols produced effect sizes similar to those of the RP:P protocols ($\Delta$ r = .002 or .014, depending on analytic approach). The median effect size for the revised protocols ( r = .05) was similar to that of the RP:P protocols ( r = .04) and the original RP:P replications ( r = .11), and smaller than that of the original studies ( r = .37). Analysis of the cumulative evidence across the original studies and the corresponding three replication attempts provided very precise estimates of the 10 tested effects and indicated that their effect sizes (median r = .07, range = .00–.15) were 78% smaller, on average, than the original effect sizes (median r = .37, range = .19–.50).;,citation_author=Charles R. Ebersole;,citation_author=Maya B. Mathur;,citation_author=Erica Baranski;,citation_author=Diane-Jo Bart-Plange;,citation_author=Nicholas R. Buttrick;,citation_author=Christopher R. Chartier;,citation_author=Katherine S. Corker;,citation_author=Martin Corley;,citation_author=Joshua K. Hartshorne;,citation_author=Hans IJzerman;,citation_author=Ljiljana B. Lazarević;,citation_author=Hugh Rabagliati;,citation_author=Ivan Ropovik;,citation_author=Balazs Aczel;,citation_author=Lena F. Aeschbach;,citation_author=Luca Andrighetto;,citation_author=Jack D. Arnal;,citation_author=Holly Arrow;,citation_author=Peter Babincak;,citation_author=Bence E. Bakos;,citation_author=Gabriel Baník;,citation_author=Ernest Baskin;,citation_author=Radomir Belopavlović;,citation_author=Michael H. Bernstein;,citation_author=Michał Białek;,citation_author=Nicholas G. Bloxsom;,citation_author=Bojana Bodroža;,citation_author=Diane B. V. Bonfiglio;,citation_author=Leanne Boucher;,citation_author=Florian Brühlmann;,citation_author=Claudia C. Brumbaugh;,citation_author=Erica Casini;,citation_author=Yiling Chen;,citation_author=Carlo Chiorri;,citation_author=William J. Chopik;,citation_author=Oliver Christ;,citation_author=Antonia M. Ciunci;,citation_author=Heather M. Claypool;,citation_author=Sean Coary;,citation_author=Marija V. Čolić;,citation_author=W. Matthew Collins;,citation_author=Paul G. Curran;,citation_author=Chris R. Day;,citation_author=Benjamin Dering;,citation_author=Anna Dreber;,citation_author=John E. Edlund;,citation_author=Filipe Falcão;,citation_author=Anna Fedor;,citation_author=Lily Feinberg;,citation_author=Ian R. Ferguson;,citation_author=Máire Ford;,citation_author=Michael C. Frank;,citation_author=Emily Fryberger;,citation_author=Alexander Garinther;,citation_author=Katarzyna Gawryluk;,citation_author=Kayla Ashbaugh;,citation_author=Mauro Giacomantonio;,citation_author=Steffen R. Giessner;,citation_author=Jon E. Grahe;,citation_author=Rosanna E. Guadagno;,citation_author=Ewa Hałasa;,citation_author=Peter J. B. Hancock;,citation_author=Rias A. Hilliard;,citation_author=Joachim Hüffmeier;,citation_author=Sean Hughes;,citation_author=Katarzyna Idzikowska;,citation_author=Michael Inzlicht;,citation_author=Alan Jern;,citation_author=William Jiménez-Leal;,citation_author=Magnus Johannesson;,citation_author=Jennifer A. Joy-Gaba;,citation_author=Mathias Kauff;,citation_author=Danielle J. Kellier;,citation_author=Grecia Kessinger;,citation_author=Mallory C. Kidwell;,citation_author=Amanda M. Kimbrough;,citation_author=Josiah P. J. King;,citation_author=Vanessa S. Kolb;,citation_author=Sabina Kołodziej;,citation_author=Marton Kovacs;,citation_author=Karolina Krasuska;,citation_author=Sue Kraus;,citation_author=Lacy E. Krueger;,citation_author=Katarzyna Kuchno;,citation_author=Caio Ambrosio Lage;,citation_author=Eleanor V. Langford;,citation_author=Carmel A. Levitan;,citation_author=Tiago Jessé Souza De Lima;,citation_author=Hause Lin;,citation_author=Samuel Lins;,citation_author=Jia E. Loy;,citation_author=Dylan Manfredi;,citation_author=Łukasz Markiewicz;,citation_author=Madhavi Menon;,citation_author=Brett Mercier;,citation_author=Mitchell Metzger;,citation_author=Venus Meyet;,citation_author=Ailsa E. Millen;,citation_author=Jeremy K. Miller;,citation_author=Andres Montealegre;,citation_author=Don A. Moore;,citation_author=Rafał Muda;,citation_author=Gideon Nave;,citation_author=Austin Lee Nichols;,citation_author=Sarah A. Novak;,citation_author=Christian Nunnally;,citation_author=Ana Orlić;,citation_author=Anna Palinkas;,citation_author=Angelo Panno;,citation_author=Kimberly P. Parks;,citation_author=Ivana Pedović;,citation_author=Emilian Pękala;,citation_author=Matthew R. Penner;,citation_author=Sebastiaan Pessers;,citation_author=Boban Petrović;,citation_author=Thomas Pfeiffer;,citation_author=Damian Pieńkosz;,citation_author=Emanuele Preti;,citation_author=Danka Purić;,citation_author=Tiago Ramos;,citation_author=Jonathan Ravid;,citation_author=Timothy S. Razza;,citation_author=Katrin Rentzsch;,citation_author=Juliette Richetin;,citation_author=Sean C. Rife;,citation_author=Anna Dalla Rosa;,citation_author=Kaylis Hase Rudy;,citation_author=Janos Salamon;,citation_author=Blair Saunders;,citation_author=Przemysław Sawicki;,citation_author=Kathleen Schmidt;,citation_author=Kurt Schuepfer;,citation_author=Thomas Schultze;,citation_author=Stefan Schulz-Hardt;,citation_author=Astrid Schütz;,citation_author=Ani N. Shabazian;,citation_author=Rachel L. Shubella;,citation_author=Adam Siegel;,citation_author=Rúben Silva;,citation_author=Barbara Sioma;,citation_author=Lauren Skorb;,citation_author=Luana Elayne Cunha De Souza;,citation_author=Sara Steegen;,citation_author=L. A. R. Stein;,citation_author=R. Weylin Sternglanz;,citation_author=Darko Stojilović;,citation_author=Daniel Storage;,citation_author=Gavin Brent Sullivan;,citation_author=Barnabas Szaszi;,citation_author=Peter Szecsi;,citation_author=Orsolya Szöke;,citation_author=Attila Szuts;,citation_author=Manuela Thomae;,citation_author=Natasha D. Tidwell;,citation_author=Carly Tocco;,citation_author=Ann-Kathrin Torka;,citation_author=Francis Tuerlinckx;,citation_author=Wolf Vanpaemel;,citation_author=Leigh Ann Vaughn;,citation_author=Michelangelo Vianello;,citation_author=Domenico Viganola;,citation_author=Maria Vlachou;,citation_author=Ryan J. Walker;,citation_author=Sophia C. Weissgerber;,citation_author=Aaron L. Wichman;,citation_author=Bradford J. Wiggins;,citation_author=Daniel Wolf;,citation_author=Michael J. Wood;,citation_author=David Zealley;,citation_author=Iris Žeželj;,citation_author=Mark Zrubka;,citation_author=Brian A. Nosek;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_issue=3;,citation_doi=10.1177/2515245920958687;,citation_issn=2515-2459, 2515-2467;,citation_volume=3;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;">
<meta name="citation_reference" content="citation_title=Open Source, Open Science, and the Replication Crisis in HCI;,citation_abstract=The open-source model of software development is an established and widely used method that has been making inroads into several scientific disciplines which use software, thereby also helping much-needed efforts at replication of scientific results. However, our own discipline of HCI does not seem to follow this trend so far. We analyze the entire body of papers from CHI 2016 and CHI 2017 regarding open-source releases, and compare our results with the discipline of bioinformatics. Based on our comparison, we suggest future directions for publication practices in HCI in order to improve scientific rigor and replicability.;,citation_author=Florian Echtler;,citation_author=Maximilian Häußler;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_doi=10.1145/3170427.3188395;,citation_isbn=978-1-4503-5621-3;,citation_language=en-US;,citation_conference_title=Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Open Source, Open Science, and the Replication Crisis in HCI;,citation_abstract=The open-source model of software development is an established and widely used method that has been making inroads into several scientific disciplines which use software, thereby also helping much-needed efforts at replication of scientific results. However, our own discipline of HCI does not seem to follow this trend so far. We analyze the entire body of papers from CHI 2016 and CHI 2017 regarding open-source releases, and compare our results with the discipline of bioinformatics. Based on our comparison, we suggest future directions for publication practices in HCI in order to improve scientific rigor and replicability.;,citation_author=Florian Echtler;,citation_author=Maximilian Häußler;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_doi=10.1145/3170427.3188395;,citation_isbn=978-1-4503-5621-3;,citation_conference_title=Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI EA ’18;">
<meta name="citation_reference" content="citation_title=A simple Monte Carlo method for estimating power in multilevel designs.;,citation_author=Craig K. Enders;,citation_author=Brian T. Keller;,citation_author=Michael P. Woller;,citation_publication_date=2023-11;,citation_cover_date=2023-11;,citation_year=2023;,citation_doi=10.1037/met0000614;,citation_issn=1939-1463, 1082-989X;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=Regression: Models, Methods and Applications;,citation_author=Ludwig Fahrmeir;,citation_author=Thomas Kneib;,citation_author=Stefan Lang;,citation_author=Brian D. Marx;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_doi=10.1007/978-3-662-63882-8;,citation_isbn=978-3-662-63881-1 978-3-662-63882-8;,citation_language=en-US;">
<meta name="citation_reference" content="citation_title=Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses;,citation_abstract=G*Power is a free power analysis program for a variety of statistical tests. We present extensions and improvements of the version introduced by Faul, Erdfelder, Lang, and Buchner (2007) in the domain of correlation and regression analyses. In the new version, we have added procedures to analyze the power of tests based on (1) single-sample tetrachoric correlations, (2) comparisons of dependent correlations, (3) bivariate linear regression, (4) multiple linear regression based on the random predictor model, (5) logistic regression, and (6) Poisson regression. We describe these new features and provide a brief introduction to their scope and handling.;,citation_author=Franz Faul;,citation_author=Edgar Erdfelder;,citation_author=Axel Buchner;,citation_author=Albert-Georg Lang;,citation_publication_date=2009-11;,citation_cover_date=2009-11;,citation_year=2009;,citation_issue=4;,citation_doi=10.3758/BRM.41.4.1149;,citation_issn=1554-3528;,citation_volume=41;,citation_language=en-US;,citation_journal_title=Behavior Research Methods;">
<meta name="citation_reference" content="citation_title=Bayesian Workflow;,citation_abstract=The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.;,citation_author=Andrew Gelman;,citation_author=Aki Vehtari;,citation_author=Daniel Simpson;,citation_author=Charles C. Margossian;,citation_author=Bob Carpenter;,citation_author=Yuling Yao;,citation_author=Lauren Kennedy;,citation_author=Jonah Gabry;,citation_author=Paul-Christian Bürkner;,citation_author=Martin Modrák;,citation_publication_date=2020-11;,citation_cover_date=2020-11;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2011.01808;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Missing data in experiments: Challenges and solutions.;,citation_author=Robin Gomila;,citation_author=Chelsey S. Clark;,citation_publication_date=2022-04;,citation_cover_date=2022-04;,citation_year=2022;,citation_issue=2;,citation_doi=10.1037/met0000361;,citation_issn=1939-1463, 1082-989X;,citation_volume=27;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=SIMR: An R package for power analysis of generalized linear mixed models by simulation;,citation_abstract=The r package simr allows users to calculate power for generalized linear mixed models from the lme4 package. The power calculations are based on Monte Carlo simulations. It includes tools for (i) running a power analysis for a given model and design; and (ii) calculating power curves to assess trade-offs between power and sample size. This paper presents a tutorial using a simple example of count data with mixed effects (with structure representative of environmental monitoring data) to guide the user along a gentle learning curve, adding only a few commands or options at a time.;,citation_author=Peter Green;,citation_author=Catriona J. MacLeod;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=4;,citation_doi=10.1111/2041-210X.12504;,citation_issn=2041-210X;,citation_volume=7;,citation_language=en-US;,citation_journal_title=Methods in Ecology and Evolution;">
<meta name="citation_reference" content="citation_title=&amp;amp;amp;lt;span style=&amp;quot;font-variant:small-caps;&amp;quot;&amp;gt;SIMR&amp;lt;/span&amp;gt; : An R package for power analysis of generalized linear mixed models by simulation;,citation_abstract=Summary The r package simr allows users to calculate power for generalized linear mixed models from the lme 4 package. The power calculations are based on Monte Carlo simulations. It includes tools for (i) running a power analysis for a given model and design; and (ii) calculating power curves to assess trade-offs between power and sample size. This paper presents a tutorial using a simple example of count data with mixed effects (with structure representative of environmental monitoring data) to guide the user along a gentle learning curve, adding only a few commands or options at a time.;,citation_author=Peter Green;,citation_author=Catriona J. MacLeod;,citation_editor=Shinichi Nakagawa;,citation_publication_date=2016-04;,citation_cover_date=2016-04;,citation_year=2016;,citation_issue=4;,citation_doi=10.1111/2041-210X.12504;,citation_issn=2041-210X, 2041-210X;,citation_volume=7;,citation_language=en-US;,citation_journal_title=Methods in Ecology and Evolution;">
<meta name="citation_reference" content="citation_title=Conducting Simulation Studies in the R Programming Environment;,citation_author=Kevin A. Hallgren;,citation_publication_date=2013-10;,citation_cover_date=2013-10;,citation_year=2013;,citation_issue=2;,citation_doi=10.20982/tqmp.09.2.p043;,citation_issn=1913-4126;,citation_volume=9;,citation_journal_title=Tutorials in Quantitative Methods for Psychology;">
<meta name="citation_reference" content="citation_title=Flexible prior elicitation via the prior predictive distribution;,citation_abstract=The prior distribution for the unknown model parameters plays a crucial role in the process of statistical inference based on Bayesian methods. However, specifying suitable priors is often difficult even when detailed prior knowledge is available in principle. The challenge is to express quantitative information in the form of a probability distribution. Prior elicitation addresses this question by extracting subjective information from an expert and transforming it into a valid prior. Most existing methods, however, require information to be provided on the unobservable parameters, whose effect on the data generating process is often complicated and hard to understand. We propose an alternative approach that only requires knowledge about the observable outcomes - knowledge which is often much easier for experts to provide. Building upon a principled statistical framework, our approach utilizes the prior predictive distribution implied by the model to automatically transform experts judgements about plausible outcome values to suitable priors on the parameters. We also provide computational strategies to perform inference and guidelines to facilitate practical use.;,citation_author=Marcelo Hartmann;,citation_author=Georgi Agiashvili;,citation_author=Paul Bürkner;,citation_author=Arto Klami;,citation_editor=Jonas Peters;,citation_editor=David Sontag;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=124;,citation_conference_title=Proceedings of the 36th conference on uncertainty in artificial intelligence (UAI);,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Generalized linear mixed-effects models for studies using different sets of stimuli across conditions;,citation_abstract=A non-repeated item (NRI) design refers to an experimental design in which items used in one level of experimental conditions are not repeatedly used at other levels. Recent literature has suggested the use of generalized linear mixed-effects models (GLMMs) for experimental data analysis, but the existing specification of GLMMs does not account for all possible dependencies among the outcomes in NRI designs. Therefore, the current study proposed a GLMM with a level-specific item random effect for NRI designs. The hypothesis testing performance of the newly proposed model was evaluated via a simulation study to detect the experimental condition effect. The model with a level-specific item random effect performed better than the existing model in terms of power when the variance of the item effect was heterogeneous. Based on these results, we suggest that experimental researchers using NRI designs consider setting a level-specific item random effect in the model.;,citation_author=ShunCheng He;,citation_author=Wooyeol Lee;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_doi=10.3389/fpsyg.2022.955722;,citation_issn=1664-1078;,citation_volume=13;,citation_journal_title=Frontiers in Psychology;">
<meta name="citation_reference" content="citation_title=Simultaneous Inference in General Parametric Models;,citation_author=Torsten Hothorn;,citation_author=Frank Bretz;,citation_author=Peter Westfall;,citation_publication_date=2008-06;,citation_cover_date=2008-06;,citation_year=2008;,citation_issue=3;,citation_doi=10.1002/bimj.200810425;,citation_issn=03233847, 15214036;,citation_volume=50;,citation_language=en-US;,citation_journal_title=Biometrical Journal;">
<meta name="citation_reference" content="citation_title=Power and Sample Size for Longitudinal Models in R – The longpower Package and Shiny App;,citation_author=Samuel Iddi;,citation_author=Michael C Donohue;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_issue=1;,citation_doi=10.32614/RJ-2022-022;,citation_issn=2073-4859;,citation_volume=14;,citation_language=en-US;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=Power analysis for generalized linear mixed models in ecology and evolution;,citation_abstract=“Will my study answer my research question?” is the most fundamental question a researcher can ask when designing a study, yet when phrased in statistical terms – “What is the power of my study?” or “How precise will my parameter estimate be?” – few researchers in ecology and evolution (EE) try to answer it, despite the detrimental consequences of performing under- or over-powered research. We suggest that this reluctance is due in large part to the unsuitability of simple methods of power analysis (broadly defined as any attempt to quantify prospectively the “informativeness” of a study) for the complex models commonly used in EE research. With the aim of encouraging the use of power analysis, we present simulation from generalized linear mixed models (GLMMs) as a flexible and accessible approach to power analysis that can account for random effects, overdispersion and diverse response distributions. We illustrate the benefits of simulation-based power analysis in two research scenarios: estimating the precision of a survey to estimate tick burdens on grouse chicks and estimating the power of a trial to compare the efficacy of insecticide-treated nets in malaria mosquito control. We provide a freely available R function, sim.glmm, for simulating from GLMMs. Analysis of simulated data revealed that the effects of accounting for realistic levels of random effects and overdispersion on power and precision estimates were substantial, with correspondingly severe implications for study design in the form of up to fivefold increases in sampling effort. We also show the utility of simulations for identifying scenarios where GLMM-fitting methods can perform poorly. These results illustrate the inadequacy of standard analytical power analysis methods and the flexibility of simulation-based power analysis for GLMMs. The wider use of these methods should contribute to improving the quality of study design in EE.;,citation_author=Paul C. D. Johnson;,citation_author=Sarah J. E. Barry;,citation_author=Heather M. Ferguson;,citation_author=Pie Müller;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=2;,citation_doi=10.1111/2041-210X.12306;,citation_issn=2041-210X;,citation_volume=6;,citation_language=en-US;,citation_journal_title=Methods in Ecology and Evolution;">
<meta name="citation_reference" content="citation_title=A practical guide and power analysis for GLMMs: Detecting among treatment variation in random effects;,citation_abstract=In ecology and evolution generalized linear mixed models (GLMMs) are becoming increasingly used to test for differences in variation by treatment at multiple hierarchical levels. Yet, the specific sampling schemes that optimize the power of an experiment to detect differences in random effects by treatment/group remain unknown. In this paper we develop a blueprint for conducting power analyses for GLMMs focusing on detecting differences in variance by treatment. We present parameterization and power analyses for random-intercepts and random-slopes GLMMs because of their generality as focal parameters for most applications and because of their immediate applicability to emerging questions in the field of behavioral ecology. We focus on the extreme case of hierarchically structured binomial data, though the framework presented here generalizes easily to any error distribution model. First, we determine the optimal ratio of individuals to repeated measures within individuals that maximizes power to detect differences by treatment in among-individual variation in intercept, among-individual variation in slope, and within-individual variation in intercept. Second, we explore how power to detect differences in target variance parameters is affected by total variation. Our results indicate heterogeneity in power across ratios of individuals to repeated measures with an optimal ratio determined by both the target variance parameter and total sample size. Additionally, power to detect each variance parameter was low overall (in most cases $&amp;amp;amp;gt;$1,000 total observations per treatment needed to achieve 80% power) and decreased with increasing variance in non-target random effects. With growing interest in variance as the parameter of inquiry, these power analyses provide a crucial component for designing experiments focused on detecting differences in variance. We hope to inspire novel experimental designs in ecology and evolution investigating the causes and implications of individual-level phenotypic variance, such as the adaptive significance of within-individual variation.;,citation_author=Morgan P. Kain;,citation_author=Ben M. Bolker;,citation_author=Michael W. McCoy;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_doi=10.7717/peerj.1226;,citation_issn=2167-8359;,citation_volume=3;,citation_language=en-US;,citation_journal_title=PeerJ;">
<meta name="citation_reference" content="citation_title=Rethinking statistical analysis methods for CHI;,citation_abstract=CHI researchers typically use a significance testing approach to statistical analysis when testing hypotheses during usability evaluations. However, the appropriateness of this approach is under increasing criticism, with statisticians, economists, and psychologists arguing against the use of routine interpretation of results using &amp;amp;amp;quot;canned&amp;quot; p values. Three problems with current practice - the fallacy of the transposed conditional, a neglect of power, and the reluctance to interpret the size of effects - can lead us to build weak theories based on vaguely specified hypothesis, resulting in empirical studies which produce results that are of limited practical or scientific use. Using publicly available data presented at CHI 2010 [19] as an example we address each of the three concerns and promote consideration of the magnitude and actual importance of effects, as opposed to statistical significance, as the new criteria for evaluating CHI research.;,citation_author=Maurits Kaptein;,citation_author=Judy Robertson;,citation_publication_date=2012-05;,citation_cover_date=2012-05;,citation_year=2012;,citation_doi=10.1145/2207676.2208557;,citation_isbn=978-1-4503-1015-4;,citation_conference_title=Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’12;">
<meta name="citation_reference" content="citation_title=Using Generalized Linear (Mixed) Models in HCI;,citation_abstract=In HCI we often encounter dependent variables which are not (conditionally) normally distributed: we measure response-times, mouse-clicks, or the number of dialog steps it took a user to complete a task. Furthermore, we often encounter nested or grouped data; users are grouped within companies or institutes, or we obtain multiple observations within users. The standard linear regression models and ANOVAs used to analyze our experimental data are not always feasible in such cases since their assumptions are violated, or the predictions from the fitted models are outside the range of the observed data. In this chapter we introduce extensions to the standard linear model (LM) to enable the analysis of these data. The use of [R] to fit both Generalized Linear Models (GLMs) as well as Generalized Linear Mixed Models (GLMMs, also known as random effects models or hierarchical models) is explained. The chapter also briefly covers regularized regression models which are hardly used in the social sciences despite the fact that these models are extremely popular in Machine Learning, often for good reasons. We end with a number of recommendations for further reading on the topics that are introduced: the current text serves as a basic introduction.;,citation_author=Maurits Kaptein;,citation_editor=Judy Robertson;,citation_editor=Maurits Kaptein;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_doi=10.1007/978-3-319-26633-6_11;,citation_isbn=978-3-319-26631-2 978-3-319-26633-6;,citation_language=en-US;,citation_inbook_title=Modern Statistical Methods for HCI;">
<meta name="citation_reference" content="citation_title=Researcher-Centered Design of Statistics: Why Bayesian Statistics Better Fit the Culture and Incentives of HCI;,citation_abstract=A core tradition of HCI lies in the experimental evaluation of the effects of techniques and interfaces to determine if they are useful for achieving their purpose. However, our individual analyses tend to stand alone, and study results rarely accrue in more precise estimates via meta-analysis: in a literature search, we found only 56 meta-analyses in HCI in the ACM Digital Library, 3 of which were published at CHI (often called the top HCI venue). Yet meta-analysis is the gold standard for demonstrating robust quantitative knowledge. We treat this as a user-centered design problem: the failure to accrue quantitative knowledge is not the users’ (i.e. researchers’) failure, but a failure to consider those users’ needs when designing statistical practice. Using simulation, we compare hypothetical publication worlds following existing frequentist against Bayesian practice. We show that Bayesian analysis yields more precise effects with each new study, facilitating knowledge accrual without traditional meta-analyses. Bayesian practices also allow more principled conclusions from small-n studies of novel techniques. These advantages make Bayesian practices a likely better fit for the culture and incentives of the field. Instead of admonishing ourselves to spend resources on larger studies, we propose using tools that more appropriately analyze small studies and encourage knowledge accrual from one study to the next. We also believe Bayesian methods can be adopted from the bottom up without the need for new incentives for replication or meta-analysis. These techniques offer the potential for a more user- (i.e. researcher-) centered approach to statistical analysis in HCI.;,citation_author=Matthew Kay;,citation_author=Gregory L. Nelson;,citation_author=Eric B. Hekler;,citation_publication_date=2016-05;,citation_cover_date=2016-05;,citation_year=2016;,citation_doi=10.1145/2858036.2858465;,citation_isbn=978-1-4503-3362-7;,citation_conference_title=Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’16;">
<meta name="citation_reference" content="citation_title=Obtaining Power or Obtaining Precision: Delineating Methods of Sample-Size Planning;,citation_abstract=Sample-size planning historically has been approached from a power analytic perspective in order to have some reasonable probability of correctly rejecting the null hypothesis. Another approach that is not as well-known is one that emphasizes accuracy in parameter estimation (AIPE). From the AIPE perspective, sample size is chosen such that the expected width of a confidence interval will be sufficiently narrow. The rationales of both approaches are delineated and two procedures are given for estimating the sample size from the AIPE perspective for a two-group mean comparison. One method yields the required sample size, such that the expected width of the computed confidence interval will be the value specified. A modification allows for a defined degree of probabilistic assurance that the width of the computed confidence interval will be no larger than specified. The authors emphasize that the correct conceptualization of sample-size planning depends on the research questions and particular goals of the study.;,citation_author=Ken Kelley;,citation_author=Scott E. Maxwell;,citation_author=Joseph R. Rausch;,citation_publication_date=2003-09;,citation_cover_date=2003-09;,citation_year=2003;,citation_issue=3;,citation_doi=10.1177/0163278703255242;,citation_issn=0163-2787, 1552-3918;,citation_volume=26;,citation_language=en-US;,citation_journal_title=Evaluation &amp;amp;amp; the Health Professions;">
<meta name="citation_reference" content="citation_title=Sample size planning for the standardized mean difference: Accuracy in parameter estimation via narrow confidence intervals.;,citation_author=Ken Kelley;,citation_author=Joseph R. Rausch;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=4;,citation_doi=10.1037/1082-989X.11.4.363;,citation_issn=1939-1463, 1082-989X;,citation_volume=11;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=A point of minimal important difference (MID): A critique of terminology and methods;,citation_author=Madeleine T King;,citation_publication_date=2011-04;,citation_cover_date=2011-04;,citation_year=2011;,citation_issue=2;,citation_doi=10.1586/erp.11.9;,citation_issn=1473-7167, 1744-8379;,citation_volume=11;,citation_language=en-US;,citation_journal_title=Expert Review of Pharmacoeconomics &amp;amp;amp; Outcomes Research;">
<meta name="citation_reference" content="citation_title=The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective;,citation_author=John K. Kruschke;,citation_author=Torrin M. Liddell;,citation_publication_date=2018-02;,citation_cover_date=2018-02;,citation_year=2018;,citation_issue=1;,citation_doi=10.3758/s13423-016-1221-4;,citation_issn=1069-9384, 1531-5320;,citation_volume=25;,citation_language=en-US;,citation_journal_title=Psychonomic Bulletin &amp;amp;amp; Review;">
<meta name="citation_reference" content="citation_title=Estimating power in (generalized) linear mixed models: An open introduction and tutorial in R;,citation_abstract=Mixed-effects models are a powerful tool for modeling fixed and random effects simultaneously, but do not offer a feasible analytic solution for estimating the probability that a test correctly rejects the null hypothesis. Being able to estimate this probability, however, is critical for sample size planning, as power is closely linked to the reliability and replicability of empirical findings. A flexible and very intuitive alternative to analytic power solutions are simulation-based power analyses. Although various tools for conducting simulation-based power analyses for mixed-effects models are available, there is lack of guidance on how to appropriately use them. In this tutorial, we discuss how to estimate power for mixed-effects models in different use cases: first, how to use models that were fit on available (e.g. published) data to determine sample size; second, how to determine the number of stimuli required for sufficient power; and finally, how to conduct sample size planning without available data. Our examples cover both linear and generalized linear models and we provide code and resources for performing simulation-based power analyses on openly accessible data sets. The present work therefore helps researchers to navigate sound research design when using mixed-effects models, by summarizing resources, collating available knowledge, providing solutions and tools, and applying them to real-world problems in sample sizing planning when sophisticated analysis procedures like mixed-effects models are outlined as inferential procedures.;,citation_author=Levi Kumle;,citation_author=Melissa L.-H. Võ;,citation_author=Dejan Draschkow;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_issue=6;,citation_doi=10.3758/s13428-021-01546-0;,citation_issn=1554-3528;,citation_volume=53;,citation_language=en-US;,citation_journal_title=Behavior Research Methods;">
<meta name="citation_reference" content="citation_title=Selection of the Number of Participants in Intensive Longitudinal Studies: A User-Friendly Shiny App and Tutorial for Performing Power Analysis in Multilevel Regression Models That Account for Temporal Dependencies;,citation_abstract=In recent years, the popularity of procedures for collecting intensive longitudinal data, such as the experience-sampling method, has increased greatly. The data collected using such designs allow researchers to study the dynamics of psychological functioning and how these dynamics differ across individuals. To this end, the data are often modeled with multilevel regression models. An important question that arises when researchers design intensive longitudinal studies is how to determine the number of participants needed to test specific hypotheses regarding the parameters of these models with sufficient power. Power calculations for intensive longitudinal studies are challenging because of the hierarchical data structure in which repeated observations are nested within the individuals and because of the serial dependence that is typically present in these data. We therefore present a user-friendly application and step-by-step tutorial for performing simulation-based power analyses for a set of models that are popular in intensive longitudinal research. Because many studies use the same sampling protocol (i.e., a fixed number of at least approximately equidistant observations) within individuals, we assume that this protocol is fixed and focus on the number of participants. All included models explicitly account for the temporal dependencies in the data by assuming serially correlated errors or including autoregressive effects.;,citation_author=Ginette Lafit;,citation_author=Janne K. Adolf;,citation_author=Egon Dejonckheere;,citation_author=Inez Myin-Germeys;,citation_author=Wolfgang Viechtbauer;,citation_author=Eva Ceulemans;,citation_publication_date=2021-01;,citation_cover_date=2021-01;,citation_year=2021;,citation_issue=1;,citation_doi=10.1177/2515245920978738;,citation_issn=2515-2459, 2515-2467;,citation_volume=4;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;">
<meta name="citation_reference" content="citation_title=Equivalence Testing for Psychological Research: A Tutorial;,citation_abstract=Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects.;,citation_author=Daniël Lakens;,citation_author=Anne M. Scheel;,citation_author=Peder M. Isager;,citation_publication_date=2018-06;,citation_cover_date=2018-06;,citation_year=2018;,citation_issue=2;,citation_doi=10.1177/2515245918770963;,citation_issn=2515-2459, 2515-2467;,citation_volume=1;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;">
<meta name="citation_reference" content="citation_title=Improving Your Statistical Inferences;,citation_abstract=This open educational resource contains information to improve statistical inferences, design better experiments, and report scientific research more transparently.;,citation_author=Daniël Lakens;,citation_publication_date=2022-04;,citation_cover_date=2022-04;,citation_year=2022;,citation_doi=10.5281/ZENODO.6409077;,citation_publisher=Zenodo;">
<meta name="citation_reference" content="citation_title=Justify your alpha;,citation_author=Daniël Lakens;,citation_author=Federico G. Adolfi;,citation_author=Casper J. Albers;,citation_author=Farid Anvari;,citation_author=Matthew A. J. Apps;,citation_author=Shlomo E. Argamon;,citation_author=Thom Baguley;,citation_author=Raymond B. Becker;,citation_author=Stephen D. Benning;,citation_author=Daniel E. Bradford;,citation_author=Erin M. Buchanan;,citation_author=Aaron R. Caldwell;,citation_author=Ben Van Calster;,citation_author=Rickard Carlsson;,citation_author=Sau-Chin Chen;,citation_author=Bryan Chung;,citation_author=Lincoln J. Colling;,citation_author=Gary S. Collins;,citation_author=Zander Crook;,citation_author=Emily S. Cross;,citation_author=Sameera Daniels;,citation_author=Henrik Danielsson;,citation_author=Lisa DeBruine;,citation_author=Daniel J. Dunleavy;,citation_author=Brian D. Earp;,citation_author=Michele I. Feist;,citation_author=Jason D. Ferrell;,citation_author=James G. Field;,citation_author=Nicholas W. Fox;,citation_author=Amanda Friesen;,citation_author=Caio Gomes;,citation_author=Monica Gonzalez-Marquez;,citation_author=James A. Grange;,citation_author=Andrew P. Grieve;,citation_author=Robert Guggenberger;,citation_author=James Grist;,citation_author=Anne-Laura Harmelen;,citation_author=Fred Hasselman;,citation_author=Kevin D. Hochard;,citation_author=Mark R. Hoffarth;,citation_author=Nicholas P. Holmes;,citation_author=Michael Ingre;,citation_author=Peder M. Isager;,citation_author=Hanna K. Isotalus;,citation_author=Christer Johansson;,citation_author=Konrad Juszczyk;,citation_author=David A. Kenny;,citation_author=Ahmed A. Khalil;,citation_author=Barbara Konat;,citation_author=Junpeng Lao;,citation_author=Erik Gahner Larsen;,citation_author=Gerine M. A. Lodder;,citation_author=Jiří Lukavský;,citation_author=Christopher R. Madan;,citation_author=David Manheim;,citation_author=Stephen R. Martin;,citation_author=Andrea E. Martin;,citation_author=Deborah G. Mayo;,citation_author=Randy J. McCarthy;,citation_author=Kevin McConway;,citation_author=Colin McFarland;,citation_author=Amanda Q. X. Nio;,citation_author=Gustav Nilsonne;,citation_author=Cilene Lino Oliveira;,citation_author=Jean-Jacques Orban Xivry;,citation_author=Sam Parsons;,citation_author=Gerit Pfuhl;,citation_author=Kimberly A. Quinn;,citation_author=John J. Sakon;,citation_author=S. Adil Saribay;,citation_author=Iris K. Schneider;,citation_author=Manojkumar Selvaraju;,citation_author=Zsuzsika Sjoerds;,citation_author=Samuel G. Smith;,citation_author=Tim Smits;,citation_author=Jeffrey R. Spies;,citation_author=Vishnu Sreekumar;,citation_author=Crystal N. Steltenpohl;,citation_author=Neil Stenhouse;,citation_author=Wojciech Świątkowski;,citation_author=Miguel A. Vadillo;,citation_author=Marcel A. L. M. Van Assen;,citation_author=Matt N. Williams;,citation_author=Samantha E. Williams;,citation_author=Donald R. Williams;,citation_author=Tal Yarkoni;,citation_author=Ignazio Ziano;,citation_author=Rolf A. Zwaan;,citation_publication_date=2018-03;,citation_cover_date=2018-03;,citation_year=2018;,citation_issue=3;,citation_doi=10.1038/s41562-018-0311-x;,citation_issn=2397-3374;,citation_volume=2;,citation_language=en-US;,citation_journal_title=Nature Human Behaviour;">
<meta name="citation_reference" content="citation_title=Sample Size Justification;,citation_abstract=An important step when designing an empirical study is to justify the sample size that will be collected. The key aim of a sample size justification for such studies is to explain how the collected data is expected to provide valuable information given the inferential goals of the researcher. In this overview article six approaches are discussed to justify the sample size in a quantitative empirical study: 1) collecting data from (almost) the entire population, 2) choosing a sample size based on resource constraints, 3) performing an a-priori power analysis, 4) planning for a desired accuracy, 5) using heuristics, or 6) explicitly acknowledging the absence of a justification. An important question to consider when justifying sample sizes is which effect sizes are deemed interesting, and the extent to which the data that is collected informs inferences about these effect sizes. Depending on the sample size justification chosen, researchers could consider 1) what the smallest effect size of interest is, 2) which minimal effect size will be statistically significant, 3) which effect sizes they expect (and what they base these expectations on), 4) which effect sizes would be rejected based on a confidence interval around the effect size, 5) which ranges of effects a study has sufficient power to detect based on a sensitivity power analysis, and 6) which effect sizes are expected in a specific research area. Researchers can use the guidelines presented in this article, for example by using the interactive form in the accompanying online Shiny app, to improve their sample size justification, and hopefully, align the informational value of a study with their inferential goals.;,citation_author=Daniël Lakens;,citation_publication_date=2022-03;,citation_cover_date=2022-03;,citation_year=2022;,citation_issue=1;,citation_doi=10.1525/collabra.33267;,citation_issn=2474-7394;,citation_volume=8;,citation_journal_title=Collabra: Psychology;">
<meta name="citation_reference" content="citation_title=Simulation-Based Power Analysis for Factorial Analysis of Variance Designs;,citation_abstract=Researchers often rely on analysis of variance (ANOVA) when they report results of experiments. To ensure that a study is adequately powered to yield informative results with an ANOVA, researchers can perform an a priori power analysis. However, power analysis for factorial ANOVA designs is often a challenge. Current software solutions do not allow power analyses for complex designs with several within-participants factors. Moreover, power analyses often need [Formula: see text] or Cohen’s f as input, but these effect sizes are not intuitive and do not generalize to different experimental designs. We have created the R package Superpower and online Shiny apps to enable researchers without extensive programming experience to perform simulation-based power analysis for ANOVA designs of up to three within- or between-participants factors. Predicted effects are entered by specifying means, standard deviations, and, for within-participants factors, the correlations. The simulation provides the statistical power for all ANOVA main effects, interactions, and individual comparisons. The software can plot power across a range of sample sizes, can control for multiple comparisons, and can compute power when the homogeneity or sphericity assumption is violated. This Tutorial demonstrates how to perform a priori power analysis to design informative studies for main effects, interactions, and individual comparisons and highlights important factors that determine the statistical power for factorial ANOVA designs.;,citation_author=Daniël Lakens;,citation_author=Aaron R. Caldwell;,citation_publication_date=2021-01;,citation_cover_date=2021-01;,citation_year=2021;,citation_issue=1;,citation_doi=10.1177/2515245920951503;,citation_issn=2515-2459, 2515-2467;,citation_volume=4;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;">
<meta name="citation_reference" content="citation_title=Power struggles: Estimating sample size for multilevel relationships research;,citation_author=Sean P. Lane;,citation_author=Erin P. Hennes;,citation_publication_date=2018-01;,citation_cover_date=2018-01;,citation_year=2018;,citation_issue=1;,citation_doi=10.1177/0265407517710342;,citation_issn=0265-4075, 1460-3608;,citation_volume=35;,citation_language=en-US;,citation_journal_title=Journal of Social and Personal Relationships;">
<meta name="citation_reference" content="citation_title=Power Analysis by Simulation using R and simglm;,citation_abstract=Power is a task that is commonly done prior to collecting data for a primary study. In most cases closed-form solutions are used to estimate power which may statistical assumptions to be able to perform the computations, for example assume residuals are normally distributed. In real-world data, these statistical assumptions may not hold, therefore estimates of power when these assumptions are assumed will likely be inflated. Power by simulation is another way to compute power estimates and offers significant flexibility to the user to explore the impact of various statistical assumption violations may have on power. This tutorial uses the simglm R package to perform the power by simulation. The simglm package provides a framework to simulate data from generalized linear mixed models which includes a wide variety of models. In addition, functions to perform replications and to compute power estimate summaries are available for users to take advantage of. Two worked examples are shown, one for a two-sample t-test and another within a repeated measures or longitudinal framework.;,citation_author=Brandon LeBeau;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_doi=10.17077/f7kk-6w7f;,citation_language=en-US;">
<meta name="citation_reference" content="citation_title=Simglm: Simulate Models Based on the Generalized Linear Model;,citation_abstract=Simulates regression models, including both simple regression and generalized linear mixed models with up to three level of nesting. Power simulations that are flexible allowing the specification of missing data, unbalanced designs, and different random error distributions are built into the package.;,citation_author=Brandon LeBeau;,citation_publication_date=2017-05;,citation_cover_date=2017-05;,citation_year=2017;,citation_doi=10.32614/CRAN.package.simglm;,citation_language=en-US;,citation_publisher=Comprehensive R Archive Network;">
<meta name="citation_reference" content="citation_title=Using the Tidyverse Package in R for Simulation Studies in SEM;,citation_author=Sunbok Lee;,citation_author=Suppanut Sriutaisuk;,citation_author=Hanjoe Kim;,citation_publication_date=2020-05;,citation_cover_date=2020-05;,citation_year=2020;,citation_issue=3;,citation_doi=10.1080/10705511.2019.1644515;,citation_issn=1070-5511, 1532-8007;,citation_volume=27;,citation_language=en-US;,citation_journal_title=Structural Equation Modeling: A Multidisciplinary Journal;">
<meta name="citation_reference" content="citation_title=Statistical Analysis with Missing Data;,citation_author=Roderick J. A. Little;,citation_author=Donald B. Rubin;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_isbn=978-1-118-62588-0;,citation_language=en-US;">
<meta name="citation_reference" content="citation_title=Evaluating significance in linear mixed-effects models in R;,citation_abstract=Mixed-effects models are being used ever more frequently in the analysis of experimental data. However, in the lme4 package in R the standards for evaluating significance of fixed effects in these models (i.e., obtaining p-values) are somewhat vague. There are good reasons for this, but as researchers who are using these models are required in many cases to report p-values, some method for evaluating the significance of the model output is needed. This paper reports the results of simulations showing that the two most common methods for evaluating significance, using likelihood ratio tests and applying the z distribution to the Wald t values from the model output (t-as-z), are somewhat anti-conservative, especially for smaller sample sizes. Other methods for evaluating significance, including parametric bootstrapping and the Kenward-Roger and Satterthwaite approximations for degrees of freedom, were also evaluated. The results of these simulations suggest that Type 1 error rates are closest to .05 when models are fitted using REML and p-values are derived using the Kenward-Roger or Satterthwaite approximations, as these approximations both produced acceptable Type 1 error rates even for smaller samples.;,citation_author=Steven G. Luke;,citation_publication_date=2017-08;,citation_cover_date=2017-08;,citation_year=2017;,citation_issue=4;,citation_doi=10.3758/s13428-016-0809-y;,citation_issn=1554-3528;,citation_volume=49;,citation_language=en-US;,citation_journal_title=Behavior Research Methods;">
<meta name="citation_reference" content="citation_title=What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory;,citation_abstract=We make only one point in this article. Every quantitative study must be able to answer the question: what is your estimand? The estimand is the target quantity—the purpose of the statistical analysis. Much attention is already placed on how to do estimation; a similar degree of care should be given to defining the thing we are estimating. We advocate that authors state the central quantity of each analysis—the theoretical estimand—in precise terms that exist outside of any statistical model. In our framework, researchers do three things: (1) set a theoretical estimand, clearly connecting this quantity to theory; (2) link to an empirical estimand, which is informative about the theoretical estimand under some identification assumptions; and (3) learn from data. Adding precise estimands to research practice expands the space of theoretical questions, clarifies how evidence can speak to those questions, and unlocks new tools for estimation. By grounding all three steps in a precise statement of the target quantity, our framework connects statistical evidence to theory.;,citation_author=Ian Lundberg;,citation_author=Rebecca Johnson;,citation_author=Brandon M. Stewart;,citation_publication_date=2021-06;,citation_cover_date=2021-06;,citation_year=2021;,citation_issue=3;,citation_doi=10.1177/00031224211004187;,citation_issn=0003-1224, 1939-8271;,citation_volume=86;,citation_language=en-US;,citation_journal_title=American Sociological Review;">
<meta name="citation_reference" content="citation_title=The consequences of ignoring therapist effects in trials with longitudinal data: A simulation study.;,citation_author=Kristoffer Magnusson;,citation_author=Gerhard Andersson;,citation_author=Per Carlbring;,citation_publication_date=2018-09;,citation_cover_date=2018-09;,citation_year=2018;,citation_issue=9;,citation_doi=10.1037/ccp0000333;,citation_issn=1939-2117, 0022-006X;,citation_volume=86;,citation_language=en-US;,citation_journal_title=Journal of Consulting and Clinical Psychology;">
<meta name="citation_reference" content="citation_title=Justify Your Alpha: A Primer on Two Practical Approaches;,citation_abstract=The default use of an alpha level of .05 is suboptimal for two reasons. First, decisions based on data can be made more efficiently by choosing an alpha level that minimizes the combined Type 1 and Type 2 error rate. Second, it is possible that in studies with very high statistical power, p values lower than the alpha level can be more likely when the null hypothesis is true than when the alternative hypothesis is true (i.e., Lindley’s paradox). In this article, we explain two approaches that can be used to justify a better choice of an alpha level than relying on the default threshold of .05. The first approach is based on the idea to either minimize or balance Type 1 and Type 2 error rates. The second approach lowers the alpha level as a function of the sample size to prevent Lindley’s paradox. An R package and Shiny app are provided to perform the required calculations. Both approaches have their limitations (e.g., the challenge of specifying relative costs and priors) but can offer an improvement to current practices, especially when sample sizes are large. The use of alpha levels that are better justified should improve statistical inferences and can increase the efficiency and informativeness of scientific research.;,citation_author=Maximilian Maier;,citation_author=Daniël Lakens;,citation_publication_date=2022-04;,citation_cover_date=2022-04;,citation_year=2022;,citation_issue=2;,citation_doi=10.1177/25152459221080396;,citation_issn=2515-2459, 2515-2467;,citation_volume=5;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;">
<meta name="citation_reference" content="citation_title=Measuring individual differences in reaction norms in field and experimental studies: A power analysis of random regression models;,citation_abstract=Summary 1. Interest in measuring individual variation in reaction norms using mixed-effects and, more specifically, random regression models have grown apace in the last few years within evolution and ecology. However, these are data hungry methods, and little effort to date has been put into understanding how much and what kind of data we need to collect in order to apply these models usefully and reliably. 2. We conducted simulations to address three central questions. First, what is the best sampling strategy to collect sufficient data to test for individual variation using random regression models? Second, on occasions when precision is difficult to assess, can we be confident that a failure to detect significant variance in plasticity using random regression represents a biological reality rather than a lack of statistical power? Finally, does the common practice of censoring individuals with one or few repeated measures improve or reduce power to estimate individual variation in random regressions? 3. We have also developed a series of easy-to-use functions in the “pamm” statistical package for R, which is freely available, that will allow researchers to conduct similar power analyses tailored more specifically to their own data. 4. Our results reveal potentially useful rules of thumb: large data sets ( N $\quad&amp;amp;amp;gt;\quad$200) are needed to evaluate the variance of individual-specific slopes; a number of individuals/number of observations per individual ratio of approximately 0$\cdot$5 consistently yielded the highest power to detect random effects; individuals with one or few observations should not generally be censored as this reduces power to detect variance in plasticity. 5. We discuss the wider implications of these simulations and remaining challenges and suggest a new way to standardize results that would better facilitate the comparison of findings across empirical studies.;,citation_author=Julien G. A. Martin;,citation_author=Daniel H. Nussey;,citation_author=Alastair J. Wilson;,citation_author=Denis Réale;,citation_publication_date=2011-08;,citation_cover_date=2011-08;,citation_year=2011;,citation_issue=4;,citation_doi=10.1111/j.2041-210X.2010.00084.x;,citation_issn=2041-210X, 2041-210X;,citation_volume=2;,citation_language=en-US;,citation_journal_title=Methods in Ecology and Evolution;">
<meta name="citation_reference" content="citation_title=Balancing Type I error and power in linear mixed models;,citation_author=Hannes Matuschek;,citation_author=Reinhold Kliegl;,citation_author=Shravan Vasishth;,citation_author=Harald Baayen;,citation_author=Douglas Bates;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_doi=10.1016/j.jml.2017.01.001;,citation_issn=0749596X;,citation_volume=94;,citation_language=en-US;,citation_journal_title=Journal of Memory and Language;">
<meta name="citation_reference" content="citation_title=Sample Size Planning for Statistical Power and Accuracy in Parameter Estimation;,citation_abstract=This review examines recent advances in sample size planning, not only from the perspective of an individual researcher, but also with regard to the goal of developing cumulative knowledge. Psychologists have traditionally thought of sample size planning in terms of power analysis. Although we review recent advances in power analysis, our main focus is the desirability of achieving accurate parameter estimates, either instead of or in addition to obtaining sufficient power. Accuracy in parameter estimation (AIPE) has taken on increasing importance in light of recent emphasis on effect size estimation and formation of confidence intervals. The review provides an overview of the logic behind sample size planning for AIPE and summarizes recent advances in implementing this approach in designs commonly used in psychological research.;,citation_author=Scott E. Maxwell;,citation_author=Ken Kelley;,citation_author=Joseph R. Rausch;,citation_publication_date=2008-01;,citation_cover_date=2008-01;,citation_year=2008;,citation_issue=1;,citation_doi=10.1146/annurev.psych.59.103006.093735;,citation_issn=0066-4308, 1545-2085;,citation_volume=59;,citation_language=en-US;,citation_journal_title=Annual Review of Psychology;">
<meta name="citation_reference" content="citation_title=Statistical Rethinking: A Bayesian Course with Examples in R and Stan;,citation_author=Richard McElreath;,citation_publication_date=2020-03;,citation_cover_date=2020-03;,citation_year=2020;,citation_doi=10.1201/9780429029608;,citation_isbn=978-0-429-02960-8;,citation_language=en-US;">
<meta name="citation_reference" content="citation_title=Best practice guidance for linear mixed-effects models in psychological science;,citation_abstract=The use of Linear Mixed-effects Models (LMMs) is set to dominate statistical analyses in psychological science and may become the default approach to analyzing quantitative data. The rapid growth in adoption of LMMs has been matched by a proliferation of differences in practice. Unless this diversity is recognized, and checked, the field shall reap enormous difficulties in the future when attempts are made to consolidate or synthesize research findings. Here we examine this diversity using two methods – a survey of researchers (n&nbsp;=&nbsp;163) and a quasi-systematic review of papers using LMMs (n&nbsp;=&nbsp;400). The survey reveals substantive concerns among psychologists using or planning to use LMMs and an absence of agreed standards. The review of papers complements the survey, showing variation in how the models are built, how effects are evaluated and, most worryingly, how models are reported. Using these data as our departure point, we present a set of best practice guidance, focusing on the reporting of LMMs. It is the authors’ intention that the paper supports a step-change in the reporting of LMMs across the psychological sciences, preventing a trajectory in which findings reported today cannot be transparently understood and used tomorrow.;,citation_author=Lotte Meteyard;,citation_author=Robert A. I. Davies;,citation_publication_date=2020-06;,citation_cover_date=2020-06;,citation_year=2020;,citation_doi=10.1016/j.jml.2020.104092;,citation_issn=0749-596X;,citation_volume=112;,citation_language=en-US;,citation_journal_title=Journal of Memory and Language;">
<meta name="citation_reference" content="citation_title=Best practice guidance for linear mixed-effects models in psychological science;,citation_author=Lotte Meteyard;,citation_author=Robert A. I. Davies;,citation_publication_date=2020-06;,citation_cover_date=2020-06;,citation_year=2020;,citation_doi=10.1016/j.jml.2020.104092;,citation_issn=0749596X;,citation_volume=112;,citation_language=en-US;,citation_journal_title=Journal of Memory and Language;">
<meta name="citation_reference" content="citation_title=Prior Knowledge Elicitation: The Past, Present, and Future;,citation_author=Petrus Mikkola;,citation_author=Osvaldo A. Martin;,citation_author=Suyog Chandramouli;,citation_author=Marcelo Hartmann;,citation_author=Oriol Abril Pla;,citation_author=Owen Thomas;,citation_author=Henri Pesonen;,citation_author=Jukka Corander;,citation_author=Aki Vehtari;,citation_author=Samuel Kaski;,citation_author=Paul-Christian Bürkner;,citation_author=Arto Klami;,citation_publication_date=2023-01;,citation_cover_date=2023-01;,citation_year=2023;,citation_issue=-1;,citation_doi=10.1214/23-BA1381;,citation_issn=1936-0975;,citation_volume=-1;,citation_journal_title=Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=Summary-statistics-based power analysis: A new and practical method to determine sample size for mixed-effects modeling.;,citation_author=Kou Murayama;,citation_author=Satoshi Usami;,citation_author=Michiko Sakaki;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_doi=10.1037/met0000330;,citation_issn=1939-1463, 1082-989X;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=Safeguard Power as a Protection Against Imprecise Power Estimates;,citation_abstract=An essential first step in planning a confirmatory or a replication study is to determine the sample size necessary to draw statistically reliable inferences using power analysis. A key problem, however, is that what is available is the sample-size estimate of the effect size, and its use can lead to severely underpowered studies when the effect size is overestimated. As a potential remedy, we introduce safeguard power analysis, which uses the uncertainty in the estimate of the effect size to achieve a better likelihood of correctly identifying the population effect size. Using a lower-bound estimate of the effect size, in turn, allows researchers to calculate a sample size for a replication study that helps protect it from being underpowered. We show that in most common instances, compared with nominal power, safeguard power is higher whereas standard power is lower. We additionally recommend the use of safeguard power analysis to evaluate the strength of the evidence provided by the original study.;,citation_author=Marco Perugini;,citation_author=Marcello Gallucci;,citation_author=Giulio Costantini;,citation_publication_date=2014-05;,citation_cover_date=2014-05;,citation_year=2014;,citation_issue=3;,citation_doi=10.1177/1745691614528519;,citation_issn=1745-6916, 1745-6924;,citation_volume=9;,citation_language=en-US;,citation_journal_title=Perspectives on Psychological Science;">
<meta name="citation_reference" content="citation_title=Some Prior(s) Experience Necessary: Templates for Getting Started With Bayesian Analysis;,citation_abstract=Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI.;,citation_author=Chanda Phelan;,citation_author=Jessica Hullman;,citation_author=Matthew Kay;,citation_author=Paul Resnick;,citation_publication_date=2019-05;,citation_cover_date=2019-05;,citation_year=2019;,citation_doi=10.1145/3290605.3300709;,citation_isbn=978-1-4503-5970-2;,citation_conference_title=Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’19;">
<meta name="citation_reference" content="citation_title=Computational Tools for Probing Interactions in Multiple Linear Regression, Multilevel Modeling, and Latent Curve Analysis;,citation_abstract=Simple slopes, regions of significance, and confidence bands are commonly used to evaluate interactions in multiple linear regression (MLR) models, and the use of these techniques has recently been extended to multilevel or hierarchical linear modeling (HLM) and latent curve analysis (LCA). However, conducting these tests and plotting the conditional relations is often a tedious and error-prone task. This article provides an overview of methods used to probe interaction effects and describes a unified collection of freely available online resources that researchers can use to obtain significance tests for simple slopes, compute regions of significance, and obtain confidence bands for simple slopes across the range of the moderator in the MLR, HLM, and LCA contexts. Plotting capabilities are also provided.;,citation_author=Kristopher J. Preacher;,citation_author=Patrick J. Curran;,citation_author=Daniel J. Bauer;,citation_publication_date=2006-12;,citation_cover_date=2006-12;,citation_year=2006;,citation_issue=4;,citation_doi=10.3102/10769986031004437;,citation_issn=1076-9986, 1935-1054;,citation_volume=31;,citation_language=en-US;,citation_journal_title=Journal of Educational and Behavioral Statistics;">
<meta name="citation_reference" content="citation_title=Statistical Power and Optimal Design for Multisite Randomized Trials;,citation_author=Stephen W Raudenbush;,citation_author=Xiaofeng Liu;,citation_doi=10.1037/1082-989X.5.2.199;,citation_language=en-US;">
<meta name="citation_reference" content="citation_title=Simulation-Based Power Analyses for the Smallest Effect Size of Interest: A Confidence-Interval Approach for Minimum-Effect and Equivalence Testing;,citation_abstract=Effect sizes are often used in psychology because they are crucial when determining the required sample size of a study and when interpreting the implications of a result. Recently, researchers have been encouraged to contextualize their effect sizes and determine what the smallest effect size is that yields theoretical or practical implications, also known as the “smallest effect size of interest” (SESOI). Having a SESOI will allow researchers to have more specific hypotheses, such as whether their findings are truly meaningful (i.e., minimum-effect testing) or whether no meaningful effect exists (i.e., equivalence testing). These types of hypotheses should be reflected in power analyses to accurately determine the required sample size. Through a confidence-interval-focused approach and simulations, I show how to conduct power analyses for minimum-effect and equivalence testing. Moreover, I show that conducting a power analysis for the SESOI might result in inconclusive results. This confidence-interval-focused simulation-based power analysis can be easily adopted to different types of research areas and designs. Last, I provide recommendations on how to conduct such simulation-based power analyses.;,citation_author=Paul Riesthuis;,citation_publication_date=2024-04;,citation_cover_date=2024-04;,citation_year=2024;,citation_issue=2;,citation_doi=10.1177/25152459241240722;,citation_issn=2515-2459;,citation_volume=7;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;,citation_publisher=SAGE Publications Inc;">
<meta name="citation_reference" content="citation_title=Improving Statistical Practice in HCI;,citation_author=Judy Robertson;,citation_author=Maurits Kaptein;,citation_editor=Judy Robertson;,citation_editor=Maurits Kaptein;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_doi=10.1007/978-3-319-26633-6_14;,citation_isbn=978-3-319-26631-2 978-3-319-26633-6;,citation_language=en-US;,citation_inbook_title=Modern Statistical Methods for HCI;">
<meta name="citation_reference" content="citation_title=Modern Statistical Methods for HCI;,citation_editor=Judy Robertson;,citation_editor=Maurits Kaptein;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_doi=10.1007/978-3-319-26633-6;,citation_isbn=978-3-319-26631-2 978-3-319-26633-6;,citation_language=en-US;,citation_series_title=Human–Computer Interaction Series;">
<meta name="citation_reference" content="citation_title=Modern Statistical Methods for HCI;,citation_editor=Judy Robertson;,citation_editor=Maurits Kaptein;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_doi=10.1007/978-3-319-26633-6;,citation_isbn=978-3-319-26631-2 978-3-319-26633-6;,citation_language=en-US;,citation_series_title=Human–Computer Interaction Series;">
<meta name="citation_reference" content="citation_title=How to capitalize on a priori contrasts in linear (mixed) models: A tutorial;,citation_author=Daniel J. Schad;,citation_author=Shravan Vasishth;,citation_author=Sven Hohenstein;,citation_author=Reinhold Kliegl;,citation_publication_date=2020-02;,citation_cover_date=2020-02;,citation_year=2020;,citation_doi=10.1016/j.jml.2019.104038;,citation_issn=0749596X;,citation_volume=110;,citation_language=en-US;,citation_journal_title=Journal of Memory and Language;">
<meta name="citation_reference" content="citation_title=Toward a principled Bayesian workflow in cognitive science.;,citation_author=Daniel J. Schad;,citation_author=Michael Betancourt;,citation_author=Shravan Vasishth;,citation_publication_date=2021-02;,citation_cover_date=2021-02;,citation_year=2021;,citation_issue=1;,citation_doi=10.1037/met0000275;,citation_issn=1939-1463, 1082-989X;,citation_volume=26;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=Estimating Statistical Power and Required Sample Sizes for Organizational Research Using Multilevel Modeling;,citation_abstract=The use of multilevel modeling to investigate organizational phenomena is rapidly increasing. Unfortunately, little advice is readily available for organizational researchers attempting to determine statistical power when using multilevel models or when determining sample sizes for each level that will maximize statistical power. This article presents an introduction to statistical power in multilevel models. The unique factors influencing power in multilevel models and calculations for estimating power for simple fixed effects, variance components, and cross-level interactions are presented. The results of simulation studies and the existing general rules of thumb are discussed, and the available power analysis software is reviewed.;,citation_author=Charles A. Scherbaum;,citation_author=Jennifer M. Ferreter;,citation_publication_date=2009-04;,citation_cover_date=2009-04;,citation_year=2009;,citation_issue=2;,citation_doi=10.1177/1094428107308906;,citation_issn=1094-4281, 1552-7425;,citation_volume=12;,citation_language=en-US;,citation_journal_title=Organizational Research Methods;">
<meta name="citation_reference" content="citation_title=An Introduction to Mixed Models for Experimental Psychology;,citation_author=Henrik Singmann;,citation_author=David Kellen;,citation_editor=Daniel Spieler;,citation_editor=Eric Schumacher;,citation_publication_date=2019-10;,citation_cover_date=2019-10;,citation_year=2019;,citation_doi=10.4324/9780429318405-2;,citation_isbn=978-0-429-31840-5;,citation_language=en-US;,citation_inbook_title=New Methods in Cognitive Psychology;">
<meta name="citation_reference" content="citation_title=Practical challenges and methodological flexibility in prior elicitation.;,citation_author=Angelika M. Stefan;,citation_author=Nathan J. Evans;,citation_author=Eric-Jan Wagenmakers;,citation_publication_date=2022-04;,citation_cover_date=2022-04;,citation_year=2022;,citation_issue=2;,citation_doi=10.1037/met0000354;,citation_issn=1939-1463, 1082-989X;,citation_volume=27;,citation_language=en-US;,citation_journal_title=Psychological Methods;">
<meta name="citation_reference" content="citation_title=The epistemic and pragmatic function of dichotomous claims based on statistical hypothesis tests;,citation_abstract=Researchers commonly make dichotomous claims based on continuous test statistics. Many have branded the practice as a misuse of statistics and criticize scientists for the widespread application of hypothesis tests to tentatively reject a hypothesis (or not) depending on whether a p-value is below or above an alpha level. Although dichotomous claims are rarely explicitly defended, we argue they play an important epistemological and pragmatic role in science. The epistemological function of dichotomous claims consists in transforming data into quasibasic statements, which are tentatively accepted singular facts that can corroborate or falsify theoretical claims. This transformation requires a prespecified methodological decision procedure such as Neyman-Pearson hypothesis tests. From the perspective of methodological falsificationism these decision procedures are necessary, as probabilistic statements (e.g., continuous test statistics) cannot function as falsifiers of substantive hypotheses. The pragmatic function of dichotomous claims is to facilitate scrutiny and criticism among peers by generating contestable claims, a process referred to by Popper as “conjectures and refutations.” We speculate about how the surprisingly widespread use of a 5% alpha level might have facilitated this pragmatic function. Abandoning dichotomous claims, for example because researchers commonly misuse p-values, would sacrifice their crucial epistemic and pragmatic functions.;,citation_author=Duygu Uygun Tunç;,citation_author=Mehmet Necip Tunç;,citation_author=Daniël Lakens;,citation_publication_date=2023-06;,citation_cover_date=2023-06;,citation_year=2023;,citation_issue=3;,citation_doi=10.1177/09593543231160112;,citation_issn=0959-3543, 1461-7447;,citation_volume=33;,citation_language=en-US;,citation_journal_title=Theory &amp;amp;amp; Psychology;">
<meta name="citation_reference" content="citation_title=Power Analysis for Parameter Estimation in Structural Equation Modeling: A Discussion and Tutorial;,citation_abstract=Despite the widespread and rising popularity of structural equation modeling (SEM) in psychology, there is still much confusion surrounding how to choose an appropriate sample size for SEM. Currently available guidance primarily consists of sample-size rules of thumb that are not backed up by research and power analyses for detecting model misspecification. Missing from most current practices is power analysis for detecting a target effect (e.g., a regression coefficient between latent variables). In this article, we (a) distinguish power to detect model misspecification from power to detect a target effect, (b) report the results of a simulation study on power to detect a target regression coefficient in a three-predictor latent regression model, and (c) introduce a user-friendly Shiny app, pwrSEM, for conducting power analysis for detecting target effects in structural equation models.;,citation_author=Y. Andre Wang;,citation_author=Mijke Rhemtulla;,citation_publication_date=2021-01;,citation_cover_date=2021-01;,citation_year=2021;,citation_issue=1;,citation_doi=10.1177/2515245920918253;,citation_issn=2515-2459;,citation_volume=4;,citation_language=en-US;,citation_journal_title=Advances in Methods and Practices in Psychological Science;,citation_publisher=SAGE Publications Inc;">
<meta name="citation_reference" content="citation_title=Generalised Linear Mixed Model Specification, Analysis, Fitting, and Optimal Design in R with the glmmr Packages;,citation_abstract=We describe the \proglang{R} package \pkg{glmmrBase} and an extension \pkg{glmmrOptim}. \pkg{glmmrBase} provides a flexible approach to specifying, fitting, and analysing generalised linear mixed models. We use an object-orientated class system within \proglang{R} to provide methods for a wide range of covariance and mean functions, including specification of non-linear functions of data and parameters, relevant to multiple applications including cluster randomised trials, cohort studies, spatial and spatio-temporal modelling, and split-plot designs. The class generates relevant matrices and statistics and a wide range of methods including full likelihood estimation of generalised linear mixed models using stochastic Maximum Likelihood, Laplace approximation, power calculation, and access to relevant calculations. The class also includes Hamiltonian Monte Carlo simulation of random effects, sparse matrix methods, and other functionality to support efficient estimation. The \pkg{glmmrOptim} package implements a set of algorithms to identify c-optimal experimental designs where observations are correlated and can be specified using the generalised linear mixed model classes. Several examples and comparisons to existing packages are provided to illustrate use of the packages.;,citation_author=Samuel I. Watson;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_doi=10.48550/ARXIV.2303.12657;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Statistical power and optimal design in experiments in which samples of participants respond to samples of stimuli;,citation_abstract=Researchers designing experiments in which a sample of participants responds to a sample of stimuli are faced with difficult questions about optimal study design. The conventional procedures of statistical power analysis fail to provide appropriate answers to these questions because they are based on statistical models in which stimuli are not assumed to be a source of random variation in the data, models that are inappropriate for experiments involving crossed random factors of participants and stimuli. In this article, we present new methods of power analysis for designs with crossed random factors, and we give detailed, practical guidance to psychology researchers planning experiments in which a sample of participants responds to a sample of stimuli. We extensively examine 5 commonly used experimental designs, describe how to estimate statistical power in each, and provide power analysis results based on a reasonable set of default parameter values. We then develop general conclusions and formulate rules of thumb concerning the optimal design of experiments in which a sample of participants responds to a sample of stimuli. We show that in crossed designs, statistical power typically does not approach unity as the number of participants goes to infinity but instead approaches a maximum attainable power value that is possibly small, depending on the stimulus sample. We also consider the statistical merits of designs involving multiple stimulus blocks. Finally, we provide a simple and flexible Web-based power application to aid researchers in planning studies with samples of stimuli. (PsycINFO Database Record (c) 2016 APA, all rights reserved);,citation_author=Jacob Westfall;,citation_author=David A. Kenny;,citation_author=Charles M. Judd;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_doi=10.1037/xge0000014;,citation_issn=1939-2222;,citation_volume=143;,citation_journal_title=Journal of Experimental Psychology: General;,citation_publisher=American Psychological Association;">
<meta name="citation_reference" content="citation_title=Simulating the Power of Statistical Tests: A Collection of R Examples;,citation_abstract=This paper illustrates how to calculate the power of a statistical test by computer simulation. It provides R code for power simulations of several classical inference procedures including one- and two-sample t tests, chi-squared tests, regression, and analysis of variance.;,citation_author=Florian Wickelmaier;,citation_publication_date=2022-03;,citation_cover_date=2022-03;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2110.09836;,citation_doi=10.48550/arXiv.2110.09836;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=R for data science: Import, tidy, transform, visualize, and model data;,citation_abstract=Use R to turn data into insight, knowledge, and understanding. With this practical book, aspiring data scientists will learn how to do data science with R and RStudio, along with the tidyverse—a collection of R packages designed to work together to make data science fast, fluent, and fun. Even if you have no programming experience, this updated edition will have you doing data science quickly. You’ll learn how to import, transform, and visualize your data and communicate the results. And you’ll get a complete, big-picture understanding of the data science cycle and the basic tools you need to manage the details. Updated for the latest tidyverse features and best practices, new chapters show you how to get data from spreadsheets, databases, and websites. Exercises help you practice what you’ve learned along the way;,citation_author=Hadley Wickham;,citation_author=Mine Çetinkaya-Rundel;,citation_author=Garrett Grolemund;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_isbn=978-1-4920-9740-2;,citation_language=en-US;">
<meta name="citation_reference" content="citation_title=Welcome to the Tidyverse;,citation_author=Hadley Wickham;,citation_author=Mara Averick;,citation_author=Jennifer Bryan;,citation_author=Winston Chang;,citation_author=Lucy McGowan;,citation_author=Romain François;,citation_author=Garrett Grolemund;,citation_author=Alex Hayes;,citation_author=Lionel Henry;,citation_author=Jim Hester;,citation_author=Max Kuhn;,citation_author=Thomas Pedersen;,citation_author=Evan Miller;,citation_author=Stephan Bache;,citation_author=Kirill Müller;,citation_author=Jeroen Ooms;,citation_author=David Robinson;,citation_author=Dana Seidel;,citation_author=Vitalie Spinu;,citation_author=Kohske Takahashi;,citation_author=Davis Vaughan;,citation_author=Claus Wilke;,citation_author=Kara Woo;,citation_author=Hiroaki Yutani;,citation_publication_date=2019-11;,citation_cover_date=2019-11;,citation_year=2019;,citation_issue=43;,citation_doi=10.21105/joss.01686;,citation_issn=2475-9066;,citation_volume=4;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=The generalizability crisis;,citation_abstract=Abstract Most theories and hypotheses in psychology are verbal in nature, yet their evaluation overwhelmingly relies on inferential statistical procedures. The validity of the move from qualitative to quantitative analysis depends on the verbal and statistical expressions of a hypothesis being closely aligned – that is, that the two must refer to roughly the same set of hypothetical observations. Here, I argue that many applications of statistical inference in psychology fail to meet this basic condition. Focusing on the most widely used class of model in psychology – the linear mixed model – I explore the consequences of failing to statistically operationalize verbal hypotheses in a way that respects researchers’ actual generalization intentions. I demonstrate that although the “random effect” formalism is used pervasively in psychology to model intersubject variability, few researchers accord the same treatment to other variables they clearly intend to generalize over (e.g., stimuli, tasks, or research sites). The under-specification of random effects imposes far stronger constraints on the generalizability of results than most researchers appreciate. Ignoring these constraints can dramatically inflate false-positive rates, and often leads researchers to draw sweeping verbal generalizations that lack a meaningful connection to the statistical quantities they are putatively based on. I argue that failure to take the alignment between verbal and statistical expressions seriously lies at the heart of many of psychology’s ongoing problems (e.g., the replication crisis), and conclude with a discussion of several potential avenues for improvement.;,citation_author=Tal Yarkoni;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_doi=10.1017/S0140525X20001685;,citation_issn=0140-525X, 1469-1825;,citation_volume=45;,citation_language=en-US;,citation_journal_title=Behavioral and Brain Sciences;">
<meta name="citation_reference" content="citation_title=Replies to commentaries on the generalizability crisis;,citation_abstract=Abstract The 38 commentaries on the target article span a broad range of disciplines and perspectives. I have organized my response to the commentaries around three broad questions: First, how serious are the problems discussed in the target article? Second, are there are other, potentially more productive, ways to think about the issues that the target article framed in terms of generalizability? And third, what, if anything, should we collectively do about these problems?;,citation_author=Tal Yarkoni;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_doi=10.1017/S0140525X21001758;,citation_issn=0140-525X, 1469-1825;,citation_volume=45;,citation_language=en-US;,citation_journal_title=Behavioral and Brain Sciences;">
<meta name="citation_reference" content="citation_title=Effect Sizes and Power Analysis in HCI;,citation_abstract=Null hypothesis significance testing (NHST) is a common statistical analysis method in HCI. But its usage and interpretation are often misunderstood. In particular, NHST does not offer the magnitude of differences observed, which is more desirable to determine the effect of comparative studies than the p value. Effect sizes and power analysis can mitigate over-reliance on the p value, and offer researchers better informed preparation and interpretation on experiments. Many research fields now require authors to include effect sizes in NHST results, and this trend is expected to be more and more common. In this chapter, I first discuss common misunderstandings of NHST and p value, and how effect sizes can complement them. I then present methods for calculating effect sizes with examples. I also describe another closely related topic, power analysis. Power analysis can be useful for appropriately designing experiments though it is not frequently used in HCI. I present power analysis methods and discuss how they should and should not be used.;,citation_author=Koji Yatani;,citation_editor=Judy Robertson;,citation_editor=Maurits Kaptein;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_doi=10.1007/978-3-319-26633-6_5;,citation_isbn=978-3-319-26631-2 978-3-319-26633-6;,citation_language=en-US;,citation_inbook_title=Modern Statistical Methods for HCI;">
<meta name="citation_reference" content="citation_title=Pass.lme: Power and Sample Size for Linear Mixed Effect Models;,citation_abstract=Power and sample size calculation for testing fixed effect coefficients in multilevel linear mixed effect models with one or more than one independent populations. Laird, Nan M. and Ware, James H. (1982) $&amp;amp;amp;lt;$doi:10.2307/2529876$&amp;gt;$.;,citation_author=Marco Yu;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_doi=10.32614/CRAN.package.pass.lme;,citation_language=en-US;,citation_publisher=Comprehensive R Archive Network;">
<meta name="citation_reference" content="citation_title=Beyond t test and ANOVA: Applications of mixed-effects models for more rigorous statistical analysis in neuroscience research;,citation_abstract=In basic neuroscience research, data are often clustered or collected with repeated measures, hence correlated. The most widely used methods such as t test and ANOVA do not take data dependence into account and thus are often misused. This Primer introduces linear and generalized mixed-effects models that consider data dependence and provides clear instruction on how to recognize when they are needed and how to apply them. The appropriate use of mixed-effects models will help researchers improve their experimental design and will lead to data analyses with greater validity and higher reproducibility of the experimental findings.;,citation_author=Zhaoxia Yu;,citation_author=Michele Guindani;,citation_author=Steven F. Grieco;,citation_author=Lujia Chen;,citation_author=Todd C. Holmes;,citation_author=Xiangmin Xu;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=1;,citation_doi=10.1016/j.neuron.2021.10.030;,citation_issn=0896-6273;,citation_volume=110;,citation_journal_title=Neuron;">
<meta name="citation_reference" content="citation_title=Practical statistical power analysis using Webpower and R;,citation_author=Zhiyong Zhang;,citation_author=Ke-Hai Yuan;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.35566/power;,citation_isbn=978-1-946728-02-9;">
<meta name="citation_reference" content="citation_title=Sample size planning for complex study designs: A tutorial for the mlpwr package;,citation_abstract=Abstract A common challenge in designing empirical studies is determining an appropriate sample size. When more complex models are used, estimates of power can only be obtained using Monte Carlo simulations. In this tutorial, we introduce the R package to perform simulation-based power analysis based on surrogate modeling. Surrogate modeling is a powerful tool in guiding the search for study design parameters that imply a desired power or meet a cost threshold (e.g., in terms of monetary cost). can be used to search for the optimal allocation when there are multiple design parameters, e.g., when balancing the number of participants and the number of groups in multilevel modeling. At the same time, the approach can take into account the cost of each design parameter, and aims to find a cost-efficient design. We introduce the basic functionality of the package, which can be applied to a wide range of statistical models and study designs. Additionally, we provide two examples based on empirical studies for illustration: one for sample size planning when using an item response theory model, and one for assigning the number of participants and the number of countries for a study using multilevel modeling.;,citation_author=Felix Zimmer;,citation_author=Mirka Henninger;,citation_author=Rudolf Debelak;,citation_publication_date=2023-11;,citation_cover_date=2023-11;,citation_year=2023;,citation_doi=10.3758/s13428-023-02269-0;,citation_issn=1554-3528;,citation_language=en-US;,citation_journal_title=Behavior Research Methods;">
<meta name="citation_reference" content="citation_title=R: A language and environment for statistical computing;,citation_author=R Core Team;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://www.R-project.org/;">
<meta name="citation_reference" content="citation_title=Binom: Binomial confidence intervals for several parameterizations;,citation_author=Sundar Dorai-Raj;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=binom;">
<meta name="citation_reference" content="citation_title=Dplyr: A grammar of data manipulation;,citation_author=Hadley Wickham;,citation_author=Romain François;,citation_author=Lionel Henry;,citation_author=Kirill Müller;,citation_author=Davis Vaughan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=dplyr;">
<meta name="citation_reference" content="citation_title=Faux: Simulation for factorial designs;,citation_author=Lisa DeBruine;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://debruine.github.io/faux/;,citation_doi=10.5281/zenodo.2669586;">
<meta name="citation_reference" content="citation_title=Forcats: Tools for working with categorical variables (factors);,citation_author=Hadley Wickham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://forcats.tidyverse.org/;">
<meta name="citation_reference" content="citation_title=Furrr: Apply mapping functions in parallel using futures;,citation_author=Davis Vaughan;,citation_author=Matt Dancho;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=furrr;">
<meta name="citation_reference" content="citation_title=A unifying framework for parallel and distributed processing in r using futures;,citation_author=Henrik Bengtsson;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://doi.org/10.32614/RJ-2021-048;,citation_issue=2;,citation_doi=10.32614/RJ-2021-048;,citation_volume=13;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=ggplot2: Elegant graphics for data analysis;,citation_author=Hadley Wickham;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=https://ggplot2.tidyverse.org;,citation_isbn=978-3-319-24277-4;">
<meta name="citation_reference" content="citation_title=Fitting linear mixed-effects models using lme4;,citation_author=Douglas Bates;,citation_author=Martin Mächler;,citation_author=Ben Bolker;,citation_author=Steve Walker;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=1;,citation_doi=10.18637/jss.v067.i01;,citation_volume=67;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Dates and times made easy with lubridate;,citation_author=Garrett Grolemund;,citation_author=Hadley Wickham;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://www.jstatsoft.org/v40/i03/;,citation_issue=3;,citation_volume=40;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=How to interpret statistical models using marginaleffects in R and Python;,citation_author=Vincent Arel-Bundock;,citation_author=Noah Greifer;,citation_author=Andrew Heiss;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Modern applied statistics with s;,citation_author=W. N. Venables;,citation_author=B. D. Ripley;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://www.stats.ox.ac.uk/pub/MASS4/;">
<meta name="citation_reference" content="citation_title=Matrix: Sparse and dense matrix classes and methods;,citation_author=Douglas Bates;,citation_author=Martin Maechler;,citation_author=Mikael Jagan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=Matrix;">
<meta name="citation_reference" content="citation_title=Simultaneous inference in general parametric models;,citation_author=Torsten Hothorn;,citation_author=Frank Bretz;,citation_author=Peter Westfall;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=50;,citation_journal_title=Biometrical Journal;">
<meta name="citation_reference" content="citation_title=Computation of multivariate normal and t probabilities;,citation_author=Alan Genz;,citation_author=Frank Bretz;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_isbn=978-3-642-01688-2;,citation_series_title=Lecture notes in statistics;">
<meta name="citation_reference" content="citation_title=papaja: Prepare reproducible APA journal articles with R Markdown;,citation_author=Frederik Aust;,citation_author=Marius Barth;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://github.com/crsh/papaja;">
<meta name="citation_reference" content="citation_title=Purrr: Functional programming tools;,citation_author=Hadley Wickham;,citation_author=Lionel Henry;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=purrr;">
<meta name="citation_reference" content="citation_title=Pwr: Basic functions for power analysis;,citation_author=Stephane Champely;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://github.com/heliosdrm/pwr;">
<meta name="citation_reference" content="citation_title=Readr: Read rectangular text data;,citation_author=Hadley Wickham;,citation_author=Jim Hester;,citation_author=Jennifer Bryan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://readr.tidyverse.org;">
<meta name="citation_reference" content="citation_title=Stringr: Simple, consistent wrappers for common string operations;,citation_author=Hadley Wickham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=stringr;">
<meta name="citation_reference" content="citation_title=Modeling survival data: Extending the Cox model;,citation_author=Terry M. Therneau;,citation_author=Patricia M. Grambsch;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_isbn=0-387-98784-3;">
<meta name="citation_reference" content="citation_title=TH.data: TH’s data archive;,citation_author=Torsten Hothorn;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=TH.data;">
<meta name="citation_reference" content="citation_title=Tibble: Simple data frames;,citation_author=Kirill Müller;,citation_author=Hadley Wickham;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=tibble;">
<meta name="citation_reference" content="citation_title=Tidyr: Tidy messy data;,citation_author=Hadley Wickham;,citation_author=Davis Vaughan;,citation_author=Maximilian Girlich;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=tidyr;">
<meta name="citation_reference" content="citation_title=Welcome to the tidyverse;,citation_author=Hadley Wickham;,citation_author=Mara Averick;,citation_author=Jennifer Bryan;,citation_author=Winston Chang;,citation_author=Lucy D’Agostino McGowan;,citation_author=Romain François;,citation_author=Garrett Grolemund;,citation_author=Alex Hayes;,citation_author=Lionel Henry;,citation_author=Jim Hester;,citation_author=Max Kuhn;,citation_author=Thomas Lin Pedersen;,citation_author=Evan Miller;,citation_author=Stephan Milton Bache;,citation_author=Kirill Müller;,citation_author=Jeroen Ooms;,citation_author=David Robinson;,citation_author=Dana Paige Seidel;,citation_author=Vitalie Spinu;,citation_author=Kohske Takahashi;,citation_author=Davis Vaughan;,citation_author=Claus Wilke;,citation_author=Kara Woo;,citation_author=Hiroaki Yutani;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=43;,citation_doi=10.21105/joss.01686;,citation_volume=4;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=tinylabels: Lightweight variable labels;,citation_author=Marius Barth;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://cran.r-project.org/package=tinylabels;">
<meta name="citation_reference" content="citation_title=Tinytable: Simple and configurable tables in ’HTML’, ’LaTeX’, ’markdown’, ’word’, ’PNG’, ’PDF’, and ’typst’ formats;,citation_author=Vincent Arel-Bundock;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://vincentarelbundock.github.io/tinytable/;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A Tutorial on Tailored Simulation-Based Sample-Size Planning for Experimental Designs with Generalized Linear Mixed Models</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliations</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Florian Pargent <a href="https://orcid.org/0000-0002-2388-553X" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        LMU Munich
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Timo K. Koch <a href="mailto:timo.koch@unisg.ch" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0001-6728-2063" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        LMU Munich
                      </p>
                    <p class="affiliation">
                        University of St.&nbsp;Gallen
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Anne-Kathrin Kleine <a href="https://orcid.org/0000-0003-1919-2834" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        LMU Munich
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Eva Lermer <a href="https://orcid.org/0000-0002-6600-9580" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        LMU Munich
                      </p>
                    <p class="affiliation">
                        Technical University of Applied Sciences Augsburg
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Susanne Gaube <a href="https://orcid.org/0000-0002-1633-4772" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        LMU Munich
                      </p>
                    <p class="affiliation">
                        University College London
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">2024-07-01</p>
            </div>
          </div>
          
                <div>
            <div class="quarto-title-meta-heading">Modified</div>
            <div class="quarto-title-meta-contents">
              <p class="date-modified">2024-11-06</p>
            </div>
          </div>
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="manuscript.pdf"><i class="bi bi-file-pdf"></i>PDF (apaquarto)</a></p></div><div class="quarto-title-meta-contents"><p><a href="manuscript.docx"><i class="bi bi-file-word"></i>MS Word (apaquarto)</a></p></div><div class="quarto-title-meta-contents"><p><a href="bundle.zip" data-meca-link="true"><i class="bi bi-archive"></i>MECA Bundle</a></p></div></div></div>
    </div>

    <div>
      <div class="abstract">
        <div class="block-title">Abstract</div>
        When planning experimental research, determining an appropriate sample size and using suitable statistical models are crucial for robust and informative results. The recent replication crisis underlines the need for more rigorous statistical methodology and adequately powered designs. Generalized linear mixed models (GLMMs) offer a flexible statistical framework to analyze experimental data with complex (e.g., dependent and hierarchical) data structures. However, available methods and software for a priori sample size planning for GLMMs are often limited to specific designs. Tailored data simulation approaches offer a more flexible alternative. Based on a practical case study where we focus on a binomial GLMM with two random intercepts and discrete predictor variables, the current tutorial equips researchers with a step-by-step guide and corresponding code for conducting tailored a priori sample size planning with GLMMs. We not only focus on power analysis but also explain how to use the precision of parameter estimates to determine appropriate sample sizes. We conclude with an outlook on the increasing importance of simulation-based sample size planning.
      </div>
    </div>

    <div>
      <div class="keywords">
        <div class="block-title">Keywords</div>
        <p>tutorial, sample size planning, generalized linear mixed model, power analysis, precision, data simulation</p>
      </div>
    </div>

    <div class="quarto-other-links-text-target">
    <div class="quarto-code-links"><div class="quarto-title-meta-heading">Code Links</div><div class="quarto-title-meta-contents"><span style="padding-right: 0.5em;"><a href="https://mybinder.org/v2/gh/Timo-Ko/glmm_simulation_tutorial/HEAD?urlpath=rstudio" target="_blank"><i class="bi bi-journals"></i>Launch Binder</a>,</span><span><a href="https://github.com/Timo-Ko/glmm_simulation_tutorial/" target="_blank"><i class="bi bi-github"></i>GitHub Repo</a></span></div></div></div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#theoretical-background" id="toc-theoretical-background" class="nav-link" data-scroll-target="#theoretical-background">Theoretical background</a>
  <ul class="collapse">
  <li><a href="#planning-for-statistical-power-or-precision" id="toc-planning-for-statistical-power-or-precision" class="nav-link" data-scroll-target="#planning-for-statistical-power-or-precision">Planning for statistical power or precision</a></li>
  <li><a href="#generalized-linear-mixed-models-glmms" id="toc-generalized-linear-mixed-models-glmms" class="nav-link" data-scroll-target="#generalized-linear-mixed-models-glmms">Generalized linear mixed models (GLMMs)</a></li>
  </ul></li>
  <li><a href="#simulation-based-sample-size-planning-with-glmms" id="toc-simulation-based-sample-size-planning-with-glmms" class="nav-link" data-scroll-target="#simulation-based-sample-size-planning-with-glmms">Simulation-based sample size planning with GLMMs</a></li>
  <li><a href="#reasons-to-use-tailored-data-simulation" id="toc-reasons-to-use-tailored-data-simulation" class="nav-link" data-scroll-target="#reasons-to-use-tailored-data-simulation">Reasons to use tailored data simulation</a></li>
  <li><a href="#general-steps-in-tailored-simulation-based-sample-size-planning" id="toc-general-steps-in-tailored-simulation-based-sample-size-planning" class="nav-link" data-scroll-target="#general-steps-in-tailored-simulation-based-sample-size-planning">General steps in tailored simulation-based sample size planning</a>
  <ul class="collapse">
  <li><a href="#step-1-define-the-estimand" id="toc-step-1-define-the-estimand" class="nav-link" data-scroll-target="#step-1-define-the-estimand">Step 1: Define the estimand</a>
  <ul class="collapse">
  <li><a href="#theory" id="toc-theory" class="nav-link" data-scroll-target="#theory">THEORY</a></li>
  <li><a href="#practice" id="toc-practice" class="nav-link" data-scroll-target="#practice">PRACTICE</a></li>
  </ul></li>
  <li><a href="#step-2-simulate-the-data-generating-process" id="toc-step-2-simulate-the-data-generating-process" class="nav-link" data-scroll-target="#step-2-simulate-the-data-generating-process">Step 2: Simulate the data-generating process</a>
  <ul class="collapse">
  <li><a href="#theory-1" id="toc-theory-1" class="nav-link" data-scroll-target="#theory-1">THEORY</a></li>
  <li><a href="#practice-1" id="toc-practice-1" class="nav-link" data-scroll-target="#practice-1">PRACTICE</a></li>
  </ul></li>
  <li><a href="#step-3-specify-the-population-parameters" id="toc-step-3-specify-the-population-parameters" class="nav-link" data-scroll-target="#step-3-specify-the-population-parameters">Step 3: Specify the population parameters</a>
  <ul class="collapse">
  <li><a href="#theory-2" id="toc-theory-2" class="nav-link" data-scroll-target="#theory-2">THEORY</a></li>
  <li><a href="#practice-2" id="toc-practice-2" class="nav-link" data-scroll-target="#practice-2">PRACTICE</a></li>
  <li><a href="#examine-insightful-descriptive-statistics" id="toc-examine-insightful-descriptive-statistics" class="nav-link" data-scroll-target="#examine-insightful-descriptive-statistics">Examine insightful descriptive statistics</a></li>
  <li><a href="#theory-3" id="toc-theory-3" class="nav-link" data-scroll-target="#theory-3">THEORY</a></li>
  <li><a href="#practice-3" id="toc-practice-3" class="nav-link" data-scroll-target="#practice-3">PRACTICE</a></li>
  <li><a href="#examine-insightful-model-based-quantities" id="toc-examine-insightful-model-based-quantities" class="nav-link" data-scroll-target="#examine-insightful-model-based-quantities">Examine insightful model-based quantities</a></li>
  <li><a href="#theory-4" id="toc-theory-4" class="nav-link" data-scroll-target="#theory-4">THEORY</a></li>
  <li><a href="#practice-4" id="toc-practice-4" class="nav-link" data-scroll-target="#practice-4">PRACTICE</a></li>
  <li><a href="#iterate-with-domain-expertise" id="toc-iterate-with-domain-expertise" class="nav-link" data-scroll-target="#iterate-with-domain-expertise">Iterate with domain expertise</a></li>
  <li><a href="#theory-5" id="toc-theory-5" class="nav-link" data-scroll-target="#theory-5">THEORY</a></li>
  <li><a href="#practice-5" id="toc-practice-5" class="nav-link" data-scroll-target="#practice-5">PRACTICE</a></li>
  </ul></li>
  <li><a href="#step-4-estimate-the-statistical-model" id="toc-step-4-estimate-the-statistical-model" class="nav-link" data-scroll-target="#step-4-estimate-the-statistical-model">Step 4: Estimate the statistical model</a>
  <ul class="collapse">
  <li><a href="#theory-6" id="toc-theory-6" class="nav-link" data-scroll-target="#theory-6">THEORY</a></li>
  <li><a href="#practice-6" id="toc-practice-6" class="nav-link" data-scroll-target="#practice-6">PRACTICE</a></li>
  </ul></li>
  <li><a href="#step-5-compute-the-estimate" id="toc-step-5-compute-the-estimate" class="nav-link" data-scroll-target="#step-5-compute-the-estimate">Step 5: Compute the estimate</a>
  <ul class="collapse">
  <li><a href="#theory-7" id="toc-theory-7" class="nav-link" data-scroll-target="#theory-7">THEORY</a></li>
  <li><a href="#practice-7" id="toc-practice-7" class="nav-link" data-scroll-target="#practice-7">PRACTICE</a></li>
  </ul></li>
  <li><a href="#step-6-perform-repeated-simulations" id="toc-step-6-perform-repeated-simulations" class="nav-link" data-scroll-target="#step-6-perform-repeated-simulations">Step 6: Perform repeated simulations</a>
  <ul class="collapse">
  <li><a href="#theory-8" id="toc-theory-8" class="nav-link" data-scroll-target="#theory-8">THEORY</a></li>
  <li><a href="#practice-8" id="toc-practice-8" class="nav-link" data-scroll-target="#practice-8">PRACTICE</a></li>
  </ul></li>
  <li><a href="#step-7-optional-conduct-sensitivity-analysis" id="toc-step-7-optional-conduct-sensitivity-analysis" class="nav-link" data-scroll-target="#step-7-optional-conduct-sensitivity-analysis">Step 7 (optional): Conduct sensitivity analysis</a></li>
  </ul></li>
  <li><a href="#conclusion-and-outlook" id="toc-conclusion-and-outlook" class="nav-link" data-scroll-target="#conclusion-and-outlook">Conclusion and outlook</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="manuscript-preview.html"><i class="bi bi-journal-code"></i>Article Notebook</a></li><li><a href="rcode-preview.html"><i class="bi bi-journal-code"></i>R code from PRACTICE sections</a></li><li><a href="full_simulation-preview.html"><i class="bi bi-journal-code"></i>Run simulation for case study</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>This manuscript has been accepted by the journal <em>Advances in Methods and Practices in Psychological Science (AMPPS)</em>. Please cite the official version of record as:</p>
<p>Pargent, F., K. Koch, T., Kleine, A.-K., Lermer, E., &amp; Gaube, S. (2024). A tutorial on tailored simulation-based sample-size planning for experimental designs with generalized linear mixed models. <em>Advances in Methods and Practices in Psychological Science</em>, 7(4). <a href="https://doi.org/10.1177/25152459241287132" class="uri">https://doi.org/10.1177/25152459241287132</a></p>
</div>
</div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>When planning experimental research, it is essential to determine an appropriate sample size and use appropriate statistical models to analyze the data to ensure that the results are robust and informative <span class="citation" data-cites="lakensSampleSizeJustification2022">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>. The recent replication crisis in Psychology and other disciplines has illustrated many challenges surrounding the reproducibility and reliability of study findings <span class="citation" data-cites="yarkoniGeneralizabilityCrisis2022">(<a href="#ref-yarkoniGeneralizabilityCrisis2022" role="doc-biblioref">Yarkoni, 2022</a>)</span>. As a result, there is a growing need for more rigorous statistical methodology and the adoption of adequately powered experimental designs. Multiple easy-to-use software solutions exist for simple statistical models and experimental designs <span class="citation" data-cites="R-pwr lakensSimulationBasedPowerAnalysis2021">(<a href="#ref-R-pwr" role="doc-biblioref">Champely, 2020</a>; <a href="#ref-lakensSimulationBasedPowerAnalysis2021" role="doc-biblioref">Lakens &amp; Caldwell, 2021</a>)</span>. A priori sample size planning for more complex research designs such as flexible generalized linear mixed models (GLMM) is not covered by standard software solutions. Researchers willing to use this framework will need to use data simulation. In the present work, we provide a tutorial on how to determine adequate sample sizes by performing tailored simulation-based sample size planning for GLMMs. After introducing some theoretical background on sample size planning, we review existing software solutions in R and discuss under which circumstances tailored data simulations are necessary. We proceed by describing the relevant steps and decisions involved in tailored data simulation, illustrated in a case study where we focus on a binomial GLMM with two random intercepts and discrete predictor variables.</p>
<!-- # Recommended background knowledge -->
<p>To benefit most of this tutorial paper, we recommend readers to familiarize themselves with basic statistical concepts like hypothesis tests (HTs) and their statistical power as well as confidence intervals (CIs) and their precision <span class="citation" data-cites="lakensImprovingYourStatistical2022 riesthuisSimulationBasedPowerAnalyses2024 kumleEstimatingPowerGeneralized2021">(<a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">Kumle et al., 2021</a>; <a href="#ref-lakensImprovingYourStatistical2022" role="doc-biblioref">Lakens, 2022b</a>; <a href="#ref-riesthuisSimulationBasedPowerAnalyses2024" role="doc-biblioref">Riesthuis, 2024</a>)</span>. Some knowledge of causal inference is beneficial but not necessary <span class="citation" data-cites="lundbergWhatYourEstimand2021 deffnerCausalFrameworkCrossCultural2022">(<a href="#ref-deffnerCausalFrameworkCrossCultural2022" role="doc-biblioref">Deffner et al., 2022</a>; <a href="#ref-lundbergWhatYourEstimand2021" role="doc-biblioref">Lundberg et al., 2021</a>)</span>. In addition, readers should have an understanding of how to conduct statistical analyses with R <span class="citation" data-cites="wickhamDataScienceImport2023">(<a href="#ref-wickhamDataScienceImport2023" role="doc-biblioref">Wickham et al., 2023</a>)</span> and how to simulate data <span class="citation" data-cites="debruineUnderstandingMixedEffectsModels2021 hallgrenConductingSimulationStudies2013 leeUsingTidyversePackage2020">(<a href="#ref-debruineUnderstandingMixedEffectsModels2021" role="doc-biblioref">DeBruine &amp; Barr, 2021</a>; <a href="#ref-hallgrenConductingSimulationStudies2013" role="doc-biblioref">Hallgren, 2013</a>; <a href="#ref-leeUsingTidyversePackage2020" role="doc-biblioref">Lee et al., 2020</a>)</span>. For data simulation, we use functions from the <em>tidyverse</em> <span class="citation" data-cites="wickhamWelcomeTidyverse2019">(<a href="#ref-wickhamWelcomeTidyverse2019" role="doc-biblioref">Wickham et al., 2019</a>)</span> and the <em>faux</em> package <span class="citation" data-cites="R-faux">(<a href="#ref-R-faux" role="doc-biblioref">DeBruine, 2023</a>)</span>. Finally, readers should have a basic understanding of regression modeling and GLMMs <span class="citation" data-cites="brownIntroductionLinearMixedEffects2021">(<a href="#ref-brownIntroductionLinearMixedEffects2021" role="doc-biblioref">Brown, 2021</a>)</span>. In this tutorial, we simulate data by manually specifying the model equation of a GLMM that represents our assumed data-generating process <span class="citation" data-cites="debruineUnderstandingMixedEffectsModels2021">(<a href="#ref-debruineUnderstandingMixedEffectsModels2021" role="doc-biblioref">DeBruine &amp; Barr, 2021</a>)</span>. It is not necessary to understand the technical details of how GLMMs are estimated. However, it is crucial to understand the structure of a basic GLMM (e.g., logistic regression with random intercepts) and how the model assumes that the dependent variable’s values are determined by the predictor variables and the random effects.</p>
</section>
<section id="theoretical-background" class="level1">
<h1>Theoretical background</h1>
<section id="planning-for-statistical-power-or-precision" class="level2">
<h2 class="anchored" data-anchor-id="planning-for-statistical-power-or-precision">Planning for statistical power or precision</h2>
<p>Conducting research with insufficiently large sample sizes can have many negative consequences <span class="citation" data-cites="buttonPowerFailureWhy2013">(<a href="#ref-buttonPowerFailureWhy2013" role="doc-biblioref">Button et al., 2013</a>)</span>. First, experiments may yield inconclusive or misleading results, hindering the accumulation of knowledge. Second, studies that are doomed never to find a postulated effect waste resources by consuming time, effort, and funding. For these reasons, many journals and funding bodies now require a sample size justification in study protocols and grant proposals, recognizing its relevance in ensuring robust and meaningful findings. While sample sizes can be justified with resource constraints or general heuristics, statistical arguments based on power or precision are the gold standard <span class="citation" data-cites="lakensSampleSizeJustification2022">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>.</p>
<p>Most empirical studies in psychology and other social sciences apply hypothesis testing. Consequently, the dominant approach for determining an adequate sample size is based on power analysis (i.e., planning for power) <span class="citation" data-cites="lakensSampleSizeJustification2022 maxwellSampleSizePlanning2008">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>; <a href="#ref-maxwellSampleSizePlanning2008" role="doc-biblioref">Maxwell et al., 2008</a>)</span>. Statistical power is defined as the probability that a HT has a significant p-value when analyzing repeated samples from a population with a true effect of some pre-specified size <span class="citation" data-cites="cohenPowerPrimer1992">(<a href="#ref-cohenPowerPrimer1992" role="doc-biblioref">Cohen, 1992</a>)</span>. Less formally, power is described as the probability that a HT correctly rejects the null hypothesis when the alternative hypothesis is true. If the sample size (i.e., the number of participants and/or stimuli) is insufficient to detect the effects or relationships being investigated with high probability, the study is considered “underpowered”. When planning for power, a target is set for the statistical power of a HT of interest. Assuming an effect size of interest and a desired significance level, a minimum sample size can be determined that, on average, would guarantee reaching this target. The most prominent heuristic is to target a power of <span class="math inline">\(1- \beta = 0.8\)</span> in combination with a type I error rate of <span class="math inline">\(\alpha = 0.05\)</span> <span class="citation" data-cites="lakensSampleSizeJustification2022">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>. However, depending on the research goals or resource constraints, there are often good reasons to move away from this standard <span class="citation" data-cites="benjaminRedefineStatisticalSignificance2017 lakensJustifyYourAlpha2018">(<a href="#ref-benjaminRedefineStatisticalSignificance2017" role="doc-biblioref">Benjamin et al., 2017</a>; <a href="#ref-lakensJustifyYourAlpha2018" role="doc-biblioref">Lakens, Adolfi, et al., 2018</a>)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>In contrast to power analysis, sample size planning can also be based on the precision of parameter estimates (i.e., planning for precision or planning for accuracy) <span class="citation" data-cites="lakensSampleSizeJustification2022 maxwellSampleSizePlanning2008">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>; <a href="#ref-maxwellSampleSizePlanning2008" role="doc-biblioref">Maxwell et al., 2008</a>)</span>. Not all research questions are best answered by hypothesis testing. It has been argued that basic research rarely requires discrete decisions on whether some effect has been “discovered” and should thus shift from hypothesis testing towards an estimation framework <span class="citation" data-cites="mcelreathStatisticalRethinkingBayesian2020 cummingNewStatisticsWhy2014 kruschkeBayesianNewStatistics2018">(<a href="#ref-cummingNewStatisticsWhy2014" role="doc-biblioref">Cumming, 2014</a>; <a href="#ref-kruschkeBayesianNewStatistics2018" role="doc-biblioref">Kruschke &amp; Liddell, 2018</a>; <a href="#ref-mcelreathStatisticalRethinkingBayesian2020" role="doc-biblioref">McElreath, 2020</a>)</span>, although this view is not without critique <span class="citation" data-cites="uyguntuncEpistemicPragmaticFunction2023">(<a href="#ref-uyguntuncEpistemicPragmaticFunction2023" role="doc-biblioref">Uygun Tunç et al., 2023</a>)</span>. When no HTs are conducted, power analysis is not relevant for sample size planning. In the precision framework, the target quantity commonly used for sample size planning is the expected width of a CI <span class="citation" data-cites="kelleySampleSizePlanning2006 lakensSampleSizeJustification2022 maxwellSampleSizePlanning2008">(<a href="#ref-kelleySampleSizePlanning2006" role="doc-biblioref">Kelley &amp; Rausch, 2006</a>; <a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>; <a href="#ref-maxwellSampleSizePlanning2008" role="doc-biblioref">Maxwell et al., 2008</a>)</span>. A CI with a confidence level of 0.95 provides the smallest interval with the property that 95% of individual CIs would include the true quantity of interest upon repeated sampling. Thus, a narrow CI with fewer plausible values for the quantity of interest is more informative about the size of the true effect than a wide CI. Apart from the confidence level, the width of a CI depends on the sample size. Because bigger samples carry more information, they lead to smaller CIs. When planning for precision, a target can be set for the expected width of a CI of interest. Assuming some effect size of interest and a certain confidence level, a minimum sample size can be determined that would guarantee reaching the targeted expected width. Because planning for precision is still rare, there are no common heuristics for choosing the desired width of the CI <span class="citation" data-cites="lakensSampleSizeJustification2022">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>.</p>
</section>
<section id="generalized-linear-mixed-models-glmms" class="level2">
<h2 class="anchored" data-anchor-id="generalized-linear-mixed-models-glmms">Generalized linear mixed models (GLMMs)</h2>
<p>As study designs become more complex, psychological researchers require more sophisticated statistical models to capture their nuanced relationships and grouping structures <span class="citation" data-cites="yarkoniGeneralizabilityCrisis2022">(<a href="#ref-yarkoniGeneralizabilityCrisis2022" role="doc-biblioref">Yarkoni, 2022</a>)</span>. GLMMs (also called multilevel models) are gaining popularity because they offer great flexibility when applied carefully <span class="citation" data-cites="brownIntroductionLinearMixedEffects2021 matuschekBalancingTypeError2017 meteyardBestPracticeGuidance2020a">(<a href="#ref-brownIntroductionLinearMixedEffects2021" role="doc-biblioref">Brown, 2021</a>; <a href="#ref-matuschekBalancingTypeError2017" role="doc-biblioref">Matuschek et al., 2017</a>; <a href="#ref-meteyardBestPracticeGuidance2020a" role="doc-biblioref">Meteyard &amp; Davies, 2020</a>)</span>. GLMMs are an extension of LMMs (Linear Mixed Models), which are, in turn, extensions of linear regression models that account for correlated data, including hierarchical structures <span class="citation" data-cites="fahrmeirRegressionModelsMethods2021 bolkerLinearGeneralizedLinear2015">(<a href="#ref-bolkerLinearGeneralizedLinear2015" role="doc-biblioref">Bolker, 2015</a>; <a href="#ref-fahrmeirRegressionModelsMethods2021" role="doc-biblioref">Fahrmeir et al., 2021</a>)</span>. In this context, correlated data means that the value in the outcome variable for one observation may be related to the value of another observation in a systematic way that is not already accounted for by the usual (fixed) predictor variables (e.g., the age of participants). This correlation can arise for various reasons: For instance, responses to some stimuli from some participants might be more similar because the same person was measured multiple times (repeated measurements), participants belong to the same group (clustering), or participants responded to the same stimulus (stimulus effects). Thus, modeling such correlations is important whenever the data has a clear structure, while the grouping variables can be hierarchically nested (e.g., grouping variables students and schools: each student belongs to exactly one school) or cross-classified (e.g., grouping variables students and math exercises: each student is presented with several math exercises). LMMs are used when the outcome variable is continuous and follows a normal distribution (after conditioning on all predictor variables). They allow for the modeling of fixed effects, which capture the relationships between the usual predictors and the outcome, as well as random effects, which account for the different types of correlation structure and grouping effects. Random effects are typically assumed to follow a normal distribution with a mean of zero and a variance that quantifies the heterogeneity across groups. Correlated random effects can be assumed in models that contain both random intercepts and random slopes. GLMMs extend the LMM framework to accommodate non-normally distributed continuous and categorical outcome variables. GLMMs involve a link function that connects the linear combination of predictor variables to the expected value of the outcome variable. The link function allows for modeling the relationship between predictors and the outcome in a non-linear way that is appropriate for the specific distribution family of the outcome variable.</p>
<!-- For example, think of an experiment with different design factors (e.g., picture positions, headline aesthetics) impacting the likelihood of users clicking on an online advertisement. The participants’ behavior is measured repeatedly over several sessions. The click patterns of participants in one session are likely to be correlated with their previous sessions, and the outcome variable is binary (click/no click) for each session, which follows a binomial distribution. -->
</section>
</section>
<section id="simulation-based-sample-size-planning-with-glmms" class="level1">
<h1>Simulation-based sample size planning with GLMMs</h1>
<!-- For less complex statistical models, like t-tests, ANOVA, and linear regression, with common study designs (e.g., mean comparison between two groups), user-friendly software for a priori sample size planning is readily available [@faulStatisticalPowerAnalyses2009; @champelyPackagePwr2018; @kelleyObtainingPowerObtaining2003; @kelleySampleSizePlanning2006].  -->
<!-- However, these software packages are often not flexible enough to perform sample size planning for complex designs. -->
<p>To our knowledge, existing approaches for sample size planning for GLMMs have exclusively focused on planning for power. In Table 1, we review available software packages that can be used to perform power analysis for multilevel models in R [Version 4.3.3; <span class="citation" data-cites="R-base">R Core Team (<a href="#ref-R-base" role="doc-biblioref">2024</a>)</span>]. Power analysis methods can be categorized into formula-based, summary-statistics-based and simulation-based methods <span class="citation" data-cites="murayamaSummarystatisticsbasedPowerAnalysis2022">(<a href="#ref-murayamaSummarystatisticsbasedPowerAnalysis2022" role="doc-biblioref">Murayama et al., 2022</a>)</span>. Formula-based methods rely on exact formulas to calculate power directly. Summary-statistics-based methods use statistical theory to approximate power based on formula-based methods developed for simple t-tests. Simulation-based methods rely on repeatedly simulating data with a known true effect size and estimating power empirically, that is what percentage of simulated datasets produces a significant p-value. Available formula-based and summary-statistics-based software packages for multilevel models often do not include GLMMs or are limited to simple designs <span class="citation" data-cites="westfallStatisticalPowerOptimal2014 murayamaSummarystatisticsbasedPowerAnalysis2022">(<a href="#ref-murayamaSummarystatisticsbasedPowerAnalysis2022" role="doc-biblioref">Murayama et al., 2022</a>; <a href="#ref-westfallStatisticalPowerOptimal2014" role="doc-biblioref">Westfall et al., 2014</a>)</span>, making it necessary to build data simulations tailored specifically to the study design. A number of tutorials have been published describing how to perform such simulation-based power analysis for multilevel models <span class="citation" data-cites="arendStatisticalPowerTwolevel2019 lafitSelectionNumberParticipants2021 zimmerSampleSizePlanning2023 brysbaertPowerAnalysisEffect2018 kumleEstimatingPowerGeneralized2021 debruineUnderstandingMixedEffectsModels2021 kainPracticalGuidePower2015 greenSIMRPackagePower2016 johnsonPowerAnalysisGeneralized2015">(<a href="#ref-arendStatisticalPowerTwolevel2019" role="doc-biblioref">Arend &amp; Schäfer, 2019</a>; <a href="#ref-brysbaertPowerAnalysisEffect2018" role="doc-biblioref">Brysbaert &amp; Stevens, 2018</a>; <a href="#ref-debruineUnderstandingMixedEffectsModels2021" role="doc-biblioref">DeBruine &amp; Barr, 2021</a>; <a href="#ref-greenSIMRPackagePower2016" role="doc-biblioref">Green &amp; MacLeod, 2016</a>; <a href="#ref-johnsonPowerAnalysisGeneralized2015" role="doc-biblioref">Johnson et al., 2015</a>; <a href="#ref-kainPracticalGuidePower2015" role="doc-biblioref">Kain et al., 2015</a>; <a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">Kumle et al., 2021</a>; <a href="#ref-lafitSelectionNumberParticipants2021" role="doc-biblioref">Lafit et al., 2021</a>; <a href="#ref-zimmerSampleSizePlanning2023" role="doc-biblioref">Zimmer et al., 2023</a>)</span>. However, many of these tutorials focus on LMMs and the most common study designs <span class="citation" data-cites="kumleEstimatingPowerGeneralized2021">(see <a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">Kumle et al., 2021</a> for a tutorial that also covers more advanced settings)</span>. This narrow focus provides limited guidance for researchers using more complex study designs, especially when little prior knowledge about plausible effect sizes is available <span class="citation" data-cites="kumleEstimatingPowerGeneralized2021">(see the discussion in <a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">Kumle et al., 2021</a>)</span>. Simulation-based power analysis with GLMMs requires making a range of assumptions about the model structure that should align with the characteristics of the data being analyzed. Existing tutorials often rely on heuristics for specifying variance components (e.g., the standard deviation of random intercepts) or assume that results from meta-analyses or data from pilot studies are available to determine plausible values for all model parameters. However, in practice, knowledge about those parameters from prior studies is often limited, which makes specifying assumptions a practical challenge (see the discussion in <span class="citation" data-cites="maxwellSampleSizePlanning2008">Maxwell et al. (<a href="#ref-maxwellSampleSizePlanning2008" role="doc-biblioref">2008</a>)</span> and <span class="citation" data-cites="kumleEstimatingPowerGeneralized2021">Kumle et al. (<a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">2021</a>)</span>). We will discuss a number of strategies on how to specify model parameters for application-specific, tailored data simulations in a later section.</p>
<div class="cell" data-apa-note="GUI available = whether a graphical user interface is provided (usually a Shiny app that is available online or can be downloaded to run locally), GLMM support = whether power analysis can be performed for generalized linear mixed model (otherwise only linear mixed models are supported), Design limitations = whether only a limited selection of study designs can be specified (otherwise arbitrary designs within the model class are supported).">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-fec3a190{}.cl-febf2b10{font-family:'Times New Roman';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-febf2b24{font-family:'Times New Roman';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 255, 1.00);background-color:transparent;}.cl-fec0c920{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-fec0d4ce{width:1.181in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4d8{width:1.575in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4d9{width:0.591in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4e2{width:0.787in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4e3{width:1.181in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4e4{width:1.575in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4e5{width:0.591in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4ec{width:0.787in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4ed{width:1.181in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4ee{width:1.575in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4f6{width:0.591in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fec0d4f7{width:0.787in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-fec3a190"><caption><p>Table 1. Overview of software packages for power analysis for
(generalized) linear mixed models in R.</p></caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-fec0d4ce"><p class="cl-fec0c920"><span class="cl-febf2b10">Package name</span></p></th><th class="cl-fec0d4d8"><p class="cl-fec0c920"><span class="cl-febf2b10">Summary</span></p></th><th class="cl-fec0d4d9"><p class="cl-fec0c920"><span class="cl-febf2b10">GUI available</span></p></th><th class="cl-fec0d4d9"><p class="cl-fec0c920"><span class="cl-febf2b10">GLMM support</span></p></th><th class="cl-fec0d4ce"><p class="cl-fec0c920"><span class="cl-febf2b10">Design limitations</span></p></th><th class="cl-fec0d4e2"><p class="cl-fec0c920"><span class="cl-febf2b10">Reference</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">glmmrBase</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Formula-</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">and</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">non-linear</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">fixed</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">effects</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">and</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">flexible</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">covariance</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">functions</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">yes</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">none</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Watson</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2023)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">longpower</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Formula-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">focus</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">longitudinal</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">data</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><a href="https://atrihub.shinyapps.io/power/"><span class="cl-febf2b24">yes</span></a></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">set</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">of</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">study</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">designs</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">with</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">two</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">levels</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Iddi</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">&amp;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">Donohue</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2022)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">mixedpower</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">‘</span><span class="cl-febf2b10">lme4</span><span class="cl-febf2b10">’</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">package</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">yes</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">none</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Kumle</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">et</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">al.</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2021)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">mlmpower</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">missing</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">data</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">mechanisms</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">to</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">two</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">levels</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Enders</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">et</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">al.</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2023)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">pamm</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">‘</span><span class="cl-febf2b10">lme4</span><span class="cl-febf2b10">’</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">package</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">none</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Martin</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">et</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">al.</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2011)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">pass.lme</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Formula-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">documentation</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">none</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Yu</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2019)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">PowerAnalysisIL</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">focus</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">longitudinal</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">data</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><a href="https://github.com/ginettelafit/PowerAnalysisIL?tab=readme-ov-file#shiny-app-and-r-package-to-perform-power-analysis-to-select-the-number-of-participants-in-intensive-longitudinal-studies"><span class="cl-febf2b24">yes</span></a></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">set</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">of</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">study</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">designs</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">with</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">two</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">levels</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Lafit</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">et</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">al.</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2021)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">powerlmm</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">missing</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">data</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">mechanisms;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">focus</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">longitudinal</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">data</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><a href="https://github.com/rpsychologist/powerlmm?tab=readme-ov-file#launch-interactive-web-application"><span class="cl-febf2b24">yes</span></a></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">set</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">of</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">study</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">designs</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">with</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">two</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">or</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">three</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">levels</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Magnusson</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">et</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">al.</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2018)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">simglm</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">missing</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">data</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">mechanisms</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><a href="https://simglm.brandonlebeau.org/reference/run_shiny.html"><span class="cl-febf2b24">yes</span></a></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">yes</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">to</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">two</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">or</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">three</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">levels</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">LeBeau</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2019)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">simr</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Simulation-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">‘</span><span class="cl-febf2b10">lme4</span><span class="cl-febf2b10">’</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">package</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">yes</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">none</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Green</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">&amp;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">MacLeod</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2016)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">summary_statistics</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">based_power</span></p></td><td class="cl-fec0d4e4"><p class="cl-fec0c920"><span class="cl-febf2b10">Summary-statistics-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">‘</span><span class="cl-febf2b10">pwr</span><span class="cl-febf2b10">’</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">package</span></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><a href="https://koumurayama.shinyapps.io/summary_statistics_based_power/"><span class="cl-febf2b24">yes</span></a></p></td><td class="cl-fec0d4e5"><p class="cl-fec0c920"><span class="cl-febf2b10">yes</span></p></td><td class="cl-fec0d4e3"><p class="cl-fec0c920"><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">set</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">of</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">study</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">designs</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">with</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">two</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">levels</span></p></td><td class="cl-fec0d4ec"><p class="cl-fec0c920"><span class="cl-febf2b10">Murayama</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">et</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">al.</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2022)</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-fec0d4ed"><p class="cl-fec0c920"><span class="cl-febf2b10">WebPower</span></p></td><td class="cl-fec0d4ee"><p class="cl-fec0c920"><span class="cl-febf2b10">Formula-based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">power</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">analysis;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">based</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">‘</span><span class="cl-febf2b10">longpower</span><span class="cl-febf2b10">’</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">package;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">focus</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">on</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">longitudinal</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">data</span></p></td><td class="cl-fec0d4f6"><p class="cl-fec0c920"><a href="https://webpower.psychstat.org/wiki/start"><span class="cl-febf2b24">yes</span></a></p></td><td class="cl-fec0d4f6"><p class="cl-fec0c920"><span class="cl-febf2b10">no</span></p></td><td class="cl-fec0d4ed"><p class="cl-fec0c920"><span class="cl-febf2b10">limited</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">set</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">of</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">study</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">designs</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">with</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">two</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">levels</span></p></td><td class="cl-fec0d4f7"><p class="cl-fec0c920"><span class="cl-febf2b10">Zhang</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">&amp;</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">Yuan</span><span class="cl-febf2b10"> </span><span class="cl-febf2b10">(2018)</span></p></td></tr></tbody></table></div>
</div>
</div>
<div class="NoIndent">
<p><em>Note.</em> GUI available = whether a graphical user interface is provided (usually a Shiny app that is available online or can be downloaded to run locally), GLMM support = whether power analysis can be performed for generalized linear mixed model (otherwise only linear mixed models are supported), Design limitations = whether only a limited selection of study designs can be specified (otherwise arbitrary designs within the model class are supported).</p>
</div>
</section>
<section id="reasons-to-use-tailored-data-simulation" class="level1">
<h1>Reasons to use tailored data simulation</h1>
<p>Performing tailored simulation-based sample size planning is more complicated and time-consuming than using the existing software tools outlined in Table 1. Circumstances under which tailored simulation-based sample size planning is necessary include 1) complex study designs, 2) complex statistical hypotheses, 3) planning for precision, and 4) lack of prior studies or pilot data.</p>
<!-- ## Complex study designs -->
<p>First, requirements of real-world studies are often more complex than the simplified designs assumed by many user-friendly software packages for sample size planning. One frequent issue in applied data analysis is missing data <span class="citation" data-cites="littleStatisticalAnalysisMissing2014">(<a href="#ref-littleStatisticalAnalysisMissing2014" role="doc-biblioref">Little &amp; Rubin, 2014</a>)</span>. Missings can be completely random (e.g., an electronic measurement device randomly failed for technical reasons), depend on some attributes also measured in the dataset (e.g., older subjects refuse answering a question on income), or be caused by the measured attribute itself (e.g., wealthy people refuse to report their income). Moreover, many experimental designs contain conditions in which values of the predictor variables are missing by design. This can make data analysis more complicated because predictors have to be coded in specific ways that prevent the estimated GLMM from becoming unidentified. Whether missing data has an effect on the sample size planning depends on our theoretical assumptions on how the missingness is caused. However, it is often challenging to decide whether missing data can be safely ignored in the data analysis and sample size planning process based on a merely theoretical approach <span class="citation" data-cites="gomilaMissingDataExperiments2022">(<a href="#ref-gomilaMissingDataExperiments2022" role="doc-biblioref">Gomila &amp; Clark, 2022</a>)</span>. Tailored simulation-based approaches offer the possibility to include the assumed process of how data become missing in the data simulation, thereby determining the required sample size based on simulated datasets that contain missing values <span class="citation" data-cites="lanePowerStrugglesEstimating2018">(for example, see <a href="#ref-lanePowerStrugglesEstimating2018" role="doc-biblioref">Lane &amp; Hennes, 2018</a>)</span>. As a by-product, the simulated datasets can also be used to test whether the intended data analysis provides the expected (unbiased) results, despite the missing data. Although GLMMs can handle a large variety of outcome variables, researchers are becoming increasingly aware that many datasets might profit from even more sophisticated models. Common examples are zero-inflated outcomes, censoring, and nonlinear predictor effects that can be modeled with the R packages <em>glmmTMB</em> <span class="citation" data-cites="brooksGlmmTMBBalancesSpeed2017">(<a href="#ref-brooksGlmmTMBBalancesSpeed2017" role="doc-biblioref">Brooks et al., 2017</a>)</span> or <em>brms</em> <span class="citation" data-cites="burknerAdvancedBayesianMultilevel2018">(<a href="#ref-burknerAdvancedBayesianMultilevel2018" role="doc-biblioref">Bürkner, 2018</a>)</span>. Tailored simulation-based approaches do not share the same limitations as the existing software solutions for power analysis that focus exclusively on GLMMs. As long as there is a software package available to estimate the model of interest, it is always possible to perform tailored simulation-based sample size planning.</p>
<!-- ## Complex statistical hypotheses -->
<p>Second, the most common hypotheses tested in psychological research are of the type <span class="math inline">\(H_0: \beta = 0\)</span>, where <span class="math inline">\(\beta\)</span> is a slope or intercept of a regression model. However, many research questions in psychology actually require testing more complex statistical hypotheses. In the new era of preregistration and registered reports <span class="citation" data-cites="chambersPresentFutureRegistered2022">(<a href="#ref-chambersPresentFutureRegistered2022" role="doc-biblioref">Chambers &amp; Tzavella, 2022</a>)</span>, most research questions should be tested with directed hypotheses because good theories at least postulate whether some psychological effect of interest is positive or negative. Even better theories should be able to specify the smallest effect sizes of interest (SESOI) that must be exceeded if the effect has any practical relevance <span class="citation" data-cites="lakensEquivalenceTestingPsychological2018">(<a href="#ref-lakensEquivalenceTestingPsychological2018" role="doc-biblioref">Lakens, Scheel, et al., 2018</a>)</span>. This might require a test such as <span class="math inline">\(H_0: \beta \leq 0.1\)</span>. More elaborate research questions often require testing hypotheses that consist of a combination of model parameters, for example, testing simple slopes <span class="citation" data-cites="preacherComputationalToolsProbing2006">(<a href="#ref-preacherComputationalToolsProbing2006" role="doc-biblioref">Preacher et al., 2006</a>)</span> with a hypothesis such as <span class="math inline">\(H_0: \beta_0 + \beta_1 \leq 0\)</span>. If the research question consists only of a single hypothesis of this sort, it might be possible to reduce the hypothesis to a single regression coefficient by clever coding and/or centering of predictor variables. However, research questions often consist of combined hypotheses that consist of more than one separate statistical hypothesis <span class="citation" data-cites="schadHowCapitalizePriori2020">(for a tutorial on contrast analysis in GLMMs, see <a href="#ref-schadHowCapitalizePriori2020" role="doc-biblioref">Schad et al., 2020</a>)</span>. For example, a combined null hypothesis <span class="math inline">\(H_0\)</span> might consist of two single null hypotheses <span class="math inline">\(H_{01}: \beta_1 \leq 0\)</span> and <span class="math inline">\(H_{02}: \beta_0 + \beta_1 \leq 0\)</span>. For some research questions, the combined null hypothesis <span class="math inline">\(H_0\)</span> would be rejected if both <span class="math inline">\(H_{01}\)</span> <em>AND</em> <span class="math inline">\(H_{02}\)</span> are rejected. For other research questions, the combined null hypothesis <span class="math inline">\(H_0\)</span> would be rejected if <span class="math inline">\(H_{01}\)</span> <em>OR</em> <span class="math inline">\(H_{02}\)</span> <em>OR</em> both are rejected. If the global hypothesis <span class="math inline">\(H_0\)</span> is combined with a logical <em>OR</em>, the p-values of the single hypotheses must be corrected for multiple testing to avoid <span class="math inline">\(\alpha\)</span>-inflation for the global hypothesis <span class="citation" data-cites="dmitrienkoTraditionalMultiplicityAdjustment2013">(<a href="#ref-dmitrienkoTraditionalMultiplicityAdjustment2013" role="doc-biblioref">Dmitrienko &amp; D’Agostino, 2013</a>)</span>. However, if the global hypothesis <span class="math inline">\(H_0\)</span> is combined with a logical <em>AND</em>, a correction for multiple testing is not necessary but rather a mistake that unnecessarily reduces the power of the global HT. None of the software packages for sample size planning in Table 1 can handle combined hypotheses and only some can handle directed hypotheses. In contrast, our case study will demonstrate how we can test directed combined hypotheses with tailored simulation-based sample size planning.</p>
<!-- ## Planning for precision -->
<p>Third, all available software packages for sample size planning with GLMMs are based on power analysis and do not support planning for precision. Thus, researchers that want to apply an estimation strategy instead of testing statistical hypotheses <span class="citation" data-cites="cummingNewStatisticsWhy2014">(<a href="#ref-cummingNewStatisticsWhy2014" role="doc-biblioref">Cumming, 2014</a>)</span>, currently cannot use the software packages outlined in Table 1. However, tailored simulation-based sample size planning can easily handle the planning for precision approach <span class="citation" data-cites="maxwellSampleSizePlanning2008">(<a href="#ref-maxwellSampleSizePlanning2008" role="doc-biblioref">Maxwell et al., 2008</a>)</span>. The only change in procedure is that instead of computing HTs for each simulated dataset and estimating statistical power across repetitions, CIs are computed for each simulated dataset, and their expected width is estimated. <!-- As long as one is interested only in confidence intervals of a single model parameter, it might be possible to adapt existing software packages to plan for precision. However, we demonstrate in our case study that in realistic research projects with GLMMs, the contrasts of interests and their respective confidence intervals are usually situated on the scale of the (expected) outcome in contrast to the scale of the model parameters.  --></p>
<!-- ## No prior studies or pilot data -->
<p>Fourth, all frameworks for sample size planning require the user to make assumptions about the expected effect size. Assuming the true effect is of this size (or greater), one can compute the (minimum) power of a HT or the (maximum) expected width of a CI. Existing software packages for sample size planning for GLMMs usually require to provide the assumed effect in the unit of some standardized measure of effect size. When the researcher has access to similar studies or pilot data, providing such standardized effect sizes is feasible. However, choosing effect sizes based on small pilot studies is generally not recommended, as those estimates can be heavily biased <span class="citation" data-cites="albersWhenPowerAnalyses2018a lakensSampleSizeJustification2022">(<a href="#ref-albersWhenPowerAnalyses2018a" role="doc-biblioref">Albers &amp; Lakens, 2018</a>; <a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>. Providing an informed standardized effect size can be an almost impossible challenge when no prior studies or pilot data are available. This problem is further exacerbated by the fact that GLMMs are so flexible that general heuristics of what should be considered a small effect do not exist or are difficult to defend. In the absence of prior evidence, using domain knowledge to construct a tailored data simulation is considered the best solution to determine plausible effect sizes <span class="citation" data-cites="kumleEstimatingPowerGeneralized2021">(see scenario 3 in <a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">Kumle et al., 2021</a>)</span>. It would be possible to use these tailored simulations to compute standardized effect sizes that could then be inserted in existing software packages for sample size planning. However, we would argue that when tailored data simulations are necessary to determine effect sizes anyway, performing the whole sample size planning in a customized way is preferred over using the existing software packages.</p>
</section>
<section id="general-steps-in-tailored-simulation-based-sample-size-planning" class="level1">
<h1>General steps in tailored simulation-based sample size planning</h1>
<p>Although the details differ for each study, every tailored simulation-based sample size planning requires a series of steps and decisions. We will introduce each step in a theoretical section, followed by the practical application based on a case study. To keep the tutorial manageable, we focus on a binomial GLMM with two random intercepts and discrete predictor variables. All code in this manuscript and simulation results are available on the Open Science Framework (<a href="https://osf.io/dhwf4/" class="uri">https://osf.io/dhwf4/</a>) and on our tutorial website (<a href="https://timo-ko.github.io/glmm_simulation_tutorial/" class="uri">https://timo-ko.github.io/glmm_simulation_tutorial/</a>).</p>
<section id="step-1-define-the-estimand" class="level2">
<h2 class="anchored" data-anchor-id="step-1-define-the-estimand">Step 1: Define the estimand</h2>
<section id="theory" class="level3">
<h3 class="anchored" data-anchor-id="theory">THEORY</h3>
<p>The first step in every research process is a clear definition of the theoretical <em>estimand</em> <span class="citation" data-cites="lundbergWhatYourEstimand2021">(<a href="#ref-lundbergWhatYourEstimand2021" role="doc-biblioref">Lundberg et al., 2021</a>)</span>, i.e.&nbsp;the theoretical quantity which is necessary to answer a specific research question. The estimand consists of a quantity that can be described for each unit under investigation and a clear definition of the target population, for which the quantity is of interest. For example, an estimand might be the probability that a clinical psychologist makes the correct diagnosis for a psychiatric patient with major depression, averaged across all clinical psychologists and depressed patients in psychiatric institutions in a given country.</p>
<p>The estimand should always be defined outside of any statistical model, because there are usually a range of statistical methods that can be used to estimate the same estimand, depending on the study design (e.g., a randomized experiment) that will produce the observed data in the planned study. For many common research questions in psychology, it is possible to express the estimand as a statistical quantity that can be estimated with a regression model, for example a single <span class="math inline">\(\beta\)</span> coefficient. However, this is not possible for all estimands, which is why the literature discusses many estimation strategies beyond regression <span class="citation" data-cites="lundbergWhatYourEstimand2021 deffnerCausalFrameworkCrossCultural2022">(<a href="#ref-deffnerCausalFrameworkCrossCultural2022" role="doc-biblioref">Deffner et al., 2022</a>; <a href="#ref-lundbergWhatYourEstimand2021" role="doc-biblioref">Lundberg et al., 2021</a>)</span>.</p>
</section>
<section id="practice" class="level3">
<h3 class="anchored" data-anchor-id="practice">PRACTICE</h3>
<p>In the present case study, we consider the effectiveness of feedback provided by an artificial intelligence (AI) embedded in a clinical decision support system. The context is a clinical setting, where task experts (i.e., radiologists), and non-expert (i.e., medical students) must detect bleedings based on head scans from computer tomography (CT). The AI model can provide initial diagnostic advice, which can be used as guidance by the humans who are required to make the final diagnostic decision. The research goal is to validate the effectiveness of the AI-enabled advice. We consider the AI-enabled advice effective, if the following pattern holds:</p>
<p><em>We expect that for BOTH radiologists and medical students, correct AI advice leads to a higher probability of accurately diagnosing a CT scan compared to no AI advice presented, AND, we expect that for BOTH task experts and non-experts, incorrect advice leads to a lower probability of accurately diagnosing a CT scan compared to no advice presented.</em></p>
<p>It becomes clear that our estimand consists of four comparisons between experimental conditions <span class="citation" data-cites="lundbergWhatYourEstimand2021">(<a href="#ref-lundbergWhatYourEstimand2021" role="doc-biblioref">Lundberg et al., 2021</a>)</span>. However, the verbal description is still somewhat vague, which is why we try to give a more precise expression for each comparison:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; P(\text{correct diagnosis} | \text{correct advice, average expert, average scan}) \\
&amp; \quad - P(\text{correct diagnosis} | \text{no advice, average expert, average scan})
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp; P(\text{correct diagnosis} | \text{no advice, average expert, average scan}) \\
&amp; \quad - P(\text{correct diagnosis} | \text{incorrect advice, average expert, average scan})
\end{aligned}
\]</span> <span class="math display">\[
\begin{aligned}
&amp; P(\text{correct diagnosis} | \text{correct advice, average student, average scan}) \\
&amp; \quad - P(\text{correct diagnosis} | \text{no advice, average student, average scan})
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp; P(\text{correct diagnosis} | \text{no advice, average student, average scan}) \\
&amp; \quad - P(\text{correct diagnosis} | \text{incorrect advice, average student, average scan})
\end{aligned}
\]</span> For example, the first expression is concerned with the difference between the probability that a correct diagnosis is made if correct AI advice is presented and the probability that a correct diagnosis is made if no AI advice is presented. This contrast is quantified for a hypothetical <em>typical</em> expert and a <em>typical</em> scan, where <em>typical</em> is usually defined as an average score on all attributes of the expert or scan.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> To complete our definition of the estimand, we have to define our target population that consists of persons, stimuli, and AI advice: With respect to persons, we are only interested in experts (i.e., radiologists) and non-experts (i.e., medical students). With respect to stimuli, we are only interested in the head CT scans made from subjects that do or do not suffer from intracerebral hemorrhage. Lastly, we are only interested in AI advice given by a specific AI-enabled system.</p>
<p>Although the estimand is initially defined outside of a statistical model, it is only useful if we find a way to estimate it based on observed data. For our exemplary research question, it is possible to construct an experimental study where all participants are confronted with the same set of head CT scans, but the kind of AI advice given for each scan is randomly assigned within participants. This random intervention allows us to produce an empirical estimate of our estimand, although, in reality, each person receives only one kind of AI advice (correct advice, incorrect advice, no advice at all) for each scan. We will see later how each of the probability expressions in our estimand can be modeled with the same GLMM. Estimating this GLMM based on the data observed in our planned study will produce an estimate for each probability, and these estimates can then be combined to compute an estimate for each of the four probability contrasts. For pedagogical reasons, we will skip the concrete definition of our estimate until we have discussed how to simulate data based on a concrete GLMM in the next section.</p>
</section>
</section>
<section id="step-2-simulate-the-data-generating-process" class="level2">
<h2 class="anchored" data-anchor-id="step-2-simulate-the-data-generating-process">Step 2: Simulate the data-generating process</h2>
<section id="theory-1" class="level3">
<h3 class="anchored" data-anchor-id="theory-1">THEORY</h3>
<p>When the estimand has been defined, the next step in the research process is to write code that simulates the data-generating process of the planned study. This requires specifying a generative process for all predictor variables used in the final data analysis. Realistic assumptions can be quite challenging for observational studies or continuous predictor variables, which is beyond the scope of this tutorial. However, this step is much easier for experimental studies with only categorical predictor variables because the distribution of predictors is fixed by the study design. When all predictor variables have been simulated, one can use the structure of a suitable GLMM to simulate the dependent variable. To simulate the GLMM, one requires plausible values for all model parameters. We will discuss strategies on how these values can be obtained later. Because we have full control over the data-generating process in a tailored simulation, it is possible to model specific aspects of the planned study, like data missing by design or assuming that some subjects might drop out. The quality of the results of the sample size planning crucially depends on the plausibility of the simulated data-generating process. If the simulated data generating process is less complex than the true process, one can expect that sample size planning underestimates the required sample size and the planned analysis has inflated type I error rates <span class="citation" data-cites="matuschekBalancingTypeError2017">(<a href="#ref-matuschekBalancingTypeError2017" role="doc-biblioref">Matuschek et al., 2017</a>)</span>. However, <span class="citation" data-cites="matuschekBalancingTypeError2017">Matuschek et al. (<a href="#ref-matuschekBalancingTypeError2017" role="doc-biblioref">2017</a>)</span> have also shown in simulations with LMMs that while fitting <em>maximal models</em> (i.e.&nbsp;that include all possible random effects) safeguards against inflated type I error rates, this can lead to a great loss in power if the variance in the random effects is actually small. Thus, we argue that even a simplified data-generating process (e.g., only a small number of interaction effects; only random intercepts, and no random slopes; assuming that data is missing completely at random) that is only plausible under idealized circumstances, can yield informative results and is preferred over performing no systematic sample size planning.</p>
</section>
<section id="practice-1" class="level3">
<h3 class="anchored" data-anchor-id="practice-1">PRACTICE</h3>
<p>In our case study, radiologists and students review a series of head CT scans to assess the presence of a bleeding. An AI model provides initial diagnostic advice to assist their decision-making. In the control condition, no AI advice is presented. When AI advice is given, this advice can be either correct or incorrect. The type of advice (no advice, incorrect advice, correct advice) is randomized within subjects across CT scans. After reviewing a CT scan, participants deliver a diagnosis (bleeding or no bleeding), which may be either accurate or inaccurate. This experimental design introduces some missing values by design since the advice is neither correct nor incorrect when no advice is present, which must be taken into account when simulating and analyzing the data. In this example, recruiting task experts (i.e., radiologists) is more challenging due to their limited availability, while non-experts (i.e., students) are more readily accessible. The goal of simulation-based sample size planning is to determine how many task experts and non-experts must be recruited to achieve sufficient statistical power or precision in the planned experiment.</p>
<p><strong>Our specific GLMM.</strong> In a GLMM, the expected value of the dependent variable <span class="math inline">\(Y\)</span> conditioned on the vector of predictor variables <span class="math inline">\(\mathbf{X}\)</span> and random effects <span class="math inline">\(\mathbf{U}\)</span>, transformed by a link function <span class="math inline">\(g()\)</span> is modeled as a linear combination <span class="math inline">\(\eta\)</span> of the predictor variables <span class="math inline">\(\mathbf{X}\)</span>, the random effects <span class="math inline">\(\mathbf{U}\)</span>, and the model parameters <span class="math inline">\(\mathbf{\beta}\)</span> <span class="citation" data-cites="fahrmeirRegressionModelsMethods2021">(<a href="#ref-fahrmeirRegressionModelsMethods2021" role="doc-biblioref">Fahrmeir et al., 2021</a>)</span>: <span class="math display">\[
g(E(Y|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u})) = \eta
\]</span> Equivalently, the conditional expected value is modeled as the linear combination <span class="math inline">\(\eta\)</span>, transformed by the inverse link function <span class="math inline">\(g^{-1}()\)</span>: <span class="math display">\[
E(Y|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u}) = g^{-1}(\eta)
\]</span> If the dependent variable (i.e., diagnostic decision) <span class="math inline">\(Y\)</span> is a binary variable with values <span class="math inline">\(0\)</span> (i.e., inaccurate), or <span class="math inline">\(1\)</span> (i.e., accurate), the conditional expected value is equivalent to the probability: <span class="math display">\[
P_{si} := P(Y = 1|\mathbf{X}=\mathbf{x},\mathbf{U}=\mathbf{u})
\]</span> In our case study, <span class="math inline">\(P_{si}\)</span> is the conditional probability that subject <span class="math inline">\(s\)</span> gives the correct response to item (i.e., CT scan) <span class="math inline">\(i\)</span>.</p>
<p>In such a setting, we model this probability as <span class="math display">\[
P_{si} = \text{inverse\_logit}(\eta_{si})
\]</span> with the inverse-logit link <span class="math inline">\(g^{-1}(\eta_{si}) = \text{inverse\_logit}(\eta_{si}) = \frac{\text{exp}(\eta_{si})}{1 + \text{exp}(\eta_{si})}\)</span> or equivalently <span class="math display">\[
\text{logit}(P_{si}) = \eta_{si}
\]</span> with the logit link <span class="math inline">\(g(P_{si}) = \text{logit}(P_{si}) = \text{ln} (\frac{P_{si}}{1 - P_{si}})\)</span>.</p>
<p>In our case study, the probability of making an accurate diagnostic decision is assumed to depend on the predictors:</p>
<ul>
<li><span class="math inline">\(advice\_present_{si}\)</span>: whether subject <span class="math inline">\(s\)</span> was presented with AI advice (1) or not (0) when asked to assess item <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(advice\_correct_{si}\)</span>: whether this advice was correct (1) or not (0)</li>
<li><span class="math inline">\(expert_s\)</span>: whether subject <span class="math inline">\(s\)</span> was a task expert (1) or not (0)</li>
</ul>
<p>and the random effects:</p>
<ul>
<li><span class="math inline">\(u_{0s}\)</span>: the deviation of subject <span class="math inline">\(s\)</span> from the average ability to solve an item (i.e., CT scan) with average difficulty; assumed to be distributed as <span class="math inline">\(u_{0s} \sim N(0, \sigma_S^2)\)</span></li>
<li><span class="math inline">\(u_{0i}\)</span>: the deviation of item (i.e., CT scan) <span class="math inline">\(i\)</span> from the average difficulty to be solved by a person with average ability; assumed to be distributed as <span class="math inline">\(u_{0i} \sim N(0, \sigma_I^2)\)</span></li>
</ul>
<p>In total, we assume the model <span class="math display">\[
\begin{aligned}
\text{logit}[P_{si}] =\ (&amp;\beta_0 + u_{0s} + u_{0i})\\
&amp;+ \beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s\\
&amp;+\beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}
\end{aligned}
\]</span> or equivalently <span class="math display">\[
\begin{aligned}
P_{si} = \text{inverse\_logit}[&amp;(\beta_0 + u_{0s} + u_{0i})\\
&amp;+ \beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} + \beta_e \cdot expert_s\\
&amp;+ \beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}]
\end{aligned}
\]</span> with model parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_e\)</span>, <span class="math inline">\(\beta_a\)</span>, <span class="math inline">\(\beta_c\)</span>, <span class="math inline">\(\beta_{ea}\)</span>, <span class="math inline">\(\beta_{ec}\)</span>, <span class="math inline">\(\sigma_S\)</span>, and <span class="math inline">\(\sigma_I\)</span>.</p>
<p>In the GLMM literature, this would be called a binomial GLMM with two random intercepts (for subjects and items), two level-1 predictors (<span class="math inline">\(advice\_present\)</span>, <span class="math inline">\(advice\_correct\)</span>), one level-2 predictor (<span class="math inline">\(expert\)</span>) and two cross-level interactions (<span class="math inline">\(expert \cdot advice\_present\)</span>, <span class="math inline">\(expert \cdot advice\_correct\)</span>). To limit complexity, we do not consider random slopes, additional predictors, or higher-level interactions.</p>
<p><strong>Simulation function in R.</strong> The following R function simulates a full dataset structured according to the design of our case study.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>simulate <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">n_subjects =</span> <span class="dv">100</span>, <span class="at">n_items =</span> <span class="dv">50</span>,</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">b_0 =</span> <span class="fl">0.847</span>, <span class="at">b_e =</span> <span class="fl">1.350</span>, <span class="at">b_a =</span> <span class="sc">-</span><span class="fl">1.253</span>, <span class="at">b_c =</span> <span class="fl">2.603</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">b_ea =</span> <span class="fl">0.790</span>, <span class="at">b_ec =</span> <span class="sc">-</span><span class="fl">1.393</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd_u0s =</span> <span class="fl">0.5</span>, <span class="at">sd_u0i =</span> <span class="fl">0.5</span>, ...){</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(dplyr)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(faux)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># simulate design</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  dat <span class="ot">&lt;-</span> <span class="fu">add_random</span>(<span class="at">subject =</span> n_subjects, <span class="at">item =</span> n_items) <span class="sc">%&gt;%</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_between</span>(<span class="st">"subject"</span>, <span class="at">expert =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="at">.prob =</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">advice_present =</span> <span class="fu">rbinom</span>(<span class="fu">n</span>(), <span class="dv">1</span>, <span class="at">prob =</span> <span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">advice_correct =</span> <span class="fu">if_else</span>(advice_present <span class="sc">==</span> <span class="dv">1</span>L, </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                                    <span class="fu">rbinom</span>(<span class="fu">n</span>(), <span class="dv">1</span>L, <span class="at">prob =</span> <span class="fl">0.8</span>), <span class="dv">0</span>L)) <span class="sc">%&gt;%</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add random effects</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_ranef</span>(<span class="st">"subject"</span>, <span class="at">u0s =</span> sd_u0s) <span class="sc">%&gt;%</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_ranef</span>(<span class="st">"item"</span>, <span class="at">u0i =</span> sd_u0i) <span class="sc">%&gt;%</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute dependent variable</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">linpred =</span> b_0 <span class="sc">+</span> u0i <span class="sc">+</span> u0s <span class="sc">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>      b_e <span class="sc">*</span> expert <span class="sc">+</span> b_a <span class="sc">*</span> advice_present <span class="sc">+</span> b_c <span class="sc">*</span> advice_correct <span class="sc">+</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>      b_ea <span class="sc">*</span> expert <span class="sc">*</span> advice_present <span class="sc">+</span> b_ec <span class="sc">*</span> expert <span class="sc">*</span> advice_correct) <span class="sc">%&gt;%</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">y_prob =</span> <span class="fu">plogis</span>(linpred)) <span class="sc">%&gt;%</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">y_bin =</span> <span class="fu">rbinom</span>(<span class="at">n =</span> <span class="fu">n</span>(), <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> y_prob))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  dat</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the first four lines of the function definition, we set some default parameter values (which we will explain in the next section) and load the packages we use to manipulate and simulate data.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> In our case study, each subject (<code>n_subjects</code> in total) is assumed to respond to each item (i.e., CT scan; <code>n_items</code> in total). Thus, the <code>add_random</code> command creates a fully-crossed <code>data.frame</code> with <code>n_subjects</code> <span class="math inline">\(\times\)</span> <code>n_items</code> rows. We add a between-subject effect with the <code>add_between</code> command, simulating that about <span class="math inline">\(25\%\)</span> of subjects are experts. The next two lines simulate that in <span class="math inline">\(\frac{2}{3}\)</span> of trials, subjects will be presented with AI advice, and if advice is presented, the advice will be correct in about <span class="math inline">\(80\%\)</span> of cases (the variable <code>advice_correct</code> is always 0 when no advice is presented). Next, we simulate one random effect for each subject (<code>u0s</code>) and for each item (<code>u0i</code>). As assumed by standard GLMMs, the <code>add_ranef</code> function draws the random effects from a normal distribution with a mean 0 and a standard deviation specified by the user. With all design variables done, we are ready to simulate our model equation outlined in the last section. The linear predictor variable <code>linpred</code> (<span class="math inline">\(\eta\)</span> in the GLMM model equations) combines the predictor variables, random effects, and model parameters as assumed by our model. We then transform the linear predictor with the inverse-link function to compute <code>y_prob</code>, the probability that the subject correctly solved the item (in R, the inverse-logit link is computed with <code>plogis</code> and the logit link with <code>qlogis</code>). In the final step, we simulate the binary dependent variable <code>y_bin</code> (i.e., whether the subject makes an accurate diagnostic decision for the CT scan) by – for each trial – drawing from a Bernoulli distribution with success probability <code>y_prob</code>.</p>
</section>
</section>
<section id="step-3-specify-the-population-parameters" class="level2">
<h2 class="anchored" data-anchor-id="step-3-specify-the-population-parameters">Step 3: Specify the population parameters</h2>
<section id="theory-2" class="level3">
<h3 class="anchored" data-anchor-id="theory-2">THEORY</h3>
<p>Population parameters are all model parameters estimated in a GLMM, in particular the regression coefficients of the fixed effects and the standard deviation of the random effects (and the correlation between random effects in more complicated models). In the absence of previous studies with the same design or pilot data, strategies to specify population parameters will always require access to some domain knowledge. In our experience, research teams for projects where tailored simulation-based sample size planning is necessary typically consist of <em>analysts</em> (who are primarily responsible for study design and statistical analysis), and <em>domain experts</em> (who often provide the original research question and are responsible for data collection). In smaller projects, analysts and domain experts might be the same persons. In these research settings, a broad review of the available literature typically plays a more important role. Because most domain knowledge can only be expressed in unstandardized measurement units of a specific application, we argue that unstandardized effect sizes are usually preferable over standardized effect sizes for tailored simulation-based sample size planning. The basic idea of all strategies is to quantify or visualize the data-generating process implied by certain values of population parameters in an intuitive way that enables calibration of population parameters based on the available domain knowledge. Although we use frequentist model estimation in our tutorial, many strategies demonstrated in this chapter are inspired by research on monitoring the plausibility of model assumptions <span class="citation" data-cites="gelmanBayesianWorkflow2020 schadPrincipledBayesianWorkflow2021">(<a href="#ref-gelmanBayesianWorkflow2020" role="doc-biblioref">Gelman et al., 2020</a>; <a href="#ref-schadPrincipledBayesianWorkflow2021" role="doc-biblioref">Schad et al., 2021</a>)</span> and eliciting prior information <span class="citation" data-cites="bocktingSimulationbasedPriorKnowledge2024 mikkolaPriorKnowledgeElicitation2023 hartmannFlexiblePriorElicitation2020 stefanPracticalChallengesMethodological2022">(<a href="#ref-bocktingSimulationbasedPriorKnowledge2024" role="doc-biblioref">Bockting et al., 2024</a>; <a href="#ref-hartmannFlexiblePriorElicitation2020" role="doc-biblioref">Hartmann et al., 2020</a>; <a href="#ref-mikkolaPriorKnowledgeElicitation2023" role="doc-biblioref">Mikkola et al., 2023</a>; <a href="#ref-stefanPracticalChallengesMethodological2022" role="doc-biblioref">Stefan et al., 2022</a>)</span> in applied Bayesian statistics.</p>
</section>
<section id="practice-2" class="level3">
<h3 class="anchored" data-anchor-id="practice-2">PRACTICE</h3>
<p>When introducing the simulation function for our case study, we have used theoretically plausible values as defaults for all model parameters (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_e\)</span>, <span class="math inline">\(\beta_a\)</span>, <span class="math inline">\(\beta_c\)</span>, <span class="math inline">\(\beta_{ea}\)</span>, <span class="math inline">\(\beta_{ec}\)</span>, <span class="math inline">\(\sigma_S\)</span>, and <span class="math inline">\(\sigma_I\)</span>) but have not talked about where these numbers came from. The starting point for all parameter values was based on results from distantly related study designs in the literature. Additionally, we had repeated discussions with our affiliated domain experts in radiology to check whether our assumptions regarding participants’ diagnostic performance seemed plausible.</p>
<p>We now outline our main strategy to determine plausible parameter values for the fixed effects (<span class="math inline">\(\beta\)</span> parameters): Unfortunately, the model parameters in a binomial GLMM are hard to interpret in isolation because first, the parameters are connected to the modeled probability via the non-linear inverse-logit link, and second, we also have to consider the random effects. The most simple interpretation, which allows us to ignore the random effects for now, works by imagining a subject with average ability (<span class="math inline">\(u_{0s} = 0\)</span>) responding to an item (i.e., CT scan) with average difficulty (<span class="math inline">\(u_{0i} = 0\)</span>). Then the model-implied probability that such a person solves such an item accurately is given by:</p>
<p><span class="math display">\[
\begin{aligned}
P(Y=1|\mathbf{X=x}, \mathbf{U} = \mathbf{0})\\
= \text{inverse\_logit}[&amp;\beta_0 + \beta_a \cdot advice\_present_{si} + \beta_c \cdot advice\_correct_{si} +  \beta_e \cdot expert_s\\
&amp;+ \beta_{ea} \cdot expert_{s} \cdot advice\_present_{si} + \beta_{ec} \cdot expert_{s} \cdot advice\_correct_{si}]
\end{aligned}
\]</span> In fact, we would only need the full equation if the subject is an expert and correct advice is presented. In all other experimental conditions, some terms drop from the equation because they are multiplied by <span class="math inline">\(0\)</span>. For example, the probability that a student with average ability solves an item with average difficulty when no advice is presented only requires the intercept: <span class="math display">\[
\begin{aligned}
P(Y=1| advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)\\
= \text{inverse\_logit}[\beta_0]
\end{aligned}
\]</span> We can revert this perspective by choosing plausible probability values based on domain knowledge and deriving the parameter values implied by these probabilities for each experimental condition.</p>
<div style="page-break-after: always;"></div>
<div class="cell" data-apa-note="Implied equations are derived based on the model equations and setting all random intercept terms to 0.">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Table 2. Assumed probabilities that an average subject solves an average item in each experimental condition.</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 31%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Experimental condition</th>
<th style="text-align: left;"><span class="math inline">\(P(Y=1 \mid \mathbf{X=x}, \mathbf{U} = \mathbf{0})\)</span></th>
<th style="text-align: left;">Implied equation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">no advice, student</td>
<td style="text-align: left;">0.70</td>
<td style="text-align: left;"><span class="math inline">\(\text{logit}(0.70) = \beta_0\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">no advice, expert</td>
<td style="text-align: left;">0.90</td>
<td style="text-align: left;"><span class="math inline">\(\text{logit}(0.90) = \beta_0 + \beta_e\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">incorrect advice, student</td>
<td style="text-align: left;">0.40</td>
<td style="text-align: left;"><span class="math inline">\(\text{logit}(0.40) = \beta_0 + \beta_a\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">incorrect advice, expert</td>
<td style="text-align: left;">0.85</td>
<td style="text-align: left;"><span class="math inline">\(\text{logit}(0.85) = \beta_0 + \beta_e + \beta_{a} + \beta_{ea}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">correct advice, student</td>
<td style="text-align: left;">0.90</td>
<td style="text-align: left;"><span class="math inline">\(\text{logit}(0.90) = \beta_0 + \beta_a + \beta_c\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">correct advice, expert</td>
<td style="text-align: left;">0.95</td>
<td style="text-align: left;"><span class="math inline">\(\text{logit}(0.95) = \beta_0 + \beta_e + \beta_a + \beta_c + \beta_{ea} + \beta_{ec}\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Table 2 shows our set of assumptions concerning the probability that an average subject solves an average item for each experimental condition, as well as the corresponding equations implied by the model. The table can be used to compute the implied values for the <span class="math inline">\(\beta\)</span> parameters, starting with the first equation and reinserting the computed <span class="math inline">\(\beta\)</span> values in all following equations (<code>b_0</code> stands for the intercept <span class="math inline">\(\beta_0\)</span>, <code>b_e</code> for the slope <span class="math inline">\(\beta_e\)</span>, and so on):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>b_0 <span class="ot">&lt;-</span> <span class="fu">qlogis</span>(<span class="fl">0.7</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>b_e <span class="ot">&lt;-</span> <span class="fu">qlogis</span>(<span class="fl">0.9</span>) <span class="sc">-</span> b_0</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>b_a <span class="ot">&lt;-</span> <span class="fu">qlogis</span>(<span class="fl">0.4</span>) <span class="sc">-</span> b_0</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>b_ea <span class="ot">&lt;-</span> <span class="fu">qlogis</span>(<span class="fl">0.85</span>) <span class="sc">-</span> b_0 <span class="sc">-</span> b_e <span class="sc">-</span> b_a</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>b_c <span class="ot">&lt;-</span> <span class="fu">qlogis</span>(<span class="fl">0.9</span>) <span class="sc">-</span> b_0 <span class="sc">-</span> b_a</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>b_ec <span class="ot">&lt;-</span> <span class="fu">qlogis</span>(<span class="fl">0.95</span>) <span class="sc">-</span> b_0 <span class="sc">-</span> b_e <span class="sc">-</span> b_a <span class="sc">-</span> b_c <span class="sc">-</span> b_ea</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="at">b_0 =</span> b_0, <span class="at">b_e =</span> b_e, <span class="at">b_a =</span> b_a, <span class="at">b_c =</span> b_c, <span class="at">b_ea =</span> b_ea, <span class="at">b_ec =</span> b_ec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       b_0        b_e        b_a        b_c       b_ea       b_ec 
 0.8472979  1.3499267 -1.2527630  2.6026897  0.7901394 -1.3928518 </code></pre>
</div>
</div>
<p>It is always possible to double-check these computations by transforming the parameter values back to probabilities, e.g.&nbsp; <span class="math display">\[
\begin{aligned}
P(Y=1|expert = 1, advice\_present = 1, advice\_correct = 1, u_{0s} = 0, u_{0i} = 0)\\
= \text{inverse\_logit}[\beta_0 + \beta_e + \beta_a + \beta_c + \beta_{ea} + \beta_{ec}]
\end{aligned}
\]</span></p>
<p>which we compute in R as:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(b_0 <span class="sc">+</span> b_e <span class="sc">+</span> b_a <span class="sc">+</span> b_c <span class="sc">+</span> b_ea <span class="sc">+</span> b_ec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.95</code></pre>
</div>
</div>
<p>This leaves us with the question on how to determine plausible values for the two remaining model parameters (<span class="math inline">\(\sigma_S\)</span>, and <span class="math inline">\(\sigma_I\)</span>) that are the standard deviations for the random intercepts. For this, we introduce two more strategies in the following sections.</p>
</section>
<section id="examine-insightful-descriptive-statistics" class="level3">
<h3 class="anchored" data-anchor-id="examine-insightful-descriptive-statistics">Examine insightful descriptive statistics</h3>
</section>
<section id="theory-3" class="level3">
<h3 class="anchored" data-anchor-id="theory-3">THEORY</h3>
<p>The mathematical structure of GLMMs determines which patterns in data would be produced by the model, if a specific set of values for the population parameters is specified. The knowledge of how to simulate from a GLMM enables us to compute <em>insightful descriptive statistics</em> that can be compared to available domain knowledge much more easily than the opaque values of model parameters. For example, domain experts might not be able to directly choose plausible values for the coefficients in a logistic regression model (which are measured on the log-odds scale). However, they should be able to reason about the expected ratio of the binary dependent variable in different experimental conditions, i.e., which relative frequency they expect to observe. The job of the analyst who is familiar with the mathematical structure of the GLMM is to produce the model-implied value of the insightful descriptive statistic that is expected by the domain expert. Although insightful descriptive statistics usually depend on the model parameters in a non-linear way, it is not necessary to solve the exact relationship mathematically. Instead, one can simply adjust the population parameters by trial and error until the model-implied quantities produce the desired result.</p>
</section>
<section id="practice-3" class="level3">
<h3 class="anchored" data-anchor-id="practice-3">PRACTICE</h3>
<p>In the last section, we showed how we can derive the model-implied probability that a subject with average ability solves an item with average difficulty for each experimental condition. Although these derivations are straightforward, it is important not to misinterpret their implications: In binomial GLMMs, the average probability to solve an item (averaged across persons of varying ability and items of varying difficulty) is <strong>not</strong> equal to the probability that a person with average ability solves an item with average difficulty <span class="citation" data-cites="fahrmeirRegressionModelsMethods2021">(<a href="#ref-fahrmeirRegressionModelsMethods2021" role="doc-biblioref">Fahrmeir et al., 2021</a>)</span>. The first perspective implies a so-called <em>marginal interpretation</em>, while the second one implies a <em>conditional interpretation</em>.</p>
<p>For example, we determined the <span class="math inline">\(\beta\)</span> parameters in a way that corresponds to a desired conditional probability of <span class="math inline">\(0.95\)</span>, that an expert with average ability solves an item with average difficulty when presented with correct advice (the conditional perspective). However, even if the model assumptions were true, the relative frequency of experts that solve items presented with correct advice would not be <span class="math inline">\(0.95\)</span> in a large sample of subjects drawn from their natural distribution of ability and items drawn from their natural distribution of difficulty (the marginal perspective). How much the two probabilities differ depends on the standard deviations of the random intercepts (the two probabilities are only equal if both standard deviations are be zero). We want to use the model-implied observed proportion of correct diagnoses in each experimental condition as an insightful descriptive statistic to determine plausible values for the random effect standard deviations. We will simulate a large dataset (for which the observed values of the descriptive statistic will be close to their model-implied true values) and simply compute the relative frequency of correct diagnoses for each experimental condition.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">simulate</span>(<span class="at">n_subjects =</span> <span class="dv">3000</span>, <span class="at">n_items =</span> <span class="dv">3000</span>,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd_u0s =</span> <span class="fl">0.5</span>, <span class="at">sd_u0i =</span> <span class="fl">0.5</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">condition =</span> <span class="fu">fct_cross</span>(</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">factor</span>(expert), <span class="fu">factor</span>(advice_present), <span class="fu">factor</span>(advice_correct))) <span class="sc">%&gt;%</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">condition =</span> <span class="fu">fct_recode</span>(condition,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a> <span class="st">"student, no advice"</span> <span class="ot">=</span> <span class="st">"0:0:0"</span>, <span class="st">"expert, no advice"</span> <span class="ot">=</span> <span class="st">"1:0:0"</span>, </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a> <span class="st">"student, incorrect advice"</span> <span class="ot">=</span> <span class="st">"0:1:0"</span>, <span class="st">"expert, incorrect advice"</span> <span class="ot">=</span> <span class="st">"1:1:0"</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a> <span class="st">"student, correct advice"</span> <span class="ot">=</span> <span class="st">"0:1:1"</span>, <span class="st">"expert, correct advice"</span> <span class="ot">=</span> <span class="st">"1:1:1"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(condition) <span class="sc">%&gt;%</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">relative_frequency =</span> <span class="fu">sum</span>(y_bin) <span class="sc">/</span> <span class="fu">n</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
  condition                 relative_frequency
  &lt;fct&gt;                                  &lt;dbl&gt;
1 student, no advice                     0.683
2 expert, no advice                      0.881
3 student, incorrect advice              0.409
4 expert, incorrect advice               0.828
5 student, correct advice                0.883
6 expert, correct advice                 0.938</code></pre>
</div>
</div>
<p>We tried using these descriptive statistics to judge together with domain experts whether our chosen values for the random effect standard deviations would produce data that aligned with their expectations. Although the result was deemed plausible, these statistics were not informative enough to determine a final set of plausible parameter values (e.g., doubling the standard deviations from 0.5 to 1 produces only minor changes in relative frequency). For this reason, we will additionally look at insightful model-based quantities.</p>
</section>
<section id="examine-insightful-model-based-quantities" class="level3">
<h3 class="anchored" data-anchor-id="examine-insightful-model-based-quantities">Examine insightful model-based quantities</h3>
</section>
<section id="theory-4" class="level3">
<h3 class="anchored" data-anchor-id="theory-4">THEORY</h3>
<p>Because GLMMs are complicated models, descriptive statistics alone are usually not enough to specify plausible values for all model parameters. This is especially true for the standard deviation of random effects that have non-linear (and often unexpected) effects on the model-implied results. An important advantage of data simulation (where one has full control over parameter values and sample sizes) is that one can produce <em>insightful model-based quantities</em> that can never be directly observed in an actual empirical dataset. For example, in a logistic model with random intercepts for participants, one can produce a visualization of the implied distribution of the probability that a participant, on average, solves a cognitive task. Although domain knowledge will probably not suffice to specify this distribution completely, it should be possible to rule out implausible boundary conditions. For example, the domain expert might deem it implausible that the 5% most able participants have a probability of more than 0.99 to solve the difficult cognitive task.</p>
</section>
<section id="practice-4" class="level3">
<h3 class="anchored" data-anchor-id="practice-4">PRACTICE</h3>
<p>The discussed inequality of conditional and marginal effects in GLMMs <span class="citation" data-cites="fahrmeirRegressionModelsMethods2021">(<a href="#ref-fahrmeirRegressionModelsMethods2021" role="doc-biblioref">Fahrmeir et al., 2021</a>)</span> makes their interpretation more difficult. One must be careful when specifying parameter values based on previous studies or pilot data that use the marginal interpretation (e.g., a pilot study providing an estimate of how often radiologists make an accurate diagnosis based on brain scans). However, this does not mean that we cannot use the marginal interpretation (average probability across persons and items) to inform plausible parameter values: When parameter values have been selected, we can compute the implied marginal distributions and compare this information to our domain knowledge. Then, we can iteratively adjust the parameter values until we are satisfied with the implied distributions. In the last section, we simulated a large dataset and computed descriptive statistics, the relative frequencies of correct diagnoses, for each experimental condition. We will now use the model-implied probability of each simulated data point (stored in the variable <code>y_prob</code>) to visualize the whole model-implied marginal distribution of correct diagnoses for each experimental condition.</p>
<div id="cell-fig-margdist1" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggdist)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">condition =</span> <span class="fu">fct_cross</span>(</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">factor</span>(expert), <span class="fu">factor</span>(advice_present), <span class="fu">factor</span>(advice_correct))) <span class="sc">%&gt;%</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">condition =</span> <span class="fu">fct_recode</span>(condition,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="st">"student, no advice"</span> <span class="ot">=</span> <span class="st">"0:0:0"</span>, <span class="st">"expert, no advice"</span> <span class="ot">=</span> <span class="st">"1:0:0"</span>, </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="st">"student, incorrect advice"</span> <span class="ot">=</span> <span class="st">"0:1:0"</span>, <span class="st">"expert, incorrect advice"</span> <span class="ot">=</span> <span class="st">"1:1:0"</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="st">"student, correct advice"</span> <span class="ot">=</span> <span class="st">"0:1:1"</span>, <span class="st">"expert, correct advice"</span> <span class="ot">=</span> <span class="st">"1:1:1"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> y_prob, <span class="at">y =</span> condition)) <span class="sc">+</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_histinterval</span>(<span class="at">point_interval =</span> <span class="st">"mean_qi"</span>, <span class="at">slab_color =</span> <span class="st">"gray45"</span>,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="st">"Sturges"</span>) <span class="sc">+</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-margdist1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-margdist1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="manuscript_files/figure-html/fig-margdist1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Marginal distributions including means, 66% and 95% confidence intervals for all experimental conditions."><img src="manuscript_files/figure-html/fig-margdist1-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-margdist1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Marginal distributions including means, 66% and 95% confidence intervals for all experimental conditions.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-margdist1" class="quarto-xref">Figure&nbsp;1</a> shows the model-implied marginal distributions, including the mean, 66% and 95% intervals. We can see that, indeed, the average probabilities (black dots) slightly differ from the probabilities of average subjects and items considered previously. This difference increases with the variability of the random effects. We can use plots like <a href="#fig-margdist1" class="quarto-xref">Figure&nbsp;1</a> as a useful tool to determine whether the specified standard deviations of the subject and item random intercepts (<span class="math inline">\(\sigma_S\)</span> and <span class="math inline">\(\sigma_I\)</span>) are reasonable by comparing the ranges and overlap between conditions to domain knowledge.</p>
<div id="cell-fig-margdist2" class="cell">
<div class="cell-output-display">
<div id="fig-margdist2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-margdist2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="manuscript_files/figure-html/fig-margdist2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Marginal distributions including means, 66% and 95% confidence intervals for all experimental conditions while setting the standard deviation of item random intercepts to 0.01."><img src="manuscript_files/figure-html/fig-margdist2-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-margdist2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Marginal distributions including means, 66% and 95% confidence intervals for all experimental conditions while setting the standard deviation of item random intercepts to 0.01.
</figcaption>
</figure>
</div>
</div>
</div>
<p>For the next plot, we have set the item standard deviation to almost zero (<span class="math inline">\(\sigma_I = 0.01\)</span>). This gives us a better way to see the variability between persons. As an example, <a href="#fig-margdist2" class="quarto-xref">Figure&nbsp;2</a> reveals a number of implicit assumptions about the comparison between experts and students: With incorrect advice, virtually all experts have a higher probability of making a correct diagnosis compared to students when considering only items with average difficulty. In contrast, there is considerable overlap in probability between experts and students with no advice and even higher overlap with correct advice. Patterns like these should be considered carefully and discussed with the domain experts. Parameter values (<span class="math inline">\(\beta\)</span> parameters, and <span class="math inline">\(\sigma_S\)</span>) should be adjusted if the implications do not seem reasonable.<br>
The final plot demonstrates that these plots are also useful for spotting standard deviations that were specified too high. For <a href="#fig-margdist3" class="quarto-xref">Figure&nbsp;3</a> we have set <span class="math inline">\(\sigma_S = 3\)</span> and <span class="math inline">\(\sigma_I = 3\)</span>. This implies that in each experimental condition, the probabilities that a subject solves an item are overwhelmingly close to either 0 or 1 and nothing in between, which is not a plausible assumption. These high standard deviations do not account for the inherent variability and complexity of human performance. For example, the expectation that an expert with low ability and incorrect advice would solve a difficult item with a probability close to zero is not convincing.</p>
<div id="cell-fig-margdist3" class="cell">
<div class="cell-output-display">
<div id="fig-margdist3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-margdist3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="manuscript_files/figure-html/fig-margdist3-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Marginal distributions including means, 66% and 95% confidence intervals for all experimental conditions while setting the standard deviation of subject and item random intercepts to 3."><img src="manuscript_files/figure-html/fig-margdist3-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-margdist3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Marginal distributions including means, 66% and 95% confidence intervals for all experimental conditions while setting the standard deviation of subject and item random intercepts to 3.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="iterate-with-domain-expertise" class="level3">
<h3 class="anchored" data-anchor-id="iterate-with-domain-expertise">Iterate with domain expertise</h3>
</section>
<section id="theory-5" class="level3">
<h3 class="anchored" data-anchor-id="theory-5">THEORY</h3>
<p>Tailored simulation-based sample size planning always requires access to domain knowledge. However, gathering domain knowledge and the specification of population parameter values is not always straightforward and can be better described as an iterative process, in which the plausibility of simulated data is repeatedly compared with the available domain expertise. As a first step, dedicated domain experts (if available) can be interviewed to <em>elicit</em> their domain knowledge about how the data of the planned study is expected to look. Because most domain experts are no experts in statistical modeling and GLMMs, they often struggle without further guidance to communicate their knowledge in a way that is useful when specifying the parameters for data simulation. For this reason, we suggest that after an initial interview, the analyst who is familiar with the structure of the GLMM selects an initial set of insightful descriptive statistics and model-based quantities. Then, they reenter into an iterative discussion with the domain experts where some set of population values are selected, and the plausibility of resulting implied quantities is evaluated. The population parameters are updated until the domain experts are satisfied with the result. During this process, the monitored descriptive statistics and model-based quantities can be updated or extended to capture as much available domain knowledge as possible. Even if no dedicated domain experts are available, the basic principles stay the same except that initial parameter values are often derived from a more extensive literature review. Descriptive statistics and model-based quantities are still used to evaluate whether the implied assumptions about the data generating process are plausible. Often, this judgment evolves over several iterations as the analyst becomes more familiar with the model and the study design.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</section>
<section id="practice-5" class="level3">
<h3 class="anchored" data-anchor-id="practice-5">PRACTICE</h3>
<p>All parameter values in our present case study have been determined based on repeated discussions with domain experts in radiology to validate our assumptions. Initially, we reviewed the literature to establish a reasonable baseline performance rate for examining head CT scans for intracranial hemorrhage. Existing studies indicate that radiologists typically demonstrate high accuracies around 90%, while interns have been shown to perform below 80%, and medical students fall even shorter. For simplicity, we assumed plausible probability values of .90 for experts and .70 for students, respectively. Our experts confirmed that these values are realistic baselines for reviewing diverse head CT images without AI assistance. Subsequently, we consulted several published papers investigating the effect of correct and incorrect advice on decision-making performance in other settings. From their findings, we inferred that both experts and students should benefit from correct and suffer losses from incorrect advice. However, the magnitude of these effects should be substantially greater for students, given their stronger reliance on advice compared to experts. We further validated the plausibility of our estimated gains and losses with the collaborating radiologists until we settled on the probabilities shown in Table 2.</p>
</section>
</section>
<section id="step-4-estimate-the-statistical-model" class="level2">
<h2 class="anchored" data-anchor-id="step-4-estimate-the-statistical-model">Step 4: Estimate the statistical model</h2>
<section id="theory-6" class="level3">
<h3 class="anchored" data-anchor-id="theory-6">THEORY</h3>
<p>At this point, the researcher is capable of producing a simulated dataset that is comparable to the actual dataset to be collected in the planned study. The next step is to specify how the statistical model shall be estimated in the actual study collected later. This requires the selection of a statistical framework, a software package that is capable of estimating the model class of interest, an estimation algorithm, and the specific model structure including all fixed effects, random effects, and the model family of the dependent variable.</p>
<p>Note that this does not always mean that one will specify the same GLMM that was used when specifying the data-generating process. On the one hand, using a simpler model for data simulation than for model estimation can be a useful strategy in scenarios where making plausible assumptions for complicated random effect structures and interactions is not feasible, or the omitted components are expected to have small effects <span class="citation" data-cites="matuschekBalancingTypeError2017">(<a href="#ref-matuschekBalancingTypeError2017" role="doc-biblioref">Matuschek et al., 2017</a>)</span>. On the other hand, using a more complex model for data simulation than for model estimation can be a useful strategy in scenarios where one has specific domain knowledge about aspects of the data-generating process that are still difficult to estimate with the current state-of-the-art in multilevel modeling. In fact, applying models that are more parsimonious than the true data generating process can provide a better trade-off between type I error rates (or bias) and power (or precision) in many scenarios <span class="citation" data-cites="matuschekBalancingTypeError2017">(<a href="#ref-matuschekBalancingTypeError2017" role="doc-biblioref">Matuschek et al., 2017</a>)</span>.</p>
</section>
<section id="practice-6" class="level3">
<h3 class="anchored" data-anchor-id="practice-6">PRACTICE</h3>
<p>In our case study, we use the <em>lme4</em> R package <span class="citation" data-cites="batesFittingLinearMixedEffects2015">(<a href="#ref-batesFittingLinearMixedEffects2015" role="doc-biblioref">Bates et al., 2015</a>)</span>, which is a state-of-the-art tool for fitting frequentist GLMMs.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> For the current example, we simulate data according to our model, in which 100 subjects respond to 50 items (we use <code>set.seed</code> to make the simulation reproducible). However, for the sake of the exercise, we can imagine that this would be real data resulting from our future experiment and think about how we would analyze this data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">simulate</span>(<span class="at">n_subjects =</span> <span class="dv">100</span>, <span class="at">n_items =</span> <span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <em>lme4</em> package uses a special syntax for model specification. Our specific GLMM is represented by the formula:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> y_bin <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> expert <span class="sc">+</span> advice_present <span class="sc">+</span> advice_correct <span class="sc">+</span> </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  expert<span class="sc">:</span>advice_present <span class="sc">+</span> expert<span class="sc">:</span>advice_correct <span class="sc">+</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">1</span><span class="sc">|</span>subject) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>item)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The first two lines look similar to any linear model in R (general intercept indicated by <code>1</code>; main effects indicated by variable names in the dataset; interactions indicated by <code>variable1:variable2</code>). The third line specifies a random intercept for each subject <code>(1|subject)</code> and for each item <code>(1|item)</code>. The complete set of rules for the syntax is outlined in <span class="citation" data-cites="batesFittingLinearMixedEffects2015">Bates et al. (<a href="#ref-batesFittingLinearMixedEffects2015" role="doc-biblioref">2015</a>)</span> and in the documentation of the <em>lme4</em> package.</p>
<p>In <em>lme4</em>, a GLMM is fitted with the <code>glmer</code> function. By setting <code>family =  "binomial"</code>, we request a binomial GLMM appropriate for our binary dependent variable <code>y_bin</code> (the binomial GLMM uses the canonical logit link by default), which is defined as an accurate (1) vs.&nbsp;inaccurate (0) diagnosis. We use the default estimation algorithm (see <code>?glmerControl</code> for a list of alternative options).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">glmer</span>(f, <span class="at">data =</span> dat, <span class="at">family =</span> <span class="st">"binomial"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can inspect the estimates for all model parameters with the <code>summary</code> command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: 
y_bin ~ 1 + expert + advice_present + advice_correct + expert:advice_present +  
    expert:advice_correct + (1 | subject) + (1 | item)
   Data: dat

     AIC      BIC   logLik deviance df.resid 
  4149.4   4201.6  -2066.7   4133.4     4992 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-5.7669  0.2125  0.3046  0.4317  2.1056 

Random effects:
 Groups  Name        Variance Std.Dev.
 subject (Intercept) 0.3148   0.5611  
 item    (Intercept) 0.1624   0.4029  
Number of obs: 5000, groups:  subject, 100; item, 50

Fixed effects:
                      Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)             1.0339     0.1103   9.374  &lt; 2e-16 ***
expert                  1.1849     0.2096   5.654 1.57e-08 ***
advice_present         -1.3436     0.1206 -11.143  &lt; 2e-16 ***
advice_correct          2.6154     0.1273  20.540  &lt; 2e-16 ***
expert:advice_present   1.0589     0.2940   3.601 0.000317 ***
expert:advice_correct  -1.8104     0.2915  -6.210 5.28e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) expert advc_p advc_c exprt:dvc_p
expert      -0.377                                 
advic_prsnt -0.349  0.176                          
advic_crrct  0.023  0.001 -0.668                   
exprt:dvc_p  0.143 -0.448 -0.412  0.276            
exprt:dvc_c -0.008  0.004  0.292 -0.435 -0.686     </code></pre>
</div>
</div>
<p>In the model output, the <code>Estimate</code> column in the <code>Fixed effects</code> table contains the estimates for the <span class="math inline">\(\beta\)</span> parameters, while the <code>Std.Dev.</code> column in the <code>Random effects</code> table contains the estimates for <span class="math inline">\(\sigma_S\)</span> and <span class="math inline">\(\sigma_I\)</span>.</p>
</section>
</section>
<section id="step-5-compute-the-estimate" class="level2">
<h2 class="anchored" data-anchor-id="step-5-compute-the-estimate">Step 5: Compute the estimate</h2>
<section id="theory-7" class="level3">
<h3 class="anchored" data-anchor-id="theory-7">THEORY</h3>
<p>In previous steps, we have defined the theoretical estimand, written a data simulation function and specified how to estimate a GLMM using simulated data. The next step is to specify how to compute a concrete point estimate of the theoretical estimand within the framework of the fitted GLMM. For some research questions, the estimate corresponds with a single regression coefficient. In more complicated scenarios, the estimate is computed from a combination of coefficients. Beyond computing the point estimate, we have already discussed that both hypothesis testing and interval estimation could be used to answer the research question. The decision on testing or estimating is then followed by selecting the specific statistical method that shall be applied to compute the HTs or CIs (e.g., compute HTs and CIs with the <em>marginaleffects</em> R package using the delta method).</p>
</section>
<section id="practice-7" class="level3">
<h3 class="anchored" data-anchor-id="practice-7">PRACTICE</h3>
<p>In the estimand section, we have translated a verbal description of our research question into four probability statements that are specified outside of any specific statistical model. For a concrete estimate within the context of our specified GLMM, we must compute the following probability contrasts:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
&amp; \quad - P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0)
\end{aligned}
\]</span> <span class="math display">\[
\begin{aligned}
&amp; P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
&amp; \quad - P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0)
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp; P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
&amp; \quad - P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp; P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
&amp; \quad - P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
\end{aligned}
\]</span> We have already discussed how to compute the involved probabilities in the section on specifying population parameters. Plugging in the GLMM model equation produces an equation for computing each contrast if all model parameters were known. When we want to estimate the above contrasts based on observed data, the only difference is that model parameters are not known and we instead use the corresponding parameter estimates.</p>
<p>We could use our knowledge of the structure of the GLMM to determine the exact formula needed to compute the contrasts of interest and then plug in the parameter estimates manually from the <code>summary(fit)</code> output. However, this would be tedious and we can use R to compute this contrast without doing the math. Using the first contrast <em>(correct advice, expert) - (no advice, expert)</em> as our example, we could apply the <code>predict</code> function of the <em>lme4</em> package to compute the predicted probability for a correct diagnosis based on our fitted model, plug in the two sets of predictor values, and compute the difference between the two estimated probabilities.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>grid1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">advice_present =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="at">advice_correct =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">expert =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>grid1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  advice_present advice_correct expert
1              1              1      1
2              0              0      1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit, <span class="at">newdata =</span> grid1, <span class="at">type =</span> <span class="st">"response"</span>, <span class="at">re.form =</span> <span class="cn">NA</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1        2 
0.939292 0.901923 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>pred[<span class="dv">1</span>] <span class="sc">-</span> pred[<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         1 
0.03736901 </code></pre>
</div>
</div>
<p>The argument <code>type = "response"</code> specifies that predictions are made on the probability scale (instead of the log-odds scale of the <span class="math inline">\(\beta\)</span> parameters), while <code>re.form = NA</code> sets all random effects to 0. We could use this method to compute point estimates for all four contrasts that are part of our estimand. However, depending on whether we are interested in hypothesis testing or parameter estimation, we also need a method to compute HTs or CIs. The <em>marginaleffects</em> package <span class="citation" data-cites="R-marginaleffects">(<a href="#ref-R-marginaleffects" role="doc-biblioref">Arel-Bundock et al., Forthcoming</a>)</span> is a very flexible, increasingly popular package to compute HTs and CIs for contrasts with a variety of statistical models, including GLMMs estimated with <em>lme4</em>. First, we specify a grid of all combinations of predictor variables and then compute estimated probabilities for all experimental conditions in our experiment with the <code>predictions</code> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(marginaleffects)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tinytable)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>grid2 <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(<span class="at">advice_present =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">advice_correct =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, <span class="at">expert =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>grid2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 8 × 3
  advice_present advice_correct expert
           &lt;int&gt;          &lt;int&gt;  &lt;int&gt;
1              0              0      0
2              0              0      1
3              0              1      0
4              0              1      1
5              1              0      0
6              1              0      1
7              1              1      0
8              1              1      1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predictions</span>(fit, <span class="at">newdata =</span> grid2, </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">"response"</span>, <span class="at">re.form =</span> <span class="cn">NA</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(preds, <span class="at">style =</span> <span class="st">"tinytable"</span>) <span class="sc">%&gt;%</span> <span class="fu">theme_tt</span>(<span class="at">theme =</span> <span class="st">"resize"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
 

  
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tinytable_wctp02o7pc0nmd03q7fo</title>
    <style>
.table td.tinytable_css_2770xiqe0dzj21uwmbms, .table th.tinytable_css_2770xiqe0dzj21uwmbms {    border-bottom: solid 0.1em #d3d8dc; }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
  

  
    <div class="container">
      <table class="table table-borderless" id="tinytable_wctp02o7pc0nmd03q7fo" style="width: auto; margin-left: auto; margin-right: auto;" data-quarto-disable-processing="true">
        <thead>
        
              <tr>
                <th scope="col">Estimate</th>
                <th scope="col">Std. Error</th>
                <th scope="col">z</th>
                <th scope="col">Pr(&gt;|z|)</th>
                <th scope="col">S</th>
                <th scope="col">2.5 %</th>
                <th scope="col">97.5 %</th>
                <th scope="col">advice_present</th>
                <th scope="col">advice_correct</th>
                <th scope="col">expert</th>
              </tr>
        </thead>
        <tfoot><tr><td colspan="10">Type:  response 
</td></tr>
<tr><td colspan="10">Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, advice_present, advice_correct, expert, y_bin 
</td></tr></tfoot>
        <tbody>
                <tr>
                  <td>0.738</td>
                  <td>0.02134</td>
                  <td> 34.6</td>
                  <td>&lt;0.001</td>
                  <td>867.2</td>
                  <td>0.696</td>
                  <td>0.779</td>
                  <td>0</td>
                  <td>0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.902</td>
                  <td>0.01739</td>
                  <td> 51.9</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.868</td>
                  <td>0.936</td>
                  <td>0</td>
                  <td>0</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>0.975</td>
                  <td>0.00421</td>
                  <td>231.6</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.966</td>
                  <td>0.983</td>
                  <td>0</td>
                  <td>1</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.954</td>
                  <td>0.01454</td>
                  <td> 65.6</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.925</td>
                  <td>0.982</td>
                  <td>0</td>
                  <td>1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>0.423</td>
                  <td>0.03221</td>
                  <td> 13.1</td>
                  <td>&lt;0.001</td>
                  <td>128.6</td>
                  <td>0.360</td>
                  <td>0.486</td>
                  <td>1</td>
                  <td>0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.874</td>
                  <td>0.02793</td>
                  <td> 31.3</td>
                  <td>&lt;0.001</td>
                  <td>711.4</td>
                  <td>0.819</td>
                  <td>0.928</td>
                  <td>1</td>
                  <td>0</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td>0.909</td>
                  <td>0.00967</td>
                  <td> 94.1</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.890</td>
                  <td>0.928</td>
                  <td>1</td>
                  <td>1</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td>0.939</td>
                  <td>0.01091</td>
                  <td> 86.1</td>
                  <td>&lt;0.001</td>
                  <td>Inf</td>
                  <td>0.918</td>
                  <td>0.961</td>
                  <td>1</td>
                  <td>1</td>
                  <td>1</td>
                </tr>
        </tbody>
      </table>
    </div>

    <script>
      function styleCell_tinytable_qgghjysbdyzofyawkk7w(i, j, css_id) {
        var table = document.getElementById("tinytable_wctp02o7pc0nmd03q7fo");
        table.rows[i].cells[j].classList.add(css_id);
      }
      function insertSpanRow(i, colspan, content) {
        var table = document.getElementById('tinytable_wctp02o7pc0nmd03q7fo');
        var newRow = table.insertRow(i);
        var newCell = newRow.insertCell(0);
        newCell.setAttribute("colspan", colspan);
        // newCell.innerText = content;
        // this may be unsafe, but innerText does not interpret <br>
        newCell.innerHTML = content;
      }
      function spanCell_tinytable_qgghjysbdyzofyawkk7w(i, j, rowspan, colspan) {
        var table = document.getElementById("tinytable_wctp02o7pc0nmd03q7fo");
        const targetRow = table.rows[i];
        const targetCell = targetRow.cells[j];
        for (let r = 0; r < rowspan; r++) {
          // Only start deleting cells to the right for the first row (r == 0)
          if (r === 0) {
            // Delete cells to the right of the target cell in the first row
            for (let c = colspan - 1; c > 0; c--) {
              if (table.rows[i + r].cells[j + c]) {
                table.rows[i + r].deleteCell(j + c);
              }
            }
          }
          // For rows below the first, delete starting from the target column
          if (r > 0) {
            for (let c = colspan - 1; c >= 0; c--) {
              if (table.rows[i + r] && table.rows[i + r].cells[j]) {
                table.rows[i + r].deleteCell(j);
              }
            }
          }
        }
        // Set rowspan and colspan of the target cell
        targetCell.rowSpan = rowspan;
        targetCell.colSpan = colspan;
      }

window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 0, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 1, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 2, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 3, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 4, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 5, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 6, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 7, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 8, 'tinytable_css_2770xiqe0dzj21uwmbms') })
window.addEventListener('load', function () { styleCell_tinytable_qgghjysbdyzofyawkk7w(0, 9, 'tinytable_css_2770xiqe0dzj21uwmbms') })
    </script>

  


</div>
</div>
<p>The point estimates for all experimental conditions are reported in the <code>Estimate</code> column. Note that the output also contains the two missing by design conditions that will never be observed in the actual study (<span class="math inline">\(advice\_present = 0, advice\_correct = 1, expert = 1\)</span> and <span class="math inline">\(advice\_present = 0, advice\_correct = 1, expert = 0\)</span>). This is no problem as long as we never interpret those estimates. Next, we use the estimated probabilities to compute the four specific contrasts that are part of our estimand. For this, we must specify which rows in <code>preds</code> have to be subtracted from each other. We will use the <code>hypotheses</code> function to compute our four contrasts of interest together with HTs and CIs. We use the default inference options of the <em>marginaleffects</em> package that compute HTs and CIs based on the approximate delta method.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>contrasts <span class="ot">&lt;-</span> preds <span class="sc">%&gt;%</span> </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypotheses</span>(<span class="at">hypothesis =</span> <span class="fu">c</span>(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"b8 = b2"</span>,  <span class="co"># (correct advice, expert) - (no advice, expert)</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"b2 = b6"</span>,  <span class="co"># (no advice, expert) - (incorrect advice, expert) </span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"b7 = b1"</span>,  <span class="co"># (correct advice, student) - (no advice, student)</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"b1 = b5"</span>), <span class="co"># (no advice, student) - (incorrect advice, student)</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">equivalence =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(contrasts, <span class="at">style =</span> <span class="st">"tinytable"</span>) <span class="sc">%&gt;%</span> <span class="fu">theme_tt</span>(<span class="at">theme =</span> <span class="st">"resize"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
 

  
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tinytable_ns4lfqa07u3am44tgx8z</title>
    <style>
.table td.tinytable_css_8qlhhei2cg8e1fcn86q3, .table th.tinytable_css_8qlhhei2cg8e1fcn86q3 {    border-bottom: solid 0.1em #d3d8dc; }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
  

  
    <div class="container">
      <table class="table table-borderless" id="tinytable_ns4lfqa07u3am44tgx8z" style="width: auto; margin-left: auto; margin-right: auto;" data-quarto-disable-processing="true">
        <thead>
        
              <tr>
                <th scope="col">Term</th>
                <th scope="col">Estimate</th>
                <th scope="col">Std. Error</th>
                <th scope="col">z</th>
                <th scope="col">Pr(&gt;|z|)</th>
                <th scope="col">S</th>
                <th scope="col">2.5 %</th>
                <th scope="col">97.5 %</th>
                <th scope="col">p (NonSup)</th>
                <th scope="col">p (NonInf)</th>
                <th scope="col">p (Equiv)</th>
              </tr>
        </thead>
        <tfoot><tr><td colspan="11">Type:  response 
</td></tr>
<tr><td colspan="11">Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv 
</td></tr></tfoot>
        <tbody>
                <tr>
                  <td>b8=b2</td>
                  <td>0.0374</td>
                  <td>0.0162</td>
                  <td> 2.31</td>
                  <td>0.021</td>
                  <td>5.6</td>
                  <td> 0.00563</td>
                  <td>0.0691</td>
                  <td>0.989</td>
                  <td>0.0105</td>
                  <td>0.989</td>
                </tr>
                <tr>
                  <td>b2=b6</td>
                  <td>0.0282</td>
                  <td>0.0279</td>
                  <td> 1.01</td>
                  <td>0.312</td>
                  <td>1.7</td>
                  <td>-0.02653</td>
                  <td>0.0830</td>
                  <td>0.844</td>
                  <td>0.1562</td>
                  <td>0.844</td>
                </tr>
                <tr>
                  <td>b7=b1</td>
                  <td>0.1717</td>
                  <td>0.0173</td>
                  <td> 9.93</td>
                  <td>&lt;0.001</td>
                  <td>74.8</td>
                  <td> 0.13780</td>
                  <td>0.2056</td>
                  <td>1.000</td>
                  <td>&lt;0.001</td>
                  <td>1.000</td>
                </tr>
                <tr>
                  <td>b1=b5</td>
                  <td>0.3145</td>
                  <td>0.0280</td>
                  <td>11.24</td>
                  <td>&lt;0.001</td>
                  <td>95.0</td>
                  <td> 0.25965</td>
                  <td>0.3693</td>
                  <td>1.000</td>
                  <td>&lt;0.001</td>
                  <td>1.000</td>
                </tr>
        </tbody>
      </table>
    </div>

    <script>
      function styleCell_tinytable_ki7fb35ggvtj62v5xux8(i, j, css_id) {
        var table = document.getElementById("tinytable_ns4lfqa07u3am44tgx8z");
        table.rows[i].cells[j].classList.add(css_id);
      }
      function insertSpanRow(i, colspan, content) {
        var table = document.getElementById('tinytable_ns4lfqa07u3am44tgx8z');
        var newRow = table.insertRow(i);
        var newCell = newRow.insertCell(0);
        newCell.setAttribute("colspan", colspan);
        // newCell.innerText = content;
        // this may be unsafe, but innerText does not interpret <br>
        newCell.innerHTML = content;
      }
      function spanCell_tinytable_ki7fb35ggvtj62v5xux8(i, j, rowspan, colspan) {
        var table = document.getElementById("tinytable_ns4lfqa07u3am44tgx8z");
        const targetRow = table.rows[i];
        const targetCell = targetRow.cells[j];
        for (let r = 0; r < rowspan; r++) {
          // Only start deleting cells to the right for the first row (r == 0)
          if (r === 0) {
            // Delete cells to the right of the target cell in the first row
            for (let c = colspan - 1; c > 0; c--) {
              if (table.rows[i + r].cells[j + c]) {
                table.rows[i + r].deleteCell(j + c);
              }
            }
          }
          // For rows below the first, delete starting from the target column
          if (r > 0) {
            for (let c = colspan - 1; c >= 0; c--) {
              if (table.rows[i + r] && table.rows[i + r].cells[j]) {
                table.rows[i + r].deleteCell(j);
              }
            }
          }
        }
        // Set rowspan and colspan of the target cell
        targetCell.rowSpan = rowspan;
        targetCell.colSpan = colspan;
      }

window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 0, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 1, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 2, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 3, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 4, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 5, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 6, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 7, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 8, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 9, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
window.addEventListener('load', function () { styleCell_tinytable_ki7fb35ggvtj62v5xux8(0, 10, 'tinytable_css_8qlhhei2cg8e1fcn86q3') })
    </script>

  


</div>
</div>
<p>The expression <code>"b8 = b2"</code> is special syntax to subtract the estimate in row number 8 from the estimate in row number 2 in the <code>preds</code>-output. The argument <code>equivalence = c(0, 0)</code> can be used to compute one-sided p-values, testing whether the contrast in the population is smaller than 0 (<code>p (NonSub)</code> column) or greater than 0 (<code>p (NonInf)</code> column). The point estimates for four contrasts are reported in the <code>Estimate</code> column. Note that to facilitate interpretation, we arranged the contrasts in a way that we theoretically expect positive values for all four of them.</p>
<p><strong>Hypothesis testing.</strong> If we chose hypothesis testing for our case study, we would test a combined null hypothesis <span class="math inline">\(H_0\)</span> that consists of four separate null hypotheses: <span class="math display">\[
\begin{aligned}
H_{01}:\ &amp; P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 1, u_{0s} = 0, u_{0i} = 0) \leq \\
&amp; P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
H_{02}:\ &amp;P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \leq \\
&amp; P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 1, u_{0s} = 0, u_{0i} = 0) \\
H_{03}:\ &amp;P(Y=1|advice\_present = 1, advice\_correct = 1, expert = 0, u_{0s} = 0, u_{0i} = 0) \leq \\
&amp; P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \\
H_{04}:\ &amp; P(Y=1|advice\_present = 0, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0) \leq \\
&amp; P(Y=1|advice\_present = 1, advice\_correct = 0, expert = 0, u_{0s} = 0, u_{0i} = 0)
\end{aligned}
\]</span> The combined null hypothesis <span class="math inline">\(H_0\)</span> should only be rejected if <strong>all</strong> individual null hypotheses are rejected <span class="citation" data-cites="dmitrienkoTraditionalMultiplicityAdjustment2013">(i.e., intersection-union setting; <a href="#ref-dmitrienkoTraditionalMultiplicityAdjustment2013" role="doc-biblioref">Dmitrienko &amp; D’Agostino, 2013</a>)</span>. In such cases, the error probabilities do not accumulate, and we would waste power when correcting for multiple tests.</p>
<p>With a standard significance level of <span class="math inline">\(\alpha = 0.05\)</span>, we would not reject all four null hypotheses (the p-value in the <code>p (NonInf)</code> column for the second hypothesis is not significant) and therefore also not reject the combined null hypothesis for this particular (simulated) dataset. Note that this decision would be wrong because we have simulated the data such that the combined alternative hypothesis <span class="math inline">\(H_1\)</span> is actually true in the population.</p>
<p><strong>Interval estimation.</strong> If we chose parameter estimation for our case study, we would focus on the two-sided CIs of the four contrasts of interest. With a standard confidence level of <span class="math inline">\(1 - \alpha = 0.95\)</span> plausible values are clearly in the positive range for the first, third, and fourth contrast, while both negative and positive values seem plausible for the second contrast. Note that due to the constrained range of the probability scale, the width of the CI differs between the four contrasts (which is the expected behavior for binomial GLMMs). The smallest width is observed for the first contrast (expert with correct advice vs.&nbsp;expert without advice), where both underlying probabilities are close to 1. The largest width is observed for the fourth contrast (student with incorrect advice vs.&nbsp;student without advice), where both underlying probabilities are closer to 0.5.</p>
</section>
</section>
<section id="step-6-perform-repeated-simulations" class="level2">
<h2 class="anchored" data-anchor-id="step-6-perform-repeated-simulations">Step 6: Perform repeated simulations</h2>
<section id="theory-8" class="level3">
<h3 class="anchored" data-anchor-id="theory-8">THEORY</h3>
<p>Conducting all previous steps enables the analyst to 1) simulate a dataset, 2) estimate a GLMM, and 3) compute HTs or CIs for estimands of interest, mirroring the analysis that will later be conducted on the actual dataset of the planned study. To produce an estimate of power or precision, the last step is to perform these previous steps repeatedly. On a conceptual level, we first require a function that takes a sample size and a full set of population parameter values as input. When planning for power, the function should return the p-value(s) of the HT(s) of interest when conducted on the simulated dataset. When planning for precision, the function should return the width of the CI(s) of interest. Second, we run this function repeatedly with the same sample size and population parameters. Because fitting GLMMs can quickly become time-consuming, it is recommended to use parallel computing, that is running simulations on multiple cores of the computer at the same time to reduce total run time. Third, the results of the repeated simulation are collected and aggregated. When planning for power, we compute the relative frequency of (a) significant p-value(s) across repeated simulations. When planning for precision, we compute the average width of the CI(s). Finally, we repeat the complete simulation for different sample sizes to determine how big the sample must be in order to achieve the targeted power or precision.</p>
</section>
<section id="practice-8" class="level3">
<h3 class="anchored" data-anchor-id="practice-8">PRACTICE</h3>
<p>Wrapping the <code>simulate</code> function already constructed earlier, the helper function <code>sim_and_analyse</code> performs all previous steps (simulate a dataset, fit a GLMM, compute p-values and CIs) in a single command.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>sim_and_analyse <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula_chr =</span> <span class="st">"y_bin ~ 1 + expert + advice_present + advice_correct + </span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="st">    expert:advice_present + expert:advice_correct + (1|subject) + (1|item)"</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">"b8 = b2"</span>, <span class="st">"b2 = b6"</span>, <span class="st">"b7 = b1"</span>, <span class="st">"b1 = b5"</span>), ...){</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(lme4)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(marginaleffects)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(tidyr)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># simulate data</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>  dat <span class="ot">&lt;-</span> <span class="fu">simulate</span>(...)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># fit model</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>  model <span class="ot">&lt;-</span> <span class="fu">glmer</span>(<span class="fu">as.formula</span>(formula_chr), <span class="at">data =</span> dat, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute contrasts</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>  contr_df <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(<span class="at">advice_present =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>, <span class="at">advice_correct =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>,</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">expert =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predictions</span>(model, <span class="at">newdata =</span> contr_df, <span class="at">type =</span> <span class="st">"response"</span>, <span class="at">re.form =</span> <span class="cn">NA</span>) <span class="sc">%&gt;%</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">hypotheses</span>(<span class="at">hypothesis =</span> contrasts, <span class="at">equivalence =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>()</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use the <em>future</em> <span class="citation" data-cites="R-RJ-2021-048">(<a href="#ref-R-RJ-2021-048" role="doc-biblioref">Bengtsson, 2021</a>)</span> and <em>furrr</em> <span class="citation" data-cites="R-furrr">(<a href="#ref-R-furrr" role="doc-biblioref">Vaughan &amp; Dancho, 2022</a>)</span> packages to perform computations in parallel. First, we enable parallelization with the <code>plan</code> function and specify how many parallel cores (“workers”) of our computer to use (users can find out the maximum number of cores on their computer with the command <code>parallel::detectCores()</code>), and set a seed to make the simulation reproducible.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(future)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plan</span>(<span class="st">"multisession"</span>, <span class="at">workers =</span> <span class="dv">6</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The next code chunk specifies a simulation grid with different settings for both the number of subjects (<code>n_subjects</code>) and the number of items (<code>n_items</code>), each combination being repeated <code>rep</code> times. The more repetitions, the more accurately power and precision can be estimated. We chose 300 repetitions for the data simulation at hand to strike a balance between achieving a robust estimate and remaining computationally feasible. With the current settings, this simulation takes several hours on a MacBook Pro from 2020 with M1 chip and 16 GB working memory. If you want to quickly experiment with the code yourself, a setting with <code>workers = 4</code> and <code>rep = 5</code> should finish in less than 5 minutes, even on smaller machines.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(furrr)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>sim_result <span class="ot">&lt;-</span> <span class="fu">crossing</span>(</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">rep =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_subjects =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>, <span class="dv">250</span>),</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_items =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">30</span>, <span class="dv">50</span>, <span class="dv">70</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">res =</span> <span class="fu">future_pmap</span>(., sim_and_analyse, </span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">.options =</span> <span class="fu">furrr_options</span>(<span class="at">seed =</span> <span class="cn">TRUE</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">col =</span> res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The result of this computation is a data frame that contains the p-values and CIs of all specified contrasts for each simulated dataset. In some iterations (predominantly in conditions with small sample sizes), model estimation did not converge with the <em>lme4</em> package. When the model fails to converge, it means that the statistical model being fitted to the data failed to reach a stable or valid solution during the estimation process. We do not remove these results because non-convergence can also happen when analyzing the real data we plan to collect, thus, we want to factor in this possibility to keep our simulation more realistic.</p>
<p><strong>Power results.</strong> For our exemplary combined hypothesis, power is defined as the (long-run) percentage of simulations in which all four p-values of our individual hypotheses are significant at the <span class="math inline">\(\alpha = 0.05\)</span> level. Based on our simulation outcomes, we compute a power estimate for each combination of <code>n_subjects</code> <span class="math inline">\(\times\)</span> <code>n_items</code> (including 95% CIs) and visualize the results with the following code.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div id="cell-fig-finalpwr" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(binom)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> sim_result <span class="sc">%&gt;%</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> term, <span class="at">names_sep =</span> <span class="st">"_"</span>, </span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_from =</span> estimate<span class="sc">:</span>p.value.equiv) <span class="sc">%&gt;%</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(n_subjects, n_items) <span class="sc">%&gt;%</span> </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">power =</span> <span class="fu">mean</span>(<span class="st">`</span><span class="at">p.value.noninf_b1=b5</span><span class="st">`</span> <span class="sc">&lt;</span> alpha <span class="sc">&amp;</span> </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">`</span><span class="at">p.value.noninf_b8=b2</span><span class="st">`</span> <span class="sc">&lt;</span> alpha <span class="sc">&amp;</span> <span class="st">`</span><span class="at">p.value.noninf_b2=b6</span><span class="st">`</span> <span class="sc">&lt;</span> alpha <span class="sc">&amp;</span> </span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">`</span><span class="at">p.value.noninf_b7=b1</span><span class="st">`</span> <span class="sc">&lt;</span> alpha), </span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_sig =</span> <span class="fu">sum</span>(<span class="st">`</span><span class="at">p.value.noninf_b1=b5</span><span class="st">`</span> <span class="sc">&lt;</span> alpha <span class="sc">&amp;</span> </span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">`</span><span class="at">p.value.noninf_b8=b2</span><span class="st">`</span> <span class="sc">&lt;</span> alpha <span class="sc">&amp;</span> <span class="st">`</span><span class="at">p.value.noninf_b2=b6</span><span class="st">`</span> <span class="sc">&lt;</span> alpha <span class="sc">&amp;</span> </span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">`</span><span class="at">p.value.noninf_b7=b1</span><span class="st">`</span> <span class="sc">&lt;</span> alpha),</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">n =</span> <span class="fu">n</span>(),</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci.lwr =</span> <span class="fu">binom.confint</span>(n_sig, n, <span class="at">method =</span> <span class="st">"wilson"</span>)<span class="sc">$</span>lower,</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci.upr =</span> <span class="fu">binom.confint</span>(n_sig, n, <span class="at">method =</span> <span class="st">"wilson"</span>)<span class="sc">$</span>upper, </span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">.groups =</span> <span class="st">"drop"</span>)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>power <span class="sc">%&gt;%</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(n_subjects, n_items), factor)) <span class="sc">%&gt;%</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n_subjects, n_items, <span class="at">fill =</span> power)) <span class="sc">+</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">sprintf</span>(<span class="st">"%.2f </span><span class="sc">\n</span><span class="st"> [%.2f; %.2f]"</span>, </span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>                                power, ci.lwr, ci.upr)), </span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"white"</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_viridis_c</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"number of subjects"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"number of items"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-finalpwr" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-finalpwr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="manuscript_files/figure-html/fig-finalpwr-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Simulation-based power estimates including 95% confidence interval of the case study for different numbers of subjects and items, based on a significance level of 0.05."><img src="manuscript_files/figure-html/fig-finalpwr-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-finalpwr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Simulation-based power estimates including 95% confidence interval of the case study for different numbers of subjects and items, based on a significance level of 0.05.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As should be the case, power estimates in <a href="#fig-finalpwr" class="quarto-xref">Figure&nbsp;4</a> increase with both the number of subjects and the number of items. The CIs reported here indicate how precisely power was estimated by our simulation. Higher precision (which would be reflected in narrower CIs) could be obtained by increasing the number of repetitions (<code>rep</code>) in the simulation. In practice, data simulations are often run multiple times with adjusted combinations of sample sizes. When running for the first time, it might be revealed that power is way too low (or much higher than required) for some combinations of <code>n_subjects</code> and <code>n_items</code>. When narrowing down the best combination that achieves sufficient power while at the same time striking a good balance of how many subjects and items are practically feasible, later rounds of data simulation will typically include a smaller grid of sample sizes combined with a higher number of repetitions. This will assure high precision for the final power estimates, which are then used for the sample size justification of the planned study.</p>
<p>When target power has been specified, the number of subjects and the number of items in our study design can be traded against each other based on practical considerations. Although it is recommended to justify the power <span class="citation" data-cites="lakensSampleSizeJustification2022">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>, we adopt the common heuristic to target a power of 0.8 to detect an effect of the expected size implied by our data simulation. This could be achieved by collecting data from 250 subjects (about 25% of which will be experts), each completing the same 50 items (with advice present in about 67% of cases, which is correct in about 80% of cases with present advice). If collecting data from 250 subjects is not feasible, an alternative would be to recruit 200 subjects but increase the length of the experiment to 70 items. However, 70 items might take too long to complete for the radiologists participating in the study, who have a busy schedule. The simulation suggests that it might also be possible to plan a shorter experiment with only 30 items if it is feasible to recruit an even higher number of subjects (to be determined by additional rounds of power analysis). Design parameters that also affect power, and which could be investigated in the simulation to find a more optimal trade-off, are the ratio of experts to students, the frequency of whether advice is presented at all, and whether it is correct or incorrect.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p><strong>Precision results.</strong> When planning for precision, one could monitor the width of all four CIs at the same time. However, because the CIs of the four contrasts strongly differ in width, it is not trivial to decide which width one should target when deciding on the appropriate sample size. In contrast to planning for power, there are no common standards on how to specify the targeted precision <span class="citation" data-cites="lakensSampleSizeJustification2022">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>. For our example, we use a simple heuristic but we strongly encourage readers to think about better alternatives that are appropriate in their own applications. Our simulations show that the smallest CI can be expected for the first contrast (expert with correct advice vs.&nbsp;expert without advice). The true contrast in probability for an average expert and an average item in this condition is <code>plogis(b_0 + b_e + b_a + b_c + b_ea + b_ec) - plogis(b_0 + b_e) =</code> <span class="math inline">\(0.05\)</span>. We want the width of this CI to be smaller than 0.1. This would mean that if the point estimate happens to be close to the true value, the plausible values inside of a 95% CI would all be positive.</p>
<p>Thus in our example, precision is defined as the (long-run) average width of a 95% CI for the probability contrast between experts with correct advice and experts without advice. Of course, a lower width implies better precision. Based on our simulation outcomes, we compute the precision estimate for each combination of <code>n_subjects</code> <span class="math inline">\(\times\)</span> <code>n_items</code> (including 95% CIs) and visualize the results with the following code.</p>
<div id="cell-fig-finalprecision" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>precision <span class="ot">&lt;-</span> sim_result <span class="sc">%&gt;%</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> term, <span class="at">names_sep =</span> <span class="st">"_"</span>, </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">values_from =</span> estimate<span class="sc">:</span>p.value.equiv) <span class="sc">%&gt;%</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(n_subjects, n_items) <span class="sc">%&gt;%</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">width =</span> <span class="st">`</span><span class="at">conf.high_b8=b2</span><span class="st">`</span> <span class="sc">-</span> <span class="st">`</span><span class="at">conf.low_b8=b2</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">precision =</span> <span class="fu">mean</span>(width),</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci.lwr =</span> <span class="fu">t.test</span>(width)<span class="sc">$</span>conf.int[<span class="dv">1</span>],</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">ci.upr =</span> <span class="fu">t.test</span>(width)<span class="sc">$</span>conf.int[<span class="dv">2</span>], </span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">.groups =</span> <span class="st">"drop"</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>precision <span class="sc">%&gt;%</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(n_subjects, n_items), factor)) <span class="sc">%&gt;%</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(n_subjects, n_items, <span class="at">fill =</span> precision)) <span class="sc">+</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">sprintf</span>(<span class="st">"%.2f </span><span class="sc">\n</span><span class="st"> [%.2f; %.2f]"</span>, </span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>                                precision, ci.lwr, ci.upr)), </span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"white"</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_viridis_c</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>), <span class="at">direction =</span> <span class="sc">-</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">fill =</span> <span class="fu">guide_colourbar</span>(<span class="at">reverse =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"number of subjects"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"number of items"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-finalprecision" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-finalprecision-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="manuscript_files/figure-html/fig-finalprecision-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Simulation-based precision estimates (expected width of confidence intervals) including 95% confidence interval of the case study for different numbers of subjects and items, based on a confidence level of 0.95."><img src="manuscript_files/figure-html/fig-finalprecision-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-finalprecision-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Simulation-based precision estimates (expected width of confidence intervals) including 95% confidence interval of the case study for different numbers of subjects and items, based on a confidence level of 0.95.
</figcaption>
</figure>
</div>
</div>
</div>
<p>As should be the case, precision estimates in <a href="#fig-finalprecision" class="quarto-xref">Figure&nbsp;5</a> increase (i.e., average width of CI decreases) with the number of included subjects and items. The CIs reported here indicate how precisely the expected width of the CI for our focal contrast was estimated by our simulation. Applying our simple heuristic of targeting an expected CI width that is smaller than 0.1, we see the same trade-off between the number of subjects and the number of items as with planning for power. We could either choose 100 subjects and 30 items or 250 subjects and 10 items. Note that our simple heuristic for determining sample size in the planning for precision scenario was quite liberal. This is reflected in the result that we would need a smaller sample size than in the planning for power scenario. With a more conservative precision target, the result is generally the opposite: As a rule, precise parameter estimates usually require bigger samples than null hypothesis testing.</p>
</section>
</section>
<section id="step-7-optional-conduct-sensitivity-analysis" class="level2">
<h2 class="anchored" data-anchor-id="step-7-optional-conduct-sensitivity-analysis">Step 7 (optional): Conduct sensitivity analysis</h2>
<p>In our case study, we have performed simulation-based sample size planning from a single set of parameter values that reflect our assumptions of an expected effect size. Instead of extracting this expected effect size from meta-analyses or pilot data, which has been the main focus of previous tutorials <span class="citation" data-cites="kumleEstimatingPowerGeneralized2021">(e.g., <a href="#ref-kumleEstimatingPowerGeneralized2021" role="doc-biblioref">Kumle et al., 2021</a>)</span>, we have demonstrated some strategies to determine plausible parameter values in GLMMs based on domain knowledge. When sample sizes are chosen based on the results of our simulation-based power analysis, a future study will be informative to reject the null hypothesis if an effect of our <em>expected size</em> is present (or estimate the effect with satisfying precision). However, if the true effect is indeed smaller, power (or precision) will be lower, and the study might not be sufficiently informative. A common, more conservative strategy for sample size justification is to perform sample size planning for the smallest effect size of interest (SESOI). An effect smaller than the SESOI would be considered too small to be interesting or practically meaningful, even if the effect is not actually zero <span class="citation" data-cites="kingPointMinimalImportant2011 lakensEquivalenceTestingPsychological2018">(<a href="#ref-kingPointMinimalImportant2011" role="doc-biblioref">King, 2011</a>; <a href="#ref-lakensEquivalenceTestingPsychological2018" role="doc-biblioref">Lakens, Scheel, et al., 2018</a>)</span>. Unfortunately, specifying a plausible SESOI is a challenging task (for strategies on how to specify a SESOI, see <span class="citation" data-cites="lakensSampleSizeJustification2022">Lakens (<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">2022a</a>)</span>, <span class="citation" data-cites="riesthuisSimulationBasedPowerAnalyses2024">Riesthuis (<a href="#ref-riesthuisSimulationBasedPowerAnalyses2024" role="doc-biblioref">2024</a>)</span>, or <span class="citation" data-cites="lakensImprovingYourStatistical2022">Lakens (<a href="#ref-lakensImprovingYourStatistical2022" role="doc-biblioref">2022b</a>)</span>). When domain knowledge or formal theories about the research topic of interest are too vague to specify a meaningful SESOI, it is still recommended to demonstrate power or precision for different effect sizes in a <em>sensitivity power analysis</em> <span class="citation" data-cites="lakensSampleSizeJustification2022">(<a href="#ref-lakensSampleSizeJustification2022" role="doc-biblioref">Lakens, 2022a</a>)</span>. By simulating power (or precision) for different effect sizes (in addition to the different number of subjects and items), one can make sure that power (or precision) would still be sufficient to detect smaller effect sizes than our expected effect or at least get an impression of how strongly power (or precision) depends on the size of the true effect. For our case study that investigates combined hypotheses in a GLMM modeling framework, sensitivity analysis would require manually specifying additional sets of plausible parameter values that reflect scenarios with smaller or larger differences between groups with respect to our specific research question. Power (or precision) could then be simulated for several of these scenarios (across different numbers of subjects and items, as considered earlier). In steps 2 and 4 of the tutorial, we have briefly discussed scenarios where the applied statistical model is more (or less) parsimonious than the data-generating process. Sensitivity analysis can be used to assess the consequences of a mismatch by investigating different combinations of data-generating processes and statistical models. Such extended simulations can be a great resource to make an informed decision about the concrete model to estimate for the planned study where the true data-generating process is unknown. Although recommended, we do not present a sensitivity analysis for our case study to keep the length of the tutorial manageable.</p>
</section>
</section>
<section id="conclusion-and-outlook" class="level1">
<h1>Conclusion and outlook</h1>
<p>In this tutorial, we provided a step-by-step guide on how to perform tailored simulation-based sample size planning for GLMMs based on a concrete case study. To conclude, we want to give an outlook on five developments regarding the future role of simulation-based sample size planning in experimental research:</p>
<ol type="1">
<li><p>As experimental designs become more complex and the appropriate flexible statistical frameworks, like GLMMs, become more popular, there is an ever growing need for simulation-based sample size planning in experimental research.</p></li>
<li><p>The ability to conduct simulation-based sample size planning becomes an increasingly valuable skill that should be taught to experimental researchers. By incorporating such training into research methods courses and workshops, researchers can improve the quality of their experimental designs and enhance the rigor of their studies. The need to reason about how to simulate plausible data that is in line with the research hypothesis, while not violating domain expertise on how plausible data should look, might also contribute to planning more insightful studies that can answer more precise research questions <span class="citation" data-cites="yarkoniGeneralizabilityCrisis2022">(<a href="#ref-yarkoniGeneralizabilityCrisis2022" role="doc-biblioref">Yarkoni, 2022</a>)</span>.</p></li>
<li><p>Given the significant disconnect between the amount of effort required to perform tailored simulation-based sample size planning and the perceived effort estimated by researchers and collaborators in experimental research, there is a need to address the mismatch in effort perception. Many researchers request simulation-based power analyses from statisticians or methodological experts without fully comprehending the complexity and time-consuming nature of these tailored simulations. Therefore, it is crucial to raise awareness about the effort involved to ensure realistic expectations and effective collaboration with methodological experts.</p></li>
<li><p>Tailored data simulations and power analyses are not mere technicalities; they are valuable research contributions that deserve adequate recognition in experimental research. Their importance can be reflected by highlighting the simulation work in a publication or even allocating them a separate publication, or incorporating them as a significant component of stage 1 preregistered reports <span class="citation" data-cites="chambersPresentFutureRegistered2022">(<a href="#ref-chambersPresentFutureRegistered2022" role="doc-biblioref">Chambers &amp; Tzavella, 2022</a>)</span>.</p></li>
<li><p>Simulation-based sample size planning aligns well with the principles of Open Science and preregistration and could be further integrated. When researchers have access to simulated data based on their pre-specified model, analyzing the collected dataset becomes straightforward and unambiguous. By preregistering their simulation-based sample size plan, researchers enhance the transparency and accountability of their experimental procedures, contributing to the credibility and reproducibility of research.</p></li>
</ol>
</section>
<section id="references" class="level1">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-albersWhenPowerAnalyses2018a" class="csl-entry" role="listitem">
Albers, C., &amp; Lakens, D. (2018). When power analyses based on pilot data are biased: <span>Inaccurate</span> effect size estimators and follow-up bias. <em>Journal of Experimental Social Psychology</em>, <em>74</em>, 187–195. <a href="https://doi.org/10.1016/j.jesp.2017.09.004">https://doi.org/10.1016/j.jesp.2017.09.004</a>
</div>
<div id="ref-R-marginaleffects" class="csl-entry" role="listitem">
Arel-Bundock, V., Greifer, N., &amp; Heiss, A. (Forthcoming). How to interpret statistical models using <span class="nocase">marginaleffects</span> in <span>R</span> and <span>Python</span>. <em>Journal of Statistical Software</em>.
</div>
<div id="ref-arendStatisticalPowerTwolevel2019" class="csl-entry" role="listitem">
Arend, M. G., &amp; Schäfer, T. (2019). Statistical power in two-level models: <span>A</span> tutorial based on <span>Monte Carlo</span> simulation. <em>Psychological Methods</em>, <em>24</em>(1), 1–19. <a href="https://doi.org/10.1037/met0000195">https://doi.org/10.1037/met0000195</a>
</div>
<div id="ref-batesFittingLinearMixedEffects2015" class="csl-entry" role="listitem">
Bates, D., Mächler, M., Bolker, B., &amp; Walker, S. (2015). Fitting <span>Linear Mixed-Effects Models Using</span> <span><strong>Lme4</strong></span>. <em>Journal of Statistical Software</em>, <em>67</em>(1). <a href="https://doi.org/10.18637/jss.v067.i01">https://doi.org/10.18637/jss.v067.i01</a>
</div>
<div id="ref-R-RJ-2021-048" class="csl-entry" role="listitem">
Bengtsson, H. (2021). A unifying framework for parallel and distributed processing in r using futures. <em>The R Journal</em>, <em>13</em>(2), 208–227. <a href="https://doi.org/10.32614/RJ-2021-048">https://doi.org/10.32614/RJ-2021-048</a>
</div>
<div id="ref-benjaminRedefineStatisticalSignificance2017" class="csl-entry" role="listitem">
Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., Cesarini, D., Chambers, C. D., Clyde, M., Cook, T. D., De Boeck, P., Dienes, Z., Dreber, A., Easwaran, K., Efferson, C., … Johnson, V. E. (2017). Redefine statistical significance. <em>Nature Human Behaviour</em>, <em>2</em>(1), 6–10. <a href="https://doi.org/10.1038/s41562-017-0189-z">https://doi.org/10.1038/s41562-017-0189-z</a>
</div>
<div id="ref-bocktingSimulationbasedPriorKnowledge2024" class="csl-entry" role="listitem">
Bockting, F., Radev, S. T., &amp; Bürkner, P.-C. (2024). Simulation-based prior knowledge elicitation for parametric <span>Bayesian</span> models. <em>Scientific Reports</em>, <em>14</em>(1), 17330. <a href="https://doi.org/10.1038/s41598-024-68090-7">https://doi.org/10.1038/s41598-024-68090-7</a>
</div>
<div id="ref-bolkerLinearGeneralizedLinear2015" class="csl-entry" role="listitem">
Bolker, B. M. (2015). Linear and generalized linear mixed models. In G. A. Fox, S. Negrete-Yankelevich, &amp; V. J. Sosa (Eds.), <em>Ecological <span>Statistics</span></em> (1st ed., pp. 309–333). Oxford University PressOxford. <a href="https://doi.org/10.1093/acprof:oso/9780199672547.003.0014">https://doi.org/10.1093/acprof:oso/9780199672547.003.0014</a>
</div>
<div id="ref-brooksGlmmTMBBalancesSpeed2017" class="csl-entry" role="listitem">
Brooks, M., E., Kristensen, K., Benthem, van, J., Magnusson, A., Berg, C., W., Nielsen, A., Skaug, H., J., Mächler, M., &amp; Bolker, B., M. (2017). <span class="nocase">glmmTMB Balances Speed</span> and <span>Flexibility Among Packages</span> for <span class="nocase">Zero-inflated Generalized Linear Mixed Modeling</span>. <em>The R Journal</em>, <em>9</em>(2), 378. <a href="https://doi.org/10.32614/RJ-2017-066">https://doi.org/10.32614/RJ-2017-066</a>
</div>
<div id="ref-brownIntroductionLinearMixedEffects2021" class="csl-entry" role="listitem">
Brown, V. A. (2021). An <span>Introduction</span> to <span>Linear Mixed-Effects Modeling</span> in <span>R</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>4</em>(1), 2515245920960351. <a href="https://doi.org/10.1177/2515245920960351">https://doi.org/10.1177/2515245920960351</a>
</div>
<div id="ref-brysbaertPowerAnalysisEffect2018" class="csl-entry" role="listitem">
Brysbaert, M., &amp; Stevens, M. (2018). Power <span>Analysis</span> and <span>Effect Size</span> in <span>Mixed Effects Models</span>: <span>A Tutorial</span>. <em>Journal of Cognition</em>, <em>1</em>(1), 9. <a href="https://doi.org/10.5334/joc.10">https://doi.org/10.5334/joc.10</a>
</div>
<div id="ref-burknerBrmsPackageBayesian2017" class="csl-entry" role="listitem">
Bürkner, P.-C. (2017). Brms: <span>An R Package</span> for <span>Bayesian Multilevel Models Using Stan</span>. <em>Journal of Statistical Software</em>, <em>80</em>, 1–28. <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a>
</div>
<div id="ref-burknerAdvancedBayesianMultilevel2018" class="csl-entry" role="listitem">
Bürkner, P.-C. (2018). Advanced <span>Bayesian Multilevel Modeling</span> with the <span>R Package</span> brms. <em>The R Journal</em>, <em>10</em>(1), 395. <a href="https://doi.org/10.32614/RJ-2018-017">https://doi.org/10.32614/RJ-2018-017</a>
</div>
<div id="ref-buttonPowerFailureWhy2013" class="csl-entry" role="listitem">
Button, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., &amp; Munafò, M. R. (2013). Power failure: Why small sample size undermines the reliability of neuroscience. <em>Nature Reviews Neuroscience</em>, <em>14</em>(5), 365–376. <a href="https://doi.org/10.1038/nrn3475">https://doi.org/10.1038/nrn3475</a>
</div>
<div id="ref-camererEvaluatingReplicabilitySocial2018" class="csl-entry" role="listitem">
Camerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., Altmejd, A., Buttrick, N., Chan, T., Chen, Y., Forsell, E., Gampa, A., Heikensten, E., Hummer, L., Imai, T., … Wu, H. (2018). Evaluating the replicability of social science experiments in <span>Nature</span> and <span>Science</span> between 2010 and 2015. <em>Nature Human Behaviour</em>, <em>2</em>(9), 637–644. <a href="https://doi.org/10.1038/s41562-018-0399-z">https://doi.org/10.1038/s41562-018-0399-z</a>
</div>
<div id="ref-chambersPresentFutureRegistered2022" class="csl-entry" role="listitem">
Chambers, C. D., &amp; Tzavella, L. (2022). The past, present and future of <span>Registered Reports</span>. <em>Nature Human Behaviour</em>, <em>6</em>(1), 29–42. <a href="https://doi.org/10.1038/s41562-021-01193-7">https://doi.org/10.1038/s41562-021-01193-7</a>
</div>
<div id="ref-R-pwr" class="csl-entry" role="listitem">
Champely, S. (2020). <em>Pwr: Basic functions for power analysis</em>. <a href="https://github.com/heliosdrm/pwr">https://github.com/heliosdrm/pwr</a>
</div>
<div id="ref-cohenPowerPrimer1992" class="csl-entry" role="listitem">
Cohen, J. (1992). A power primer. <em>Psychological Bulletin</em>, <em>112</em>(1), 155–159. <a href="https://doi.org/10.1037/0033-2909.112.1.155">https://doi.org/10.1037/0033-2909.112.1.155</a>
</div>
<div id="ref-cummingNewStatisticsWhy2014" class="csl-entry" role="listitem">
Cumming, G. (2014). The <span>New Statistics</span>: <span>Why</span> and <span>How</span>. <em>Psychological Science</em>, <em>25</em>(1), 7–29. <a href="https://doi.org/10.1177/0956797613504966">https://doi.org/10.1177/0956797613504966</a>
</div>
<div id="ref-R-faux" class="csl-entry" role="listitem">
DeBruine, L. (2023). <em>Faux: Simulation for factorial designs</em>. Zenodo. <a href="https://doi.org/10.5281/zenodo.2669586">https://doi.org/10.5281/zenodo.2669586</a>
</div>
<div id="ref-debruineUnderstandingMixedEffectsModels2021" class="csl-entry" role="listitem">
DeBruine, L., &amp; Barr, D. J. (2021). Understanding <span>Mixed-Effects Models Through Data Simulation</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>4</em>(1), 2515245920965119. <a href="https://doi.org/10.1177/2515245920965119">https://doi.org/10.1177/2515245920965119</a>
</div>
<div id="ref-deffnerCausalFrameworkCrossCultural2022" class="csl-entry" role="listitem">
Deffner, D., Rohrer, J. M., &amp; McElreath, R. (2022). A <span>Causal Framework</span> for <span>Cross-Cultural Generalizability</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>5</em>(3), 251524592211063. <a href="https://doi.org/10.1177/25152459221106366">https://doi.org/10.1177/25152459221106366</a>
</div>
<div id="ref-dmitrienkoTraditionalMultiplicityAdjustment2013" class="csl-entry" role="listitem">
Dmitrienko, A., &amp; D’Agostino, R. (2013). Traditional multiplicity adjustment methods in clinical trials. <em>Statistics in Medicine</em>, <em>32</em>(29), 5172–5218. <a href="https://doi.org/10.1002/sim.5990">https://doi.org/10.1002/sim.5990</a>
</div>
<div id="ref-ebersoleManyLabsTesting2020" class="csl-entry" role="listitem">
Ebersole, C. R., Mathur, M. B., Baranski, E., Bart-Plange, D.-J., Buttrick, N. R., Chartier, C. R., Corker, K. S., Corley, M., Hartshorne, J. K., IJzerman, H., Lazarević, L. B., Rabagliati, H., Ropovik, I., Aczel, B., Aeschbach, L. F., Andrighetto, L., Arnal, J. D., Arrow, H., Babincak, P., … Nosek, B. A. (2020). Many <span>Labs</span> 5: <span>Testing Pre-Data-Collection Peer Review</span> as an <span>Intervention</span> to <span>Increase Replicability</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>3</em>(3), 309–331. <a href="https://doi.org/10.1177/2515245920958687">https://doi.org/10.1177/2515245920958687</a>
</div>
<div id="ref-endersSimpleMonteCarlo2023" class="csl-entry" role="listitem">
Enders, C. K., Keller, B. T., &amp; Woller, M. P. (2023). A simple <span>Monte Carlo</span> method for estimating power in multilevel designs. <em>Psychological Methods</em>. <a href="https://doi.org/10.1037/met0000614">https://doi.org/10.1037/met0000614</a>
</div>
<div id="ref-fahrmeirRegressionModelsMethods2021" class="csl-entry" role="listitem">
Fahrmeir, L., Kneib, T., Lang, S., &amp; Marx, B. D. (2021). <em>Regression: <span>Models</span>, <span>Methods</span> and <span>Applications</span></em>. Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-662-63882-8">https://doi.org/10.1007/978-3-662-63882-8</a>
</div>
<div id="ref-gelmanBayesianWorkflow2020" class="csl-entry" role="listitem">
Gelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., &amp; Modrák, M. (2020). <em>Bayesian <span>Workflow</span></em> (arXiv:2011.01808). arXiv. <a href="https://arxiv.org/abs/2011.01808">https://arxiv.org/abs/2011.01808</a>
</div>
<div id="ref-gomilaMissingDataExperiments2022" class="csl-entry" role="listitem">
Gomila, R., &amp; Clark, C. S. (2022). Missing data in experiments: <span>Challenges</span> and solutions. <em>Psychological Methods</em>, <em>27</em>(2), 143–155. <a href="https://doi.org/10.1037/met0000361">https://doi.org/10.1037/met0000361</a>
</div>
<div id="ref-greenSIMRPackagePower2016" class="csl-entry" role="listitem">
Green, P., &amp; MacLeod, C. J. (2016). <span>SIMR</span>: An <span>R</span> package for power analysis of generalized linear mixed models by simulation. <em>Methods in Ecology and Evolution</em>, <em>7</em>(4), 493–498. <a href="https://doi.org/10.1111/2041-210X.12504">https://doi.org/10.1111/2041-210X.12504</a>
</div>
<div id="ref-hallgrenConductingSimulationStudies2013" class="csl-entry" role="listitem">
Hallgren, K. A. (2013). Conducting <span>Simulation Studies</span> in the <span>R Programming Environment</span>. <em>Tutorials in Quantitative Methods for Psychology</em>, <em>9</em>(2), 43–60. <a href="https://doi.org/10.20982/tqmp.09.2.p043">https://doi.org/10.20982/tqmp.09.2.p043</a>
</div>
<div id="ref-hartmannFlexiblePriorElicitation2020" class="csl-entry" role="listitem">
Hartmann, M., Agiashvili, G., Bürkner, P., &amp; Klami, A. (2020). Flexible prior elicitation via the prior predictive distribution. In J. Peters &amp; D. Sontag (Eds.), <em>Proceedings of the 36th conference on uncertainty in artificial intelligence (<span>UAI</span>)</em> (Vol. 124, pp. 1129–1138). PMLR.
</div>
<div id="ref-iddiPowerSampleSize2022" class="csl-entry" role="listitem">
Iddi, S., &amp; Donohue, M. C. (2022). Power and <span>Sample Size</span> for <span>Longitudinal Models</span> in <span>R</span> – <span>The</span> longpower <span>Package</span> and <span>Shiny App</span>. <em>The R Journal</em>, <em>14</em>(1), 264–282. <a href="https://doi.org/10.32614/RJ-2022-022">https://doi.org/10.32614/RJ-2022-022</a>
</div>
<div id="ref-johnsonPowerAnalysisGeneralized2015" class="csl-entry" role="listitem">
Johnson, P. C. D., Barry, S. J. E., Ferguson, H. M., &amp; Müller, P. (2015). Power analysis for generalized linear mixed models in ecology and evolution. <em>Methods in Ecology and Evolution</em>, <em>6</em>(2), 133–142. <a href="https://doi.org/10.1111/2041-210X.12306">https://doi.org/10.1111/2041-210X.12306</a>
</div>
<div id="ref-kainPracticalGuidePower2015" class="csl-entry" role="listitem">
Kain, M. P., Bolker, B. M., &amp; McCoy, M. W. (2015). A practical guide and power analysis for <span>GLMMs</span>: Detecting among treatment variation in random effects. <em>PeerJ</em>, <em>3</em>, e1226. <a href="https://doi.org/10.7717/peerj.1226">https://doi.org/10.7717/peerj.1226</a>
</div>
<div id="ref-kelleySampleSizePlanning2006" class="csl-entry" role="listitem">
Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: <span>Accuracy</span> in parameter estimation via narrow confidence intervals. <em>Psychological Methods</em>, <em>11</em>(4), 363–385. <a href="https://doi.org/10.1037/1082-989X.11.4.363">https://doi.org/10.1037/1082-989X.11.4.363</a>
</div>
<div id="ref-kingPointMinimalImportant2011" class="csl-entry" role="listitem">
King, M. T. (2011). A point of minimal important difference (<span>MID</span>): A critique of terminology and methods. <em>Expert Review of Pharmacoeconomics &amp; Outcomes Research</em>, <em>11</em>(2), 171–184. <a href="https://doi.org/10.1586/erp.11.9">https://doi.org/10.1586/erp.11.9</a>
</div>
<div id="ref-kruschkeBayesianNewStatistics2018" class="csl-entry" role="listitem">
Kruschke, J. K., &amp; Liddell, T. M. (2018). The <span>Bayesian New Statistics</span>: <span>Hypothesis</span> testing, estimation, meta-analysis, and power analysis from a <span>Bayesian</span> perspective. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(1), 178–206. <a href="https://doi.org/10.3758/s13423-016-1221-4">https://doi.org/10.3758/s13423-016-1221-4</a>
</div>
<div id="ref-kumleEstimatingPowerGeneralized2021" class="csl-entry" role="listitem">
Kumle, L., Võ, M. L.-H., &amp; Draschkow, D. (2021). Estimating power in (generalized) linear mixed models: <span>An</span> open introduction and tutorial in <span>R</span>. <em>Behavior Research Methods</em>, <em>53</em>(6), 2528–2543. <a href="https://doi.org/10.3758/s13428-021-01546-0">https://doi.org/10.3758/s13428-021-01546-0</a>
</div>
<div id="ref-lafitSelectionNumberParticipants2021" class="csl-entry" role="listitem">
Lafit, G., Adolf, J. K., Dejonckheere, E., Myin-Germeys, I., Viechtbauer, W., &amp; Ceulemans, E. (2021). Selection of the <span>Number</span> of <span>Participants</span> in <span>Intensive Longitudinal Studies</span>: <span>A User-Friendly Shiny App</span> and <span>Tutorial</span> for <span>Performing Power Analysis</span> in <span>Multilevel Regression Models That Account</span> for <span>Temporal Dependencies</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>4</em>(1), 251524592097873. <a href="https://doi.org/10.1177/2515245920978738">https://doi.org/10.1177/2515245920978738</a>
</div>
<div id="ref-lakensSampleSizeJustification2022" class="csl-entry" role="listitem">
Lakens, D. (2022a). Sample <span>Size Justification</span>. <em>Collabra: Psychology</em>, <em>8</em>(1), 33267. <a href="https://doi.org/10.1525/collabra.33267">https://doi.org/10.1525/collabra.33267</a>
</div>
<div id="ref-lakensImprovingYourStatistical2022" class="csl-entry" role="listitem">
Lakens, D. (2022b). <em>Improving <span>Your Statistical Inferences</span></em>. Zenodo. <a href="https://doi.org/10.5281/ZENODO.6409077">https://doi.org/10.5281/ZENODO.6409077</a>
</div>
<div id="ref-lakensJustifyYourAlpha2018" class="csl-entry" role="listitem">
Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., Baguley, T., Becker, R. B., Benning, S. D., Bradford, D. E., Buchanan, E. M., Caldwell, A. R., Van Calster, B., Carlsson, R., Chen, S.-C., Chung, B., Colling, L. J., Collins, G. S., Crook, Z., … Zwaan, R. A. (2018). Justify your alpha. <em>Nature Human Behaviour</em>, <em>2</em>(3), 168–171. <a href="https://doi.org/10.1038/s41562-018-0311-x">https://doi.org/10.1038/s41562-018-0311-x</a>
</div>
<div id="ref-lakensSimulationBasedPowerAnalysis2021" class="csl-entry" role="listitem">
Lakens, D., &amp; Caldwell, A. R. (2021). Simulation-<span>Based Power Analysis</span> for <span>Factorial Analysis</span> of <span>Variance Designs</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>4</em>(1), 251524592095150. <a href="https://doi.org/10.1177/2515245920951503">https://doi.org/10.1177/2515245920951503</a>
</div>
<div id="ref-lakensEquivalenceTestingPsychological2018" class="csl-entry" role="listitem">
Lakens, D., Scheel, A. M., &amp; Isager, P. M. (2018). Equivalence <span>Testing</span> for <span>Psychological Research</span>: <span>A Tutorial</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(2), 259–269. <a href="https://doi.org/10.1177/2515245918770963">https://doi.org/10.1177/2515245918770963</a>
</div>
<div id="ref-lanePowerStrugglesEstimating2018" class="csl-entry" role="listitem">
Lane, S. P., &amp; Hennes, E. P. (2018). Power struggles: <span>Estimating</span> sample size for multilevel relationships research. <em>Journal of Social and Personal Relationships</em>, <em>35</em>(1), 7–31. <a href="https://doi.org/10.1177/0265407517710342">https://doi.org/10.1177/0265407517710342</a>
</div>
<div id="ref-lebeauPowerAnalysisSimulation2019" class="csl-entry" role="listitem">
LeBeau, B. (2019). <em>Power <span>Analysis</span> by <span>Simulation</span> using <span>R</span> and simglm</em>. <a href="https://doi.org/10.17077/f7kk-6w7f">https://doi.org/10.17077/f7kk-6w7f</a>
</div>
<div id="ref-leeUsingTidyversePackage2020" class="csl-entry" role="listitem">
Lee, S., Sriutaisuk, S., &amp; Kim, H. (2020). Using the <span>Tidyverse Package</span> in <span>R</span> for <span>Simulation Studies</span> in <span>SEM</span>. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>, <em>27</em>(3), 468–482. <a href="https://doi.org/10.1080/10705511.2019.1644515">https://doi.org/10.1080/10705511.2019.1644515</a>
</div>
<div id="ref-littleStatisticalAnalysisMissing2014" class="csl-entry" role="listitem">
Little, R. J. A., &amp; Rubin, D. B. (2014). <em>Statistical <span>Analysis</span> with <span>Missing Data</span></em> (2nd ed). Wiley.
</div>
<div id="ref-lundbergWhatYourEstimand2021" class="csl-entry" role="listitem">
Lundberg, I., Johnson, R., &amp; Stewart, B. M. (2021). What <span>Is Your Estimand</span>? <span>Defining</span> the <span>Target Quantity Connects Statistical Evidence</span> to <span>Theory</span>. <em>American Sociological Review</em>, <em>86</em>(3), 532–565. <a href="https://doi.org/10.1177/00031224211004187">https://doi.org/10.1177/00031224211004187</a>
</div>
<div id="ref-magnussonConsequencesIgnoringTherapist2018" class="csl-entry" role="listitem">
Magnusson, K., Andersson, G., &amp; Carlbring, P. (2018). The consequences of ignoring therapist effects in trials with longitudinal data: <span>A</span> simulation study. <em>Journal of Consulting and Clinical Psychology</em>, <em>86</em>(9), 711–725. <a href="https://doi.org/10.1037/ccp0000333">https://doi.org/10.1037/ccp0000333</a>
</div>
<div id="ref-martinMeasuringIndividualDifferences2011" class="csl-entry" role="listitem">
Martin, J. G. A., Nussey, D. H., Wilson, A. J., &amp; Réale, D. (2011). Measuring individual differences in reaction norms in field and experimental studies: A power analysis of random regression models. <em>Methods in Ecology and Evolution</em>, <em>2</em>(4), 362–374. <a href="https://doi.org/10.1111/j.2041-210X.2010.00084.x">https://doi.org/10.1111/j.2041-210X.2010.00084.x</a>
</div>
<div id="ref-matuschekBalancingTypeError2017" class="csl-entry" role="listitem">
Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., &amp; Bates, D. (2017). Balancing <span>Type I</span> error and power in linear mixed models. <em>Journal of Memory and Language</em>, <em>94</em>, 305–315. <a href="https://doi.org/10.1016/j.jml.2017.01.001">https://doi.org/10.1016/j.jml.2017.01.001</a>
</div>
<div id="ref-maxwellSampleSizePlanning2008" class="csl-entry" role="listitem">
Maxwell, S. E., Kelley, K., &amp; Rausch, J. R. (2008). Sample <span>Size Planning</span> for <span>Statistical Power</span> and <span>Accuracy</span> in <span>Parameter Estimation</span>. <em>Annual Review of Psychology</em>, <em>59</em>(1), 537–563. <a href="https://doi.org/10.1146/annurev.psych.59.103006.093735">https://doi.org/10.1146/annurev.psych.59.103006.093735</a>
</div>
<div id="ref-mcelreathStatisticalRethinkingBayesian2020" class="csl-entry" role="listitem">
McElreath, R. (2020). <em>Statistical <span>Rethinking</span>: <span>A Bayesian Course</span> with <span>Examples</span> in <span>R</span> and <span>Stan</span></em> (2nd ed.). <span>Chapman and Hall/CRC</span>. <a href="https://doi.org/10.1201/9780429029608">https://doi.org/10.1201/9780429029608</a>
</div>
<div id="ref-meteyardBestPracticeGuidance2020a" class="csl-entry" role="listitem">
Meteyard, L., &amp; Davies, R. A. I. (2020). Best practice guidance for linear mixed-effects models in psychological science. <em>Journal of Memory and Language</em>, <em>112</em>, 104092. <a href="https://doi.org/10.1016/j.jml.2020.104092">https://doi.org/10.1016/j.jml.2020.104092</a>
</div>
<div id="ref-mikkolaPriorKnowledgeElicitation2023" class="csl-entry" role="listitem">
Mikkola, P., Martin, O. A., Chandramouli, S., Hartmann, M., Abril Pla, O., Thomas, O., Pesonen, H., Corander, J., Vehtari, A., Kaski, S., Bürkner, P.-C., &amp; Klami, A. (2023). Prior <span>Knowledge Elicitation</span>: <span>The Past</span>, <span>Present</span>, and <span>Future</span>. <em>Bayesian Analysis</em>, <em>-1</em>(-1). <a href="https://doi.org/10.1214/23-BA1381">https://doi.org/10.1214/23-BA1381</a>
</div>
<div id="ref-murayamaSummarystatisticsbasedPowerAnalysis2022" class="csl-entry" role="listitem">
Murayama, K., Usami, S., &amp; Sakaki, M. (2022). Summary-statistics-based power analysis: <span>A</span> new and practical method to determine sample size for mixed-effects modeling. <em>Psychological Methods</em>. <a href="https://doi.org/10.1037/met0000330">https://doi.org/10.1037/met0000330</a>
</div>
<div id="ref-preacherComputationalToolsProbing2006" class="csl-entry" role="listitem">
Preacher, K. J., Curran, P. J., &amp; Bauer, D. J. (2006). Computational <span>Tools</span> for <span>Probing Interactions</span> in <span>Multiple Linear Regression</span>, <span>Multilevel Modeling</span>, and <span>Latent Curve Analysis</span>. <em>Journal of Educational and Behavioral Statistics</em>, <em>31</em>(4), 437–448. <a href="https://doi.org/10.3102/10769986031004437">https://doi.org/10.3102/10769986031004437</a>
</div>
<div id="ref-R-base" class="csl-entry" role="listitem">
R Core Team. (2024). <em>R: A language and environment for statistical computing</em>. R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>
</div>
<div id="ref-riesthuisSimulationBasedPowerAnalyses2024" class="csl-entry" role="listitem">
Riesthuis, P. (2024). Simulation-<span>Based Power Analyses</span> for the <span>Smallest Effect Size</span> of <span>Interest</span>: <span>A Confidence-Interval Approach</span> for <span>Minimum-Effect</span> and <span>Equivalence Testing</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>7</em>(2), 25152459241240722. <a href="https://doi.org/10.1177/25152459241240722">https://doi.org/10.1177/25152459241240722</a>
</div>
<div id="ref-schadPrincipledBayesianWorkflow2021" class="csl-entry" role="listitem">
Schad, D. J., Betancourt, M., &amp; Vasishth, S. (2021). Toward a principled <span>Bayesian</span> workflow in cognitive science. <em>Psychological Methods</em>, <em>26</em>(1), 103–126. <a href="https://doi.org/10.1037/met0000275">https://doi.org/10.1037/met0000275</a>
</div>
<div id="ref-schadHowCapitalizePriori2020" class="csl-entry" role="listitem">
Schad, D. J., Vasishth, S., Hohenstein, S., &amp; Kliegl, R. (2020). How to capitalize on a priori contrasts in linear (mixed) models: <span>A</span> tutorial. <em>Journal of Memory and Language</em>, <em>110</em>, 104038. <a href="https://doi.org/10.1016/j.jml.2019.104038">https://doi.org/10.1016/j.jml.2019.104038</a>
</div>
<div id="ref-stefanPracticalChallengesMethodological2022" class="csl-entry" role="listitem">
Stefan, A. M., Evans, N. J., &amp; Wagenmakers, E.-J. (2022). Practical challenges and methodological flexibility in prior elicitation. <em>Psychological Methods</em>, <em>27</em>(2), 177–197. <a href="https://doi.org/10.1037/met0000354">https://doi.org/10.1037/met0000354</a>
</div>
<div id="ref-uyguntuncEpistemicPragmaticFunction2023" class="csl-entry" role="listitem">
Uygun Tunç, D., Tunç, M. N., &amp; Lakens, D. (2023). The epistemic and pragmatic function of dichotomous claims based on statistical hypothesis tests. <em>Theory &amp; Psychology</em>, <em>33</em>(3), 403–423. <a href="https://doi.org/10.1177/09593543231160112">https://doi.org/10.1177/09593543231160112</a>
</div>
<div id="ref-R-furrr" class="csl-entry" role="listitem">
Vaughan, D., &amp; Dancho, M. (2022). <em>Furrr: Apply mapping functions in parallel using futures</em>. <a href="https://CRAN.R-project.org/package=furrr">https://CRAN.R-project.org/package=furrr</a>
</div>
<div id="ref-watsonGeneralisedLinearMixed2023" class="csl-entry" role="listitem">
Watson, S. I. (2023). <em>Generalised <span>Linear Mixed Model Specification</span>, <span>Analysis</span>, <span>Fitting</span>, and <span>Optimal Design</span> in <span>R</span> with the glmmr <span>Packages</span></em>. arXiv. <a href="https://doi.org/10.48550/ARXIV.2303.12657">https://doi.org/10.48550/ARXIV.2303.12657</a>
</div>
<div id="ref-westfallStatisticalPowerOptimal2014" class="csl-entry" role="listitem">
Westfall, J., Kenny, D. A., &amp; Judd, C. M. (2014). Statistical power and optimal design in experiments in which samples of participants respond to samples of stimuli. <em>Journal of Experimental Psychology: General</em>, <em>143</em>, 2020–2045. <a href="https://doi.org/10.1037/xge0000014">https://doi.org/10.1037/xge0000014</a>
</div>
<div id="ref-wickhamWelcomeTidyverse2019" class="csl-entry" role="listitem">
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T., Miller, E., Bache, S., Müller, K., Ooms, J., Robinson, D., Seidel, D., Spinu, V., … Yutani, H. (2019). Welcome to the <span>Tidyverse</span>. <em>Journal of Open Source Software</em>, <em>4</em>(43), 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>
</div>
<div id="ref-wickhamDataScienceImport2023" class="csl-entry" role="listitem">
Wickham, H., Çetinkaya-Rundel, M., &amp; Grolemund, G. (2023). <em>R for data science: Import, tidy, transform, visualize, and model data</em> (2nd edition). O’Reilly.
</div>
<div id="ref-yarkoniGeneralizabilityCrisis2022" class="csl-entry" role="listitem">
Yarkoni, T. (2022). The generalizability crisis. <em>Behavioral and Brain Sciences</em>, <em>45</em>, e1. <a href="https://doi.org/10.1017/S0140525X20001685">https://doi.org/10.1017/S0140525X20001685</a>
</div>
<div id="ref-yuPassLmePower2019" class="csl-entry" role="listitem">
Yu, M. (2019). <em>Pass.lme: <span>Power</span> and <span>Sample Size</span> for <span>Linear Mixed Effect Models</span></em> (p. 0.9.0). Comprehensive R Archive Network. <a href="https://doi.org/10.32614/CRAN.package.pass.lme">https://doi.org/10.32614/CRAN.package.pass.lme</a>
</div>
<div id="ref-zhangPracticalStatisticalPower2018" class="csl-entry" role="listitem">
Zhang, Z., &amp; Yuan, K.-H. (2018). <em>Practical statistical power analysis using <span>Webpower</span> and <span>R</span></em>. ISDSA Press. <a href="https://doi.org/10.35566/power">https://doi.org/10.35566/power</a>
</div>
<div id="ref-zimmerSampleSizePlanning2023" class="csl-entry" role="listitem">
Zimmer, F., Henninger, M., &amp; Debelak, R. (2023). Sample size planning for complex study designs: <span>A</span> tutorial for the mlpwr package. <em>Behavior Research Methods</em>. <a href="https://doi.org/10.3758/s13428-023-02269-0">https://doi.org/10.3758/s13428-023-02269-0</a>
</div>
</div>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>For example, the <em>Social Sciences Replication Project</em> targeted a power of 0.90 to safeguard against biased effect sizes in the original studies <span class="citation" data-cites="camererEvaluatingReplicabilitySocial2018">(<a href="#ref-camererEvaluatingReplicabilitySocial2018" role="doc-biblioref">Camerer et al., 2018</a>)</span>, and <em>Many Labs 5</em> even targeted a power of 0.95 <span class="citation" data-cites="ebersoleManyLabsTesting2020">(<a href="#ref-ebersoleManyLabsTesting2020" role="doc-biblioref">Ebersole et al., 2020</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Note that a different estimand would be the so-called average treatment effect (ATE). For the ATE, the probability contrast is defined for each combination of expert and scan, and then these contrasts are averaged across all experts and scans from the target population <span class="citation" data-cites="lundbergWhatYourEstimand2021">(<a href="#ref-lundbergWhatYourEstimand2021" role="doc-biblioref">Lundberg et al., 2021</a>)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The <em>faux</em> package <span class="citation" data-cites="R-faux">(<a href="#ref-R-faux" role="doc-biblioref">DeBruine, 2023</a>)</span> contains useful functions when simulating factorial designs, including random effects.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Developing more effective strategies on how to elicit and visualize domain knowledge is currently an active area of research, primarily in the context of Bayesian modeling <span class="citation" data-cites="bocktingSimulationbasedPriorKnowledge2024 mikkolaPriorKnowledgeElicitation2023 stefanPracticalChallengesMethodological2022 hartmannFlexiblePriorElicitation2020">(<a href="#ref-bocktingSimulationbasedPriorKnowledge2024" role="doc-biblioref">Bockting et al., 2024</a>; <a href="#ref-hartmannFlexiblePriorElicitation2020" role="doc-biblioref">Hartmann et al., 2020</a>; <a href="#ref-mikkolaPriorKnowledgeElicitation2023" role="doc-biblioref">Mikkola et al., 2023</a>; <a href="#ref-stefanPracticalChallengesMethodological2022" role="doc-biblioref">Stefan et al., 2022</a>)</span>. We expect that future advances in this field will also be highly relevant for tailored simulation-based sample size planning with frequentist models.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>For Bayesian GLMMs, the <em>brms</em> R package is currently the most prominent option <span class="citation" data-cites="burknerBrmsPackageBayesian2017">(<a href="#ref-burknerBrmsPackageBayesian2017" role="doc-biblioref">Bürkner, 2017</a>)</span>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>This code was inspired by the “Mixed Design Simulation” vignette of the <em>faux</em> package at <a href="https://debruine.github.io/faux/articles/sim_mixed.html" class="uri">https://debruine.github.io/faux/articles/sim_mixed.html</a>.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>An advanced alternative to our heuristic trade-off between subjects and items would be to explicitly optimize for cost-efficient study designs using the <em>mlpwr</em> package <span class="citation" data-cites="zimmerSampleSizePlanning2023">(<a href="#ref-zimmerSampleSizePlanning2023" role="doc-biblioref">Zimmer et al., 2023</a>)</span>. The package performs simulation-based power analysis in a surrogate modeling framework that can evaluate power for a large grid of design combinations more efficiently. The framework also requires users to write their own <code>sim_and_analyse</code> function and can be considered a great extension on what we cover in our tutorial.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{pargent2024,
  author = {Pargent, Florian and K. Koch, Timo and Kleine, Anne-Kathrin
    and Lermer, Eva and Gaube, Susanne},
  title = {A {Tutorial} on {Tailored} {Simulation-Based} {Sample-Size}
    {Planning} for {Experimental} {Designs} with {Generalized} {Linear}
    {Mixed} {Models}},
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {7},
  number = {4},
  date = {2024},
  doi = {10.1177/25152459241287132},
  langid = {en},
  abstract = {When planning experimental research, determining an
    appropriate sample size and using suitable statistical models are
    crucial for robust and informative results. The recent replication
    crisis underlines the need for more rigorous statistical methodology
    and adequately powered designs. Generalized linear mixed models
    (GLMMs) offer a flexible statistical framework to analyze
    experimental data with complex (e.g., dependent and hierarchical)
    data structures. However, available methods and software for a
    priori sample size planning for GLMMs are often limited to specific
    designs. Tailored data simulation approaches offer a more flexible
    alternative. Based on a practical case study where we focus on a
    binomial GLMM with two random intercepts and discrete predictor
    variables, the current tutorial equips researchers with a
    step-by-step guide and corresponding code for conducting tailored a
    priori sample size planning with GLMMs. We not only focus on power
    analysis but also explain how to use the precision of parameter
    estimates to determine appropriate sample sizes. We conclude with an
    outlook on the increasing importance of simulation-based sample size
    planning.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-pargent2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Pargent, F., K. Koch, T., Kleine, A.-K., Lermer, E., &amp; Gaube, S.
(2024). A Tutorial on Tailored Simulation-Based Sample-Size Planning for
Experimental Designs with Generalized Linear Mixed Models. <em>Advances
in Methods and Practices in Psychological Science</em>, <em>7</em>(4).
<a href="https://doi.org/10.1177/25152459241287132">https://doi.org/10.1177/25152459241287132</a>
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","selector":".lightbox","loop":false,"closeEffect":"zoom","descPosition":"bottom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>